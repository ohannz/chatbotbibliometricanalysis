orig_row,topic,prob_max,text
0,1,1.0,"Purpose: To evaluate the accuracy, comprehensiveness, empathetic tone, and patient preference for AI and urologist responses to patient messages concerning common BPH questions across phases of care. Methods: Cross-sectional study evaluating responses to 20 BPH-related questions generated by 2 AI chatbots and 4 urologists in a simulated clinical messaging environment without direct patient interaction. Accuracy, completeness, and empathetic tone of responses assessed by experts using Likert scales, and preferences and perceptions of authorship (chatbot vs. human) rated by non-medical evaluators. Results: Five non-medical volunteers independently evaluated, ranked, and inferred the source for 120 responses (n = 600 total). For volunteer evaluations, the mean (SD) score of chatbots, 3.0 (1.4) (moderately empathetic) was significantly higher than urologists, 2.1 (1.1) (slightly empathetic) (p < 0.001); mean (SD) and preference ranking for chatbots, 2.6 (1.6), was significantly higher than urologist ranking, 3.9 (1.6) (p < 0.001). Two subject matter experts (SMEs) independently evaluated 120 responses each (answers to 20 questions from 4 urologist and 2 chatbots, n = 240 total). For SME evaluations, mean (SD) accuracy score for chatbots was 4.5 (1.1) (nearly all correct) and not significantly different than urologists, 4.6 (1.2). The mean (SD) completeness score for chatbots was 2.4 (0.8) (comprehensive), significantly higher than urologists, 1.6 (0.6) (adequate) (p < 0.001). Conclusion: Answers to patient BPH messages generated by chatbots were evaluated by experts as equally accurate and more complete than urologist answers. Non-medical volunteers preferred chatbot-generated messages and considered them more empathetic compared to answers generated by urologists. © 2024 Elsevier B.V., All rights reserved."
1,-1,0.21775813079632142,"Background: With the rise of large language models, the application of artificial intelligence in research is expanding, possibly accelerating specific stages of the research processes. This study aims to compare the accuracy, completeness and relevance of chatbot-generated responses against human responses in evidence synthesis as part of a scoping review. Methods: We employed a structured survey-based research methodology to analyse and compare responses between two human researchers and four chatbots (ZenoChat, ChatGPT 3.5, ChatGPT 4.0, and ChatFlash) to questions based on a pre-coded sample of 407 articles. These questions were part of an evidence synthesis of a scoping review dealing with digitally supported interaction between healthcare workers. Results: The analysis revealed no significant differences in judgments of correctness between answers by chatbots and those given by humans. However, chatbots’ answers were found to recognise the context of the original text better, and they provided more complete, albeit longer, responses. Human responses were less likely to add new content to the original text or include interpretation. Amongst the chatbots, ZenoChat provided the best-rated answers, followed by ChatFlash, with ChatGPT 3.5 and ChatGPT 4.0 tying for third. Correct contextualisation of the answer was positively correlated with completeness and correctness of the answer. Conclusions: Chatbots powered by large language models may be a useful tool to accelerate qualitative evidence synthesis. Given the current speed of chatbot development and fine-tuning, the successful applications of chatbots to facilitate research will very likely continue to expand over the coming years. © 2025 Elsevier B.V., All rights reserved."
2,0,1.0,"Background: Early treatment is critical to improve eating disorder prognosis. Single session interventions have been proposed as a strategy to provide short term support to people on waitlists for eating disorder treatment, however, it is not always possible to access this early intervention. Conversational artificial intelligence agents or “chatbots” reflect a unique opportunity to attempt to fill this gap in service provision. The aim of this research was to co-design a novel chatbot capable of delivering a single session intervention for adults on the waitlist for eating disorder treatment across the diagnostic spectrum and ascertain its preliminary acceptability and feasibility. Methods: A Double Diamond co-design approach was employed which included four phases: discover, define, develop, and deliver. There were 17 participants in total in Australia; ten adults with a lived experience of an eating disorder and seven registered psychologists working in the field of eating disorders, who participated in online interviews and workshops. Thematic and content analyses were undertaken with interview/workshop transcriptions with findings from the previous phase informing the ideas and development of the next phase. A final prototype of a single session intervention chatbot was presented to the participants in the deliver phase. Results: Thematic and content analyses identified four main themes that were present across the four phases of interviews/workshops: conversational tone, safety and risk management, user journey and session structure, and content. Conclusions: Overall, the feedback on the single session intervention chatbot was positive throughout the Double Diamond process from both people with a lived experience of an eating disorder and psychologists. Incorporating the feedback across the four themes and four co-design phases allowed for refinement of the chatbot. Further research is required to evaluate the chatbot’s efficacy in early treatment settings. © 2025 Elsevier B.V., All rights reserved."
3,1,0.6362585758264091,"Background: Increased utilization of artificial intelligence (AI)-driven search and large language models by the lay and medical community requires us to evaluate the accuracy of AI responses to common hand surgery questions. We hypothesized that the answers to most hand surgery questions posed to an AI large language model would be correct. Methods: Using the topics covered in Green’s Operative Hand Surgery 8th Edition as a guide, 56 hand surgery questions were compiled and posed to ChatGPT (OpenAI, San Francisco, CA). Two attending hand surgeons then independently reviewed ChatGPT’s answers for response accuracy, completeness, and usefulness. A Cohen’s kappa analysis was performed to assess interrater agreement. Results: An average of 45 of the 56 questions posed to ChatGPT were deemed correct (80%), 39 responses were deemed useful (70%), and 32 responses were deemed complete (57%) by the reviewers. Kappa analysis demonstrated “fair to moderate” agreement between the two raters. Reviewers disagreed on 11 questions regarding correctness, 16 questions regarding usefulness, and 19 questions regarding completeness. Conclusions: Large language models have the potential to both positively and negatively impact patient perceptions and guide referral patterns based on the accuracy, completeness, and usefulness of their responses. While most responses fit these criteria, more precise responses are needed to ensure patient safety and avoid misinformation. Individual hand surgeons and surgical societies must understand these technologies and interface with the companies developing them to provide our patients with the best possible care. © 2025 Elsevier B.V., All rights reserved."
4,1,0.6346080257482395,"Objectives: The purpose of this study was to compare the reliability and accuracy of responses provided to patients about hip arthroscopy (HA) by Chat Generative Pre-Trained Transformer (ChatGPT), an artificial intelligence (AI) and large language model (LLM) online program, with those obtained through a contemporary Google Search for frequently asked questions (FAQs) regarding HA. Methods: “HA” was entered into Google Search and ChatGPT, and the 15 most common FAQs and the answers were determined. In Google Search, the FAQs were obtained from the “People also ask” section. ChatGPT was queried to provide the 15 most common FAQs and subsequent answers. The Rothwell system groups the questions under 10 subheadings. Responses of ChatGPT and Google Search engines were compared. Results: Timeline of recovery (23.3%) and technical details (20%) were the most common categories of questions. ChatGPT produced significantly more data in the technical details category (33.3% vs. 6.6%; p-value ​= ​0.0455) than in the other categories. The most FAQs were academic in nature for both Google web search (46.6%) and ChatGPT (93.3%). ChatGPT provided significantly more academic references than Google web searches (93.3% vs. 46.6%). Conversely, Google web search cited more medical practice references (20% vs. 0%), single surgeon websites (26% vs. 0%), and government websites (6% vs. 0%) more frequently than ChatGPT. Conclusion: ChatGPT performed similarly to Google searches for information about HA. Compared to Google, ChatGPT provided significantly more academic sources for its answers to patient questions. Level of evidence: Level IV. © 2025 Elsevier B.V., All rights reserved."
5,0,0.5262757023584002,"Background: Adolescent mental health is vital for public health, yet many interventions fail to recognise adolescents as proactive community contributors. This paper discusses the co-design and acceptability testing of a chat-story intervention to enhance Brazilian adolescents' participation in the promotion of mental health in their peer communities. We specifically highlight the iterative process of co-creating this intervention with community stakeholders. Methods: The co-design was led by researchers, a youth collaborative group, and health-tech experts. Part 1 included quantitative (n = 1,768) and qualitative (n = 46) studies with Brazilian adolescents aged 15–18 for priority-setting. Part 2 involved co-creation and technical production, with input from youth advisors (n = 24), school staff (n = 11), and policy experts (n = 3). In Part 3, the chat-story was user tested (n = 32). Parts 4 and 5 assessed acceptability through a qualitative study in schools (n = 138) and initial efficacy during an online campaign (n = 795). Results: Participants aspired to support their peers' mental health in schools, both one-to-one and collectively, but felt unprepared. This informed the chat-story's goal of enhancing peer support and collective action skills. Themes identified during Part 1, such as prejudice and academic pressure, were woven into the narrative to raise awareness of the social determinants of mental health, drawing from real-life stories. In the final story, players search for their missing best friend at school, uncovering his anxiety struggles and practicing skills such as empathic listening and partnership building. A manual for teachers was collaboratively designed for use within school settings, supplementing direct-to-user online applications. Acceptability testing showed participants found the tool authentic and user-friendly. Online users perceived the tool as preparing and motivating them to offer peer support and engage in collective action. Conclusions: The immersive co-creation model, enriched by input from key stakeholders, yielded a relevant and well-received intervention for Brazilian adolescents. Co-designed creative tools like chat-stories hold promise as digital mental health tools, fostering awareness, critical reflection, and inspiring adolescents to drive positive social change. © 2025 Elsevier B.V., All rights reserved."
6,-1,0.17523651660737768,"Artificial intelligence (AI) can help prepare graduating medical students for responding to nursing texts, something few interns are prepared to do on day 1 of residency. An AI-nurse could enhance that preparation by paging and corresponding with fourth-year medical students, requesting urgent orders during an overnight on-call simulation. © 2025 Elsevier B.V., All rights reserved."
7,1,0.39631279988573365,"Introduction: Tumor boards are a cornerstone of modern cancer treatment. Given their advanced capabilities, the role of Large Language Models (LLMs) in generating tumor board decisions for otorhinolaryngology (ORL) head and neck surgery is gaining increasing attention. However, concerns over data protection and the use of confidential patient information in web-based LLMs have restricted their widespread adoption and hindered the exploration of their full potential. In this first study of its kind we compared standard human multidisciplinary tumor board recommendations (MDT) against a web-based LLM (ChatGPT-4o) and a locally run LLM (Llama 3) addressing data protection concerns. Material and methods: Twenty-five simulated tumor board cases were presented to an MDT composed of specialists from otorhinolaryngology, craniomaxillofacial surgery, medical oncology, radiology, radiation oncology, and pathology. This multidisciplinary team provided a comprehensive analysis of the cases. The same cases were input into ChatGPT-4o and Llama 3 using structured prompts, and the concordance between the LLMs' and MDT’s recommendations was assessed. Four MDT members evaluated the LLMs' recommendations in terms of medical adequacy (using a six-point Likert scale) and whether the information provided could have influenced the MDT's original recommendations. Results: ChatGPT-4o showed 84% concordance (21 out of 25 cases) and Llama 3 demonstrated 92% concordance (23 out of 25 cases) with the MDT in distinguishing between curative and palliative treatment strategies. In 64% of cases (16/25) ChatGPT-4o and in 60% of cases (15/25) Llama, identified all first-line therapy options considered by the MDT, though with varying priority. ChatGPT-4o presented all the MDT’s first-line therapies in 52% of cases (13/25), while Llama 3 offered a homologous treatment strategy in 48% of cases (12/25). Additionally, both models proposed at least one of the MDT's first-line therapies as their top recommendation in 28% of cases (7/25). The ratings for medical adequacy yielded a mean score of 4.7 (IQR: 4–6) for ChatGPT-4o and 4.3 (IQR: 3–5) for Llama 3. In 17% of the assessments (33/200), MDT members indicated that the LLM recommendations could potentially enhance the MDT's decisions. Discussion: This study demonstrates the capability of both LLMs to provide viable therapeutic recommendations in ORL head and neck surgery. Llama 3, operating locally, bypasses many data protection issues and shows promise as a clinical tool to support MDT decisions. However at present, LLMs should augment rather than replace human decision-making. © 2025 Elsevier B.V., All rights reserved."
8,1,1.0,"Natural language processing (NLP) is the study of systems that allow machines to understand, interpret, and generate human language. With the advent of large language models (LLMs), non-technical industries can also harness the power of NLP. This includes healthcare, specifically surgical care and plastic surgery. This manuscript is an introductory review for plastic surgeons to understand the current state and future potential of NLP in patient consultations. The integration of NLP into plastic surgery patient consultations can transform both documentation and communication. These applications include information extraction, patient chart summarization, ambient transcription, coding, enhancing patient understanding, translation, and a patient-facing chatbot. We discuss the current progress toward building these applications and highlight their challenges. NLP has the potential to personalize care, enhance patient satisfaction, and improve workflows for plastic surgeons. Altogether, NLP can radically transform our current model of consultation into one that is more patient-centered. © 2025 Elsevier B.V., All rights reserved."
9,3,1.0,"The Artificial Intelligence Patient Librarian (AIPL) was designed to meet the psychosocial and supportive care needs of Metastatic Breast Cancer (MBC) patients with HR+/HER2− subtypes. AIPL provides conversational patient education, answers user questions, and offers tailored online resource recommendations. This study, conducted in three phases, assessed AIPL’s impact on patients’ ability to manage their advanced disease. In Phase 1, educational content was adapted for chatbot delivery, and over 100 credible online resources were annotated using a Convolutional Neural Network (CNN) to drive recommendations. Phase 2 involved 42 participants who completed pre- and post-surveys after using AIPL for two weeks. The surveys measured patient activation using the Patient Activation Measure (PAM) tool and evaluated user experience with the System Usability Scale (SUS). Phase 3 included focus groups to explore user experiences in depth. Of the 42 participants, 36 completed the study, with 10 participating in focus groups. Most participants were aged 40–64. PAM scores showed no significant differences between pre-survey (mean = 59.33, SD = 5.19) and post-survey (mean = 59.22, SD = 6.16), while SUS scores indicated good usability. Thematic analysis revealed four key themes: AIPL offers basic wellness and health guidance, provides limited support for managing relationships, offers limited condition-specific medical information, and is unable to offer hope to patients. Despite showing no impact on the PAM, possibly due to high baseline activation, AIPL demonstrated good usability and met basic information needs, particularly for newly diagnosed MBC patients. Future iterations will incorporate a large language model (LLM) to provide more comprehensive and personalized assistance. © 2025 Elsevier B.V., All rights reserved."
10,-1,0.1316465975768777,"Introduction: Digital tools could assist obstetric providers by delivering information given increasing options for fetal aneuploidy screening. Purpose: To determine the impact of a chatbot for pre-test education and counseling in low-risk pregnancies. Methods: Two sites participated in this randomized controlled trial. Patients in the intervention group used a chatbot prior to the provider visit, while patients in the control group only received education by the provider. The primary outcome was change in patient knowledge scores after provider education. Analysis was by intention to treat. Results: Overall, 258 women participated (n = 130; intervention and n = 128; control). Knowledge gain was significantly higher among patients using the chatbot (mean increase in correct answers [out of 20]: +4.1 vs +1.9, p < 0.001). Both groups reported high satisfaction, with no statistically significant difference between intervention and control groups (mean patient satisfaction [1–10]: 8.2 vs 8.5 respectively, p = 0.35). Providers also reported high satisfaction scores with no significant difference between intervention and control groups (mean provider satisfaction [1 − 10]: 8.7 vs 8.4 respectively, p = 0.13). Conclusions: Pre-test education via a chatbot can increase patient knowledge of prenatal testing choices, with high patient and provider satisfaction. © 2024 Elsevier B.V., All rights reserved."
11,4,1.0,"Background: We developed MARVIN, an artificial intelligence (AI)-based chatbot that provides 24/7 expert-validated information on self-management-related topics for people with HIV. This study assessed (1) the feasibility of using MARVIN, (2) its usability and acceptability, and (3) four usability subconstructs (perceived ease of use, perceived usefulness, attitude towards use, and behavioural intention to use). Methods: In a mixed-methods study conducted at the McGill University Health Centre, enrolled participants were asked to have 20 conversations within 3 weeks with MARVIN on predetermined topics and to complete a usability questionnaire. Feasibility, usability, acceptability, and usability subconstructs were examined against predetermined success thresholds. Qualitatively, randomly selected participants were invited to semi-structured focus groups/interviews to discuss their experiences with MARVIN. Barriers and facilitators were identified according to the four usability subconstructs. Results: From March 2021 to April 2022, 28 participants were surveyed after a 3-week testing period, and nine were interviewed. Study retention was 70% (28/40). Mean usability exceeded the threshold (69.9/68), whereas mean acceptability was very close to target (23.8/24). Ratings of attitude towards MARVIN's use were positive (+14%), with the remaining subconstructs exceeding the target (5/7). Facilitators included MARVIN's reliable and useful real-time information support, its easy accessibility, provision of convivial conversations, confidentiality, and perception as being emotionally safe. However, MARVIN's limited comprehension and the use of Facebook as an implementation platform were identified as barriers, along with the need for more conversation topics and new features (e.g., memorization). Conclusions: The study demonstrated MARVIN's global usability. Our findings show its potential for HIV self-management and provide direction for further development. © 2025 Elsevier B.V., All rights reserved."
12,1,0.8238186001507497,"Background: With suicide rates in the United States at an all-time high, individuals experiencing suicidal ideation are increasingly turning to large language models (LLMs) for guidance and support. Objective: The objective of this study was to assess the competency of 3 widely used LLMs to distinguish appropriate versus inappropriate responses when engaging individuals who exhibit suicidal ideation. Methods: This observational, cross-sectional study evaluated responses to the revised Suicidal Ideation Response Inventory (SIRI-2) generated by ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro. Data collection and analyses were conducted in July 2024. A common training module for mental health professionals, SIRI-2 provides 24 hypothetical scenarios in which a patient exhibits depressive symptoms and suicidal ideation, followed by two clinician responses. Clinician responses were scored from –3 (highly inappropriate) to +3 (highly appropriate). All 3 LLMs were provided with a standardized set of instructions to rate clinician responses. We compared LLM responses to those of expert suicidologists, conducting linear regression analyses and converting LLM responses to z scores to identify outliers (z score>1.96 or <–1.96; P<0.05). Furthermore, we compared final SIRI-2 scores to those produced by health professionals in prior studies. Results: All 3 LLMs rated responses as more appropriate than ratings provided by expert suicidologists. The item-level mean difference was 0.86 for ChatGPT (95% CI 0.61-1.12; P<.001), 0.61 for Claude (95% CI 0.41-0.81; P<.001), and 0.73 for Gemini (95% CI 0.35-1.11; P<.001). In terms of z scores, 19% (9 of 48) of ChatGPT responses were outliers when compared to expert suicidologists. Similarly, 11% (5 of 48) of Claude responses were outliers compared to expert suicidologists. Additionally, 36% (17 of 48) of Gemini responses were outliers compared to expert suicidologists. ChatGPT produced a final SIRI-2 score of 45.7, roughly equivalent to master’s level counselors in prior studies. Claude produced an SIRI-2 score of 36.7, exceeding prior performance of mental health professionals after suicide intervention skills training. Gemini produced a final SIRI-2 score of 54.5, equivalent to untrained K-12 school staff. Conclusions: Current versions of 3 major LLMs demonstrated an upward bias in their evaluations of appropriate responses to suicidal ideation; however, 2 of the 3 models performed equivalent to or exceeded the performance of mental health professionals. © 2025 Elsevier B.V., All rights reserved."
13,4,1.0,"Awareness and uptake of HIV pre-exposure prophylaxis (PrEP), a highly efficacious medication for HIV prevention, remains low in many sub-Saharan African countries. This study explored the acceptability and feasibility of an HIV prevention chatbot tailored for cisgender women and transgender men in Lagos, Nigeria. The chatbot was developed and implemented in the Nigerian healthcare context using participatory approaches engaging HIV healthcare providers and representatives from the target populations to ensure that the content was appropriate, comprehensible, and non-stigmatizing. The chatbot included information about PrEP, HIV risk/ vulnerabilities, and self-assessment guidelines. The pilot was conducted among 150 participants (132 cisgender women and 18 transgender men) recruited at public health facilities and community health clinics. The chatbot was well-received by clients and healthcare providers and has the potential for rapid scale-up to facilitate PrEP uptake among HIV vulnerable populations. Participants reported the chatbot was easy to understand (97%), a good way to learn health information (99%), and that they would recommend it to others (96%). Participants appreciated the confidentiality of the chatbot, the conversational prompts and offered suggestions to make the chatbot more accessible and user-friendly. Most participants (92%) reported that they learned new information about HIV from the chatbot. © 2025 Elsevier B.V., All rights reserved."
14,0,0.3231260317206519,"Background: Chatbots are increasingly accepted in public health for their ability to replicate human-like communication and provide scalable, 24/7 services. The high prevalence of dental caries in children underscores the need for early and effective intervention. Objective: This study aimed to develop the 30-Day FunDee chatbot and evaluate its effectiveness, usability, and acceptability in delivering oral health education to caregivers of children aged 6 to 36 months. Methods: The chatbot was created using the artificial intelligence (AI) chatbot behavior change model, integrating behavioral change theories into content designed for 3‐5 minutes of daily use over 30 days. A pre-post experimental study was conducted from December 2021 to February 2022 in Hat Yai District, Songkhla Province, and Maelan District, Pattani Province, Thailand. Fifty-eight caregivers completed a web-based structured questionnaire at baseline and 2 months post baseline to evaluate knowledge, protection motivation theory-based perceptions, and tooth-brushing practices. Usability was assessed via chatbot logfiles and a web-based questionnaire at 2 months post baseline. Acceptability was evaluated through three methods: (1) open-ended chatbot interactions on day 30, (2) a web-based structured questionnaire at 2 months post baseline, and (3) semistructured telephone interviews with 15 participants 2 weeks post intervention. Participants for interviews were stratified by adherence levels and randomly selected from Hatyai and Maelan districts. All self-reported variables were measured on a 5-point Likert scale (1=lowest, 5=highest). Results: The chatbot was successfully developed based on the 4 components of the AI chatbot behavior change model. Participants had a mean age of 34.5 (SD 8.6) years. The frequency of tooth brushing among caregivers significantly improved, increasing from 72.4% at baseline to 93.1% two months post baseline (P=.006). Protection motivation theory-based perceptions also showed significant improvement, with mean scores rising from 4.0 (SD 0.6) at baseline to 4.5 (SD 0.6) two months post baseline (P<.001). The chatbot received high ratings for satisfaction (4.7/5, SD 0.6) and usability (4.7/5, SD 0.5). Participants engaged with the chatbot for an average of 24.7 (SD 7.2) days out of 30. Caregivers praised the chatbot’s content quality, empathetic communication, and multimedia design, but noted the intervention’s lengthy duration and messaging system as limitations. Conclusions: The 30-Day FunDee chatbot effectively enhanced caregivers’ perceptions of oral health care and improved tooth-brushing practices for children aged 6‐36 months. High user satisfaction and engagement demonstrate its potential as an innovative tool for oral health education. These findings warrant further validation through large-scale, randomized controlled trials. © 2025 Elsevier B.V., All rights reserved."
15,-1,0.21999410684678214,"The increasing demand and use of technology has led to the convergence of technology with health and diagnostic procedures. Digital health is the use of technology and information to enhance and alleviate health issues, as the name suggests. The Indian healthcare industry is changing as a result of wearable technology, telemedicine, genomics, virtual reality (VR), robotics, and artificial intelligence (AI). India is poised for a ""digital health"" revolution, much like many other economies. (Digital Health Report, 2020: Informa Markets' Indian Health). The use of digital health technologies has become essential to the provision of healthcare. The health technology sector, which includes wearables, telemedicine, e-pharmacies, and other products, has grown recently all over the world. Additionally, a lot of research and development has gone into integrating technology like blockchain, virtual reality, robots, and artificial intelligence with medications and healthcare. Healthcare is the biggest industry in India and has a lot of room to grow. This market is driven by the modern world's increasing need for digital healthcare solutions. © 2025 Elsevier B.V., All rights reserved."
16,1,1.0,"Background: ChatGPT, a conversational artificial intelligence developed by OpenAI, has rapidly become an invaluable tool for researchers. With the recent integration of Python code interpretation into the ChatGPT environment, there has been a significant increase in the potential utility of ChatGPT as a research tool, particularly in terms of data analysis applications. Objective: This study aimed to assess ChatGPT as a data analysis tool and provide researchers with a framework for applying ChatGPT to data management tasks, descriptive statistics, and inferential statistics. Methods: A subset of the National Inpatient Sample was extracted. Data analysis trials were divided into data processing, categorization, and tabulation, as well as descriptive and inferential statistics. For data processing, categorization, and tabulation assessments, ChatGPT was prompted to reclassify variables, subset variables, and present data, respectively. Descriptive statistics assessments included mean, SD, median, and IQR calculations. Inferential statistics assessments were conducted at varying levels of prompt specificity (“Basic,” “Intermediate,” and “Advanced”). Specific tests included chi-square, Pearson correlation, independent 2-sample t test, 1-way ANOVA, Fisher exact, Spearman correlation, Mann-Whitney U test, and Kruskal-Wallis H test. Outcomes from consecutive prompt-based trials were assessed against expected statistical values calculated in Python (Python Software Foundation), SAS (SAS Institute), and RStudio (Posit PBC). Results: ChatGPT accurately performed data processing, categorization, and tabulation across all trials. For descriptive statistics, it provided accurate means, SDs, medians, and IQRs across all trials. Inferential statistics accuracy against expected statistical values varied with prompt specificity: 32.5% accuracy for “Basic” prompts, 81.3% for “Intermediate” prompts, and 92.5% for “Advanced” prompts. Conclusions: ChatGPT shows promise as a tool for exploratory data analysis, particularly for researchers with some statistical knowledge and limited programming expertise. However, its application requires careful prompt construction and human oversight to ensure accuracy. As a supplementary tool, ChatGPT can enhance data analysis efficiency and broaden research accessibility. © 2025 Elsevier B.V., All rights reserved."
17,-1,0.1727233122523865,"Background: Women of childbearing age (aged 18-44 years) face multiple barriers to receiving screening and treatment for unhealthy alcohol and substance use, depression, and anxiety, including lack of screening in the primary care setting and lack of support in accessing care. The Women Empowered to Connect with Addiction Resources and Engage in Evidence-based Treatment (WE-CARE) mobile app was developed to test universal screening with women of childbearing age and linkage to care after an anonymous assessment. Objective: In this study, we aimed to investigate the feasibility and acceptability of providing anonymous screening instruments through mobile phones for alcohol and substance use, as well as depression and anxiety, for women of childbearing age. Methods: We used agile development principles based on previous formative research to test WE-CARE mobile health app with women of childbearing age (N=30) who resided in 1 of 6 counties in central Florida. WE-CARE included screening instruments (for alcohol, substance use, depression, and anxiety), a moderated discussion forum, educational microlearning videos, a frequently asked questions section, and resources for linkage to treatment. Individuals were recruited using flyers, academic listserves, and a commercial human subject recruiting company (Prolific). Upon completion of the screening instruments, women explored the educational and linkage to care features of the app and filled out a System Usability Scale to evaluate the mobile health app’s usability and acceptability. Postpilot semistructured interviews (n=4) were conducted to further explore the women’s reactions to the app. Results: A total of 77 women downloaded the application and 30 completed testing. Women of childbearing age gave the WE-CARE app an excellent System Usability Scale score of 86.7 (SD 12.43). Our results indicate elevated risk for substance use in 18 of the 30 (60%) participants, 9/18 (50%) also had an elevated risk for anxiety or depression, and 11/18 (61%) had an elevated risk for substance use, anxiety, or depression. Participants reported that WE-CARE was easy to navigate and use but they would have liked to see more screening questions and more educational content. Linkage to care was an issue; however, as none of the women identified as “at-risk” for substance use disorders contacted the free treatment clinic for further evaluation. Conclusions: The mobile health app was highly rated for acceptability and usability, but participants were not receptive to seeking help at a treatment center after only a few brief encounters with the app. The linkage to care design features was likely insufficient to encourage them to seek treatment. The next version of WE-CARE will include normative scores for participants to self-evaluate their screening status compared with their age- and gender-matched peers and enhanced linkages to care features. Future development will focus on enhancing engagement to improve change behaviors and assess readiness for change. © 2025 Elsevier B.V., All rights reserved."
18,1,1.0,"Digital teaching diversifies the ways of knowledge assessment, as natural language processing offers the possibility of answering questions posed by students and teachers. Objective: This study evaluated ChatGPT's, Bard's and Gemini's performances on second year of medical studies’ (DFGSM2) Pathology exams from the Health Sciences Center of Dijon (France) in 2018–2022. Methods: From 2018 to 2022, exam scores, discriminating powers and discordance rates were retrieved. Seventy questions (25 first-order single response questions and 45 second-order multiple response questions) were submitted on May 2023 to ChatGPT 3.5 and Bard 2.0, and on September 2024 to Gemini 1.5 and ChatGPT-4. Chatbot's and student's average scores were compared, as well as discriminating powers of questions answered by chatbots. The percentage of student–chatbot identical answers was retrieved, and linear regression analysis correlated the scores of chatbots with student's discordance rates. Chatbot's reliability was assessed by submitting the questions in four successive rounds and comparing score variability using a Fleiss’ Kappa and a Cohen's Kappa. Results: Newer chatbots outperformed both students and older chatbots as for the overall scores and multiple-response questions. All chatbots outperformed students on less discriminating questions. Oppositely, all chatbots were outperformed by students to questions with a high discriminating power. Chatbot's scores were correlated to student discordance rates. ChatGPT 4 and Gemini 1.5 provided variable answers, due to effects linked to prompt engineering. Conclusion: Our study in line with the literature confirms chatbot's moderate performance for questions requiring complex reasoning, with ChatGPT outperforming Google chatbots. The use of NLP software based on distributional semantics remains a challenge for the generation of questions in French. Drawbacks to the use of NLP software in generating questions include the generation of hallucinations and erroneous medical knowledge which have to be taken into count when using NLP software in medical education. © 2025 Elsevier B.V., All rights reserved."
19,-1,0.21888402071795457,"Background: Providing ongoing support to the increasing number of caregivers as their needs change in the long-term course of dementia is a severe challenge to any health care system. Conversational artificial intelligence (AI) operating 24/7 may help to tackle this problem. Objective: This study describes the development of a generative AI chatbot—the PDC30 Chatbot—and evaluates its acceptability in a mixed methods study. Methods: The PDC30 Chatbot was developed using the GPT-4o large language model, with a personality agent to constrain its behavior to provide advice on dementia caregiving based on the Positive Dementia Caregiving in 30 Days Guidebook—a laypeople’s resource based on a validated training manual for dementia caregivers. The PDC30 Chatbot’s responses to 21 common questions were compared with those of ChatGPT and another chatbot (called Chatbot-B) as standards of reference. Chatbot-B was constructed using PDC30 Chatbot’s architecture but replaced the latter’s knowledge base with a collection of authoritative sources, including the World Health Organization’s iSupport, By Us For Us Guides, and 185 web pages or manuals by Alzheimer’s Association, National Institute on Aging, and UK Alzheimer’s Society. In the next phase, to assess the acceptability of the PDC30 Chatbot, 21 family caregivers used the PDC30 Chatbot for two weeks and provided ratings and comments on its acceptability. Results: Among the three chatbots, ChatGPT’s responses tended to be repetitive and not specific enough. PDC30 Chatbot and Chatbot-B, by virtue of their design, produced highly context-sensitive advice, with the former performing slightly better when the questions conveyed significant psychological distress on the part of the caregiver. In the acceptability study, caregivers found the PDC30 Chatbot highly user-friendly, and its responses quite helpful and easy to understand. They were rather satisfied with it and would strongly recommend it to other caregivers. During the 2-week trial period, the majority used the chatbot more than once per day. Thematic analysis of their written feedback revealed three major themes: helpfulness, accessibility, and improved attitude toward AI. Conclusions: The PDC30 Chatbot provides quality responses to caregiver questions, which are well-received by caregivers. Conversational AI is a viable approach to improve the support of caregivers. © 2025 Elsevier B.V., All rights reserved."
20,1,0.7555136717857527,"Clinical relevance: Worldwide, millions suffer from cataracts, which impair vision and quality of life. Cataract education improves outcomes, satisfaction, and treatment adherence. Lack of health literacy, language and cultural barriers, personal preferences, and limited resources may all impede effective communication. Background: AI can improve patient education by providing personalised, interactive, and accessible information tailored to patient understanding, interest, and motivation. AI chatbots can have human-like conversations and give advice on numerous topics. Methods: This study investigated the efficacy of chatbots in cataract patient education relative to traditional resources like the AAO website, focusing on information accuracy,understandability, actionability, and readability. A descriptive comparative design was used to analyse quantitative data from frequently asked questions about cataracts answered by ChatGPT, Bard, Bing AI, and the AAO website. SOLO taxonomy, PEMAT, and the Flesch-Kincaid ease score were used to collect and analyse the data. Results: Chatbots scored higher than AAO website on cataract-related questions in terms of accuracy (mean SOLO score ChatGPT: 3.1 ± 0.31, Bard: 2.9 ± 0.72, Bing AI: 2.65 ± 0.49, AAO website: 2.4 ± 0.6, (p < 0.001)). For understandability (mean PEMAT-U score AAO website: 0,89 ± 0,04, ChatGPT 0,84 ± 0,02, Bard: 0,84 ± 0,02, Bing AI: 0,81 ± 0,02, (p < 0.001)), and actionability (mean PEMAT-A score ChatGPT: 0.86 ± 0.03, Bard: 0.85 ± 0.06, Bing AI: 0.81 ± 0.05, AAO website: 0.81 ± 0.06, (p < 0.001)) AAO website scored better than chatbots. Flesch-Kincaid readability ease analysis showed that Bard (55,5 ± 8,48) had the highest mean score, followed by AAO website (51,96 ± 12,46), Bing AI (41,77 ± 9,53), and ChatGPT (34,38 ± 9,75, (p < 0.001)). Conclusion: Chatbots have the potential to provide more detailed and accurate data than the AAO website. On the other hand, the AAO website has the advantage of providing information that is more understandable and practical. When patient preferences are not taken into account, generalised or biased information can decrease reliability. © 2025 Elsevier B.V., All rights reserved."
21,0,0.30340401588072435,"Background: Diabetes self-management education and support (DSMES) improves diabetes outcomes yet remains consistently underutilized. Chatbot technology offers the potential to increase access to and engagement in DSMES. Evidence supporting the case for chatbot uptake and efficacy in people with diabetes (PWD) is needed. Method: A diabetes education and support chatbot was deployed in a regional health care system. Adults with type 2 diabetes with an A1C of 8.0% to 8.9% and/or having recently completed a 12-week diabetes care management program were enrolled in a pilot program. Weekly chats included three elements: knowledge assessment, limited self-reporting of blood glucose data and medication taking behaviors, and education content (short videos and printable materials). A clinician facing dashboard identified need for escalation via flags based on participant responses. Data were collected to assess satisfaction, engagement, and preliminary glycemic outcomes. Results: Over 16 months, 150 PWD (majority above 50 years of age, female, and African American) were enrolled. The unenrollment rate was 5%. Most escalation flags (N = 128) were for hypoglycemia (41%), hyperglycemia (32%), and medication issues (11%). Overall satisfaction was high for chat content, length, and frequency, and 87% reported increased self-care confidence. Enrollees completing more than one chat had a mean drop in A1C of −1.04%, whereas those completing one chat or less had a mean increase in A1C of +0.09% (P =.008). Conclusion: This diabetes education chatbot pilot demonstrated PWD acceptability, satisfaction, and engagement plus preliminary evidence of self-care confidence and A1C improvement. Further efforts are needed to validate these promising early findings. © 2025 Elsevier B.V., All rights reserved."
22,1,0.653752393099969,"Background: Professional medical organizations publish policy statements that are used to impact legislation or address societal issues. Many organizations are nonpartisan, yet it is uncertain whether their policy statements balance liberal and conservative values. Objective: This study aims to evaluate the political viewpoint of policy statements from 6 influential medical organizations, including the American Academy of Pediatrics, American College of Surgeons, American Psychiatric Association, American College of Obstetricians and Gynecologists, American College of Physicians, and American Academy of Family Physicians. Methods: Between December 2023 and February 2024, policy statements from the 6 organizations were identified and evaluated using ChatGPT with GPT-4 to reduce bias. Each statement was pasted into a new ChatGPT session following the phrase “Does this text align with a liberal or conservative viewpoint?” Two authors reviewed each response and categorized the statement as liberal, probably liberal, neutral, probably conservative, or conservative. Results: One-third of policy statements (529/1592, 33.2%) were found to be aligned with a political ideology. Among these 529 statements, 516 (97.5%) were liberal or probably liberal and 13 (2.5%) were conservative or probably conservative. For each organization, among policy statements with a political leaning, the percentage of liberal or probably liberal statements was as follows: 100% (69/69) for the American Academy of Pediatrics, 100% (24/24) for the American College of Obstetricians and Gynecologists, 100% (12/12) for the American College of Surgeons, 99% (72/73) for the American Psychiatric Association, 97% (174/180) for the American Academy of Family Physicians, and 96% (165/171) for the American College of Physicians. Conclusions: One in 3 policy statements from these 6 professional organizations align with a partisan political viewpoint. Among these, positions are 40 times more likely to be liberal or probably liberal than conservative or probably conservative. Whether or not organizations are politically neutral and seek viewpoint diversity warrants further exploration. © 2025 Elsevier B.V., All rights reserved."
23,0,0.4688278692886426,"Background: Common mental disorders are prevalent in young people in low- and middle-income countries (LMICs). Digitally delivered interventions have the potential to overcome many structural and psychosocial barriers to mental health care. Chatbots have been proposed as one potentially acceptable and feasible method that may increase engagement. Yet, there is currently limited evidence for their efficacy in reducing psychological distress. This paper summarises the development of a World Health Organization digital psychological intervention for young people experiencing impairing psychological distress, developed in line with Human Centred Design (HCD) principles. Objective: This study refined and adapted a chatbot intervention initially developed for adolescents aged 15–18 years that was completed in consultation with end-users in this age group (N = 236), community members (N = 73), and psychology intervention experts (N = 9) across varied settings. The purpose was to create an adaptation fit for use by young adults aged 18–21 years experiencing psychological distress in Jordan. Methods: The current study followed a limited user-centred design process involving focus groups and key informant interviews with stakeholders including young adults aged 18–21 years (N = 33), community members (N = 13), and psychology intervention experts (N = 11). Iterative design development occurred throughout the cultural adaptation and refinement process. Results: There was a clear preference for a chatbot based intervention that included interactions with fictional characters with relatable problems. The chatbot content followed a transdiagnostic model that addressed common problems including low mood, stress and anger with reference to vocational, familial and interpersonal stressors that the target population commonly faced. It followed a non-AI decision tree format with multiple sessions and was designed to be adaptable for use in different countries with different populations and software systems. Prototype versions of the chatbot were well-received by adolescents (15–18-year-old) and young adults (18–21-year-old). Conclusions: This is the first report of the development of a chatbot intervention for adolescents and young adults in LMICs that was designed using a HCD framework. Systematic end-user engagement through all phases of the research aimed to make this intervention acceptable and useable for adolescents and young adults in a wide variety of settings. The chatbot is currently being tested in randomised controlled trials in Jordan and Lithuania. © 2025 Elsevier B.V., All rights reserved."
24,3,1.0,"Background: Artificially intelligent (AI) chatbots that deploy natural language processing and machine learning are becoming more common in health care to facilitate patient education and outreach; however, generative chatbots such as ChatGPT face challenges, as they can misinform and hallucinate. Health care systems are increasingly interested in using these tools for patient education, access to care, and self-management, but need reassurances that AI systems can be secure and credible. Objective: This study aimed to build a secure system that people can use to send SMS with questions about substance use, and which can be used to screen for substance use disorder (SUD). The system will rely on data transfer via third party vendors and will thus require reliable and trustworthy encryption of protected health information . Methods: We describe the process and specifications for building an AI chatbot that users can access to gain information on and screen for SUD from Be Well Texas, a clinical provider affiliated with the University of Texas Health Sciences Center at San Antonio. Results: The AI chatbot system uses natural language processing and machine learning to classify expert-curated content related to SUD. It illustrates how we can comply with best practices in HIPPA (Health Insurance Portability and Accountability Act) compliance in data encryption for data transfer and data at rest, while still offering a state-of-the-art system that uses dynamic, user-driven conversation to dialogue about SUD, screen for SUD and access SUD treatment services. Conclusions: Recent calls for attention to user-friendly design concerning user rights that honor digital rights and regulations for digital substance use offerings suggest that this study is timely and appropriate while still advancing the field of AI. © 2025 Elsevier B.V., All rights reserved."
25,-1,0.1342605133776537,"Maternal morbidity and mortality in India continue to be high in populations and places with limited access to quality health services. Major barriers include out of pocket expenditure, lack of autonomy and information around maternal health services and weak implementation of pro-poor policies. Addressing demand-side barriers and enablers is critical to improving healthcare uptake and healthcare adherence along the pregnancy-postnatal continuum. This paper describes three well known operational spaces, maternal health financing, digital health, and self-care interventions within the Indian context including pro-poor maternal health policies, mobile health ecosystems and networks, and self-care opportunities that promote women's knowledge, choice, self-efficacy, and autonomy. These are expanded on to identify additional opportunities to improve access to MH services. Finally, the authors describe a new digital health intervention using a chat-based digital support system that has the potential to reduce barriers that women face in seeking and receiving quality MH services in Assam and elsewhere. Future work on how to implement such a combined approach need to account for multiple contextual factors, including understanding the nature and success of national pro-poor MH policies in each state, how the public and private health systems function and interact, social determinants of health as well as engaging women in the process to improve maternal and newborn health outcomes. © 2025 Elsevier B.V., All rights reserved."
26,-1,0.2136210132298143,"Background: Nonadherence to medication is a key factor contributing to high heart failure (HF) rehospitalization rates. A conversational agent (CA) or chatbot is a technology that can enhance medication adherence by helping patients self-manage their medication routines at home. Objective: This study outlines the conception of a design method for developing a CA to support patients in medication adherence, utilizing design thinking as the primary process for gathering requirements, prototyping, and testing. We apply this design method to the ongoing development of Medical Assistance and Rehabilitation Intelligent Agent (MARIA), a rule-based CA. Methods: Following the design thinking process, at the ideation stage, we engaged a multidisciplinary group of stakeholders (patients and pharmacists) to elicit requirements for the early conception of MARIA. In collaboration with pharmacists, we structured MARIA’s dialogue into a workflow based on Adlerian therapy, a psychoeducational theory. At the testing stage, we conducted an observational study using the Wizard of Oz (WoZ) research method to simulate the MARIA prototype with 20 patient participants. This approach validated and refined our application of Adlerian therapy in the CA’s dialogue. We incorporated human-likeness and trust scoring into user satisfaction assessments after each WoZ session to evaluate MARIA’s feasibility and acceptance of medication adherence. Dialogue data collected through WoZ simulations were analyzed using a coding analysis technique. Results: Our design method for the CA revealed gaps in MARIA’s conception, including (1) handling negative responses, (2) appropriate use of emoticons to enhance human-likeness, (3) system feedback mechanisms during turn-taking delays, and (4) defining the extent to which a CA can communicate on behalf of a health care provider regarding medication adherence. Conclusions: The design thinking process provided interactive steps to involve users early in the development of a CA. Notably, the use of WoZ in an observational clinical protocol highlighted the following: (1) coding analysis offered guidelines for modeling CA dialogue with patient safety in mind; (2) incorporating human-likeness and trust in user satisfaction assessments provided insights into attributes that foster patient trust in a CA; and (3) the application of Adlerian therapy demonstrated its effectiveness in motivating patients with HF to adhere to medication within a CA framework. In conclusion, our method is valuable for modeling and validating CA interactions with patients, assessing system reliability, user expectations, and constraints. It can guide designers in leveraging existing CA technologies, such as ChatGPT or AWS Lex, for adaptation in health care settings. © 2025 Elsevier B.V., All rights reserved."
27,1,0.37644561712448393,"Background: Patients frequently resort to the internet to access information about cancer. However, these websites often lack content accuracy and readability. Recently, ChatGPT, an artificial intelligence–powered chatbot, has signified a potential paradigm shift in how patients with cancer can access vast amounts of medical information, including insights into radiotherapy. However, the quality of the information provided by ChatGPT remains unclear. This is particularly significant given the general public’s limited knowledge of this treatment and concerns about its possible side effects. Furthermore, evaluating the quality of responses is crucial, as misinformation can foster a false sense of knowledge and security, lead to noncompliance, and result in delays in receiving appropriate treatment. Objective: This study aims to evaluate the quality and reliability of ChatGPT’s responses to common patient queries about radiotherapy, comparing the performance of ChatGPT’s two versions: GPT-3.5 and GPT-4. Methods: We selected 40 commonly asked radiotherapy questions and entered the queries in both versions of ChatGPT. Response quality and reliability were evaluated by 16 radiotherapy experts using the General Quality Score (GQS), a 5-point Likert scale, with the median GQS determined based on the experts’ ratings. Consistency and similarity of responses were assessed using the cosine similarity score, which ranges from 0 (complete dissimilarity) to 1 (complete similarity). Readability was analyzed using the Flesch Reading Ease Score, ranging from 0 to 100, and the Flesch-Kincaid Grade Level, reflecting the average number of years of education required for comprehension. Statistical analyses were performed using the Mann-Whitney test and effect size, with results deemed significant at a 5% level (P=.05). To assess agreement between experts, Krippendorff α and Fleiss κ were used. Results: GPT-4 demonstrated superior performance, with a higher GQS and a lower number of scores of 1 and 2, compared to GPT-3.5. The Mann-Whitney test revealed statistically significant differences in some questions, with GPT-4 generally receiving higher ratings. The median (IQR) cosine similarity score indicated substantial similarity (0.81, IQR 0.05) and consistency in the responses of both versions (GPT-3.5: 0.85, IQR 0.04; GPT-4: 0.83, IQR 0.04). Readability scores for both versions were considered college level, with GPT-4 scoring slightly better in the Flesch Reading Ease Score (34.61) and Flesch-Kincaid Grade Level (12.32) compared to GPT-3.5 (32.98 and 13.32, respectively). Responses by both versions were deemed challenging for the general public. Conclusions: Both GPT-3.5 and GPT-4 demonstrated having the capability to address radiotherapy concepts, with GPT-4 showing superior performance. However, both models present readability challenges for the general population. Although ChatGPT demonstrates potential as a valuable resource for addressing common patient queries related to radiotherapy, it is imperative to acknowledge its limitations, including the risks of misinformation and readability issues. In addition, its implementation should be supported by strategies to enhance accessibility and readability. © 2025 Elsevier B.V., All rights reserved."
28,0,1.0,"Background: Procrastination negatively affects university students’ academics and mental health. Traditional time management apps lack therapeutic strategies like cognitive behavioral therapy to address procrastination’s psychological aspects. Therefore, we developed and integrated a semigenerative chatbot named Moa into a to-do app. Objective: We intended to determine the benefits of the Moa-integrated to-do app over the app without Moa by verifying behavioral and cognitive changes, analyzing the influence of engagement patterns on the changes, and exploring the user experience. Methods: The developed chatbot Moa guided users over 30 days in terms of self-observation, strategy establishment, and reflection. The architecture comprised response-generating and procrastination factor–detection algorithms. A pilot randomized controlled trial was conducted with 85 participants (n=37, 44% female; n=48, 56% male) from a university in South Korea. The control group used a to-do app without Moa, whereas the treatment group used a fully automated Moa-integrated app. The Irrational Procrastination Scale, Pure Procrastination Scale, Time Management Behavior Scale, and the Perceived Stress Scale were examined using linear mixed models with repeated measurements obtained before (T0) and after (T1) 1-month use and after 2-month use (T2) to assess the changes in irrational procrastination, pure procrastination, time management and behavior, academic self-regulation, and stress. Intervention engagement, divided into “high,” “middle” and “low” clusters, was quantified using app access and use of the to-do list and grouped using k-means clustering. In addition, changes in the psychological scale scores between the control and treatment groups were analyzed within each cluster. User experience was quantified based on the usability, feasibility, and acceptability of and satisfaction with the app, whereas thematic analysis explored the users’ subjective responses to app use. Results: In total, 75 participants completed the study. The interaction of time × procrastination was significant during the required use period (P=.01). The post hoc test indicated a significant improvement from T0 to T1 in the Time Management Behavior Scale and Perceived Stress Scale scores only in the treatment group (P<.001 and P=.009). The changes in Pure Procrastination Scale score after the required use period were significant in all clusters except for the low cluster of the control group. The high cluster in the treatment group exhibited a significant change in the Irrational Procrastination Scale after Bonferroni correction (P=.046). Usability was determined to be good in the treatment group (mean score 72.8, SD 16.0), and acceptability was higher than in the control group (P=.03). Evaluation of user experience indicated that only the participants in the treatment group achieved self-reflection and experienced an alliance with the app. Conclusions: The chatbot-integrated app demonstrated greater efficacy in influencing user behavior providing psychological support. It will serve as a valuable tool for managing procrastination and stress together. © 2025 Elsevier B.V., All rights reserved."
29,5,1.0,"Background: Telehealth interventions are effective in hypertension management. However, the cost-effectiveness of using them for managing patients with hypertension remains inconclusive. Further research is required to understand the effectiveness and cost-effectiveness in the real-world setting. Objective: The Primary Technology-Enhanced Care for Hypertension (PTEC-HT) scaling program, a telehealth intervention for hypertension management, is currently being scaled nationwide in Singapore. The program comprises remote blood pressure (BP) monitoring at home, health care team support through teleconsultations, and in-app support with a digital chatbot. This study aimed to evaluate the program’s effectiveness and cost-effectiveness. Methods: For patients under the PTEC-HT scaling program, BP readings over 6 months and 12 months, age, and gender were collected within the program. Health care use, health care cost, and patient ethnicity were extracted from the National Healthcare Group Polyclinics. For patients in the usual care group, demographic information, clinical data, health care use, and health care costs were extracted from the national claims records. Comparing the PTEC-HT scaling program with usual care, a trial-based economic evaluation using patient-level data was conducted to examine the effectiveness and cost-effectiveness over time horizons of 6 months and 12 months. The health care system’s perspective was adopted. Regression analysis and exact matching were used to control for the differences between the PTEC-HT group and the usual care group. Results: For the 6-month analysis, 427 patients were included in the PTEC-HT group, and 64,679 patients were included in the usual care group. For the 12-month analysis, 338 patients were included in the PTEC-HT group, and 7324 patients were included in the usual care group. Using exact matching plus regression, in the 6-month analysis, the probability of having controlled BP was 13.5% (95% CI 6.3%-20.7%) higher for the PTEC-HT group compared to the usual care group. In the 12-month analysis, the probability of having controlled BP was 16% (95% CI 10.7%-21.3%) higher for the PTEC-HT group. Without considering the cost of the BP machine and program maintenance cost, the direct medical cost was S $57.7 (95% CI 54.4-61.0; a currency exchange rate of S $1=US $0.74 was applicable;) lower per patient for the PTEC-HT group in the 6-month analysis and S $170.9 (95% CI 151.9-189.9) lower per patient for the PTEC-HT group in the 12-month analysis. With the cost of the BP machine and program maintenance considered, compared to usual care, the PTEC-HT program reached breakeven at around the sixth month and saved S $52.6 (95% CI 33.6-71.6) per patient at the 12th month. Conclusions: Implemented in a real-world setting in Singapore, our study showed that the PTEC-HT scaling program is more effective in controlling BP status with lower cost compared to the usual care over 12 months. © 2025 Elsevier B.V., All rights reserved."
30,-1,0.13096150853541855,"Background: Maternal mental health disorders are prevalent, yet many individuals do not receive adequate support due to stigma, financial constraints, and limited access to care. Digital interventions, particularly chatbots, have the potential to provide scalable, low-cost support, but few are tailored specifically to the needs of perinatal individuals. Objective: This study aimed to (1) design and develop Moment for Parents, a tailored chatbot for perinatal mental health education and support, and (2) assess usability through engagement, usage patterns, and user experience. Methods: This study used a human-centered design to develop Moment for Parents, a rules-based chatbot to support pregnant and postpartum individuals. In phase 1, ethnographic interviews (n=43) explored user needs to inform chatbot development. In phase 2, a total of 108 pregnant and postpartum individuals were recruited to participate in a pilot test and had unrestricted access to the chatbot. Engagement was tracked over 8 months to assess usage patterns and re-engagement rates. After 1 month, participants completed a usability, relevance, and satisfaction survey, providing key insights for refining the chatbot. Results: Key themes that came from the ethnographic interviews in phase 1 included the need for trusted resources, emotional support, and better mental health guidance. These insights informed chatbot content, including mood-based exercises and coping strategies. Re-engagement was high (69/108, 63.9%), meaning users who had stopped interacting for at least 1 week returned to the chatbot at least once. A large proportion (28/69, 40.6%) re-engaged 3 or more times. Overall, 28/30 (93.3%) found the chatbot relevant for them, though some noted repetitive content and limited response options. Conclusions: The Moment for Parents chatbot successfully engaged pregnant and postpartum individuals with higher-than-typical retention and re-engagement patterns. The findings underscore the importance of flexible, mood-based digital support tailored to perinatal needs. Future research should examine how intermittent chatbot use influences mental health outcomes and refine content delivery to enhance long-term engagement and effectiveness. © 2025 Elsevier B.V., All rights reserved."
31,0,0.433245323958176,"Introduction: Non-hostile humour and laughter have been known for therapeutic benefits in an individual’s mental health and wellbeing. To this end, we evaluated the Self-Initiated Humour Protocol (SIHP), a new type of self-administrable laughter intervention that utilises spontaneous and self-induced laughter. Rooted in the core principles of the Self-Attachment Technique—in which an individual creates an affectional bond with their childhood self as represented by their childhood photo or personalised childhood avatar—SIHP provides an algorithmic framework for individuals to learn to laugh in a non-hostile manner and develop a sense of humour in all possible life contexts. This allows SIHP to be self-administered by interacting with an AI agent. Methods: An 8-week intervention was conducted with N = 27 adult participants. Exclusion criteria: severe depression or anxiety (PHQ-9 and GAD-7 scores above 15). Participants’ measurements were collected in the areas of wellbeing, use of different humour styles, emotional self-regulation, self-compassion and psychological capital, and analysed to understand any changes over time. Measurements were taken immediately before, after the intervention, and at the 3-month follow-up. Throughout the intervention, participants were required to practise SIHP 20 min a day with the aid of an emotionally intelligent chatbot and their personalised child avatar in virtual reality (VR). Results: Analysis of results at the 3-month follow-up showed significant improvements in the primary outcome of wellbeing with large effect size ( (Formula presented.) ), as well as a range of secondary outcomes with large effect sizes, self-compassion ( (Formula presented.) ), use of self-enhancing humour ( (Formula presented.) ), and emotion regulation ( (Formula presented.) ); the results also showed improvement to participant’s psychological capital with moderate effect size ( (Formula presented.) ). Discussion: This study shows the potential for the practice of SIHP as supported by an emotionally intelligent chatbot and personalised child avatar to have medium-term positive effects, which should be validated through future randomised trials. © 2025 Elsevier B.V., All rights reserved."
32,-1,0.1912412505013438,"Background: The worldwide introduction of ChatGPT in November 2022 may have changed how its users perceive and interact with other chatbots. This possibility may confound the comparison of responses to pre-ChatGPT and post-ChatGPT iterations of pre-existing chatbots, in turn affecting the direction of their evolution. Before the release of ChatGPT, we created a therapeutic chatbot, MIBot, whose goal is to use motivational interviewing to guide smokers toward making the decision to quit smoking. We were concerned that measurements going forward would not be comparable to those in the past, impacting the evaluation of future changes to the chatbot. Objective: The aim of the study is to explore changes in how users interact with MIBot after the release of ChatGPT and examine the relationship between these changes and users’ familiarity with ChatGPT. Methods: We compared user interactions with MIBot prior to ChatGPT’s release and 6 months after the release. Participants (N=143) were recruited through a web-based platform in November of 2022, prior to the release of ChatGPT, to converse with MIBot, in an experiment we refer to as MIBot (version 5.2). In May 2023, a set of (n=129) different participants were recruited to interact with the same version of MIBot and asked additional questions about their familiarity with ChatGPT, in the experiment called MIBot (version 5.2A). We used the Mann-Whitney U test to compare metrics between cohorts and Spearman rank correlation to assess relationships between familiarity with ChatGPT and other metrics within the MIBot (version 5.2A) cohort. Results: In total, 83(64.3%) participants in the MIBot (version 5.2A) cohort had used ChatGPT, with 66 (51.2%) using it on a regular basis. Satisfaction with MIBot was significantly lower in the post-ChatGPT cohort (U=11,331.0; P=.001), driven by a decrease in perceived empathy as measured by the Average Consultation and Relational Empathy Measure (U=10,838.0; P=.01). Familiarity with ChatGPT was positively correlated with average response length (ρ=0.181; P=.04) and change in perceived importance of quitting smoking (ρ=0.296; P<.001). Conclusions: The widespread reach of ChatGPT has changed how users interact with MIBot. Post-ChatGPT users are less satisfied with MIBot overall, particularly in terms of perceived empathy. However, users with greater familiarity with ChatGPT provide longer responses and demonstrated a greater increase in their perceived importance of quitting smoking after a session with MIBot. These findings suggest the need for chatbot developers to adapt to evolving user expectations in the era of advanced generative artificial intelligence. © 2025 Elsevier B.V., All rights reserved."
33,-1,0.24917279858171448,"Background: Large language models, exemplified by ChatGPT, have reached a level of sophistication that makes distinguishing between human- and artificial intelligence (AI)–generated texts increasingly challenging. This has raised concerns in academia, particularly in medicine, where the accuracy and authenticity of written work are paramount. Objective: This semirandomized controlled study aims to examine the ability of 2 blinded expert groups with different levels of content familiarity—medical professionals and humanities scholars with expertise in textual analysis—to distinguish between longer scientific texts in German written by medical students and those generated by ChatGPT. Additionally, the study sought to analyze the reasoning behind their identification choices, particularly the role of content familiarity and linguistic features. Methods: Between May and August 2023, a total of 35 experts (medical: n=22; humanities: n=13) were each presented with 2 pairs of texts on different medical topics. Each pair had similar content and structure: 1 text was written by a medical student, and the other was generated by ChatGPT (version 3.5, March 2023). Experts were asked to identify the AI-generated text and justify their choice. These justifications were analyzed through a multistage, interdisciplinary qualitative analysis to identify relevant textual features. Before unblinding, experts rated each text on 6 characteristics: linguistic fluency and spelling/grammatical accuracy, scientific quality, logical coherence, expression of knowledge limitations, formulation of future research questions, and citation quality. Univariate tests and multivariate logistic regression analyses were used to examine associations between participants’ characteristics, their stated reasons for author identification, and the likelihood of correctly determining a text’s authorship. Results: Overall, in 48 out of 69 (70%) decision rounds, participants accurately identified the AI-generated texts, with minimal difference between groups (medical: 31/43, 72%; humanities: 17/26, 65%; odds ratio [OR] 1.37, 95% CI 0.5-3.9). While content errors had little impact on identification accuracy, stylistic features—particularly redundancy (OR 6.90, 95% CI 1.01-47.1), repetition (OR 8.05, 95% CI 1.25-51.7), and thread/coherence (OR 6.62, 95% CI 1.25-35.2)—played a crucial role in participants’ decisions to identify a text as AI-generated. Conclusions: The findings suggest that both medical and humanities experts were able to identify ChatGPT-generated texts in medical contexts, with their decisions largely based on linguistic attributes. The accuracy of identification appears to be independent of experts’ familiarity with the text content. As the decision-making process primarily relies on linguistic attributes—such as stylistic features and text coherence—further quasi-experimental studies using texts from other academic disciplines should be conducted to determine whether instructions based on these features can enhance lecturers’ ability to distinguish between student-authored and AI-generated work. © 2025 Elsevier B.V., All rights reserved."
34,-1,0.23973791538332556,"Introduction: Caregivers of patients with end-stage kidney disease (ESKD) face significant challenges that contribute to caregiver burden, negatively impacting their physical, psychological, social, and financial well-being. With the growing prevalence of chronic diseases and an aging population, there is an urgent need for accessible and scalable solutions to detect and address caregiver burden. Artificial Intelligence (AI) chatbots using natural language processing (NLP) have shown promise in providing mental health support and monitoring through natural conversations. This study will contribute to research and clinical practice by: (1) validating a novel approach for early detection of caregiver burden through NLP, (2) analyzing the feasibility of AI-powered chatbots for continuous caregiver monitoring, and (3) informing the development of scalable, accessible tools to identify at-risk caregivers. Methods and analysis: This protocol for the mixed methods aims to evaluate the feasibility, acceptability, and preliminary effectiveness of BOTANIC (Burden Observation and Timely Aid for Navigating Informal Caregiving), an AI-powered chatbot for early detection of caregiver burden. A single-center validation study will be conducted at Alexandra Hospital, Singapore. Twenty primary caregivers of ESKD patients will be recruited to use BOTANIC for 12 weeks. BOTANIC, developed using Python and open-source libraries, will integrate with Telegram and utilize advanced NLP techniques to analyze caregiver conversations and detect signs of burden. The NLP algorithm will analyze conversations to generate burden scores at baseline and at 12 weeks. Participants will also complete baseline and 12-week assessments using validated questionnaires including the Zarit Burden Interview (ZBI), Patient Health Questionnaire-9 (PHQ-9), and Generalized Anxiety Disorder-7 (GAD-7). Primary outcomes include concordance between caregiver burden levels detected by the NLP algorithm and validated assessment scores at both timepoints. Secondary outcomes include user engagement metrics and system satisfaction. Semi-structured interviews will explore participants’ experiences with the chatbot. Quantitative data will be analyzed using descriptive statistics and appropriate statistical tests such as paired t-tests or Wilcoxon signed-rank tests, while qualitative data will undergo thematic analysis. Ethics and dissemination: The study has been approved by the NHG Domain Specific Review Board. Findings will be published in peer-reviewed journals, presented at conferences, and used to inform the development of larger-scale trials of AI-powered caregiver support interventions. © 2025 Elsevier B.V., All rights reserved."
35,0,0.6487624825188429,"Background: Depression and anxiety are a leading cause of disability worldwide and often start during adolescence and young adulthood. The majority of young people live in low- and middle-income countries where there is a lack of mental health services. The World Health Organization (WHO) developed a guided, nonartificial intelligence chatbot intervention called Scalable Technology for Adolescents and youth to Reduce Stress (STARS) to reduce symptoms of depression and anxiety among young people affected by adversity. Objective: The objective of this study was to evaluate the feasibility of the STARS intervention and study procedures among young people in Jordan. Methods: A 2-arm, single-blind, feasibility randomized controlled trial was conducted among 60 young people aged 18 years to 21 years living in Jordan with self-reported elevated levels of psychological distress. Immediately after baseline, participants were randomized 1:1 into the STARS intervention or enhanced care as usual (ECAU). STARS consisted of 10 lessons in which participants interacted with a chatbot and learned several cognitive behavioral therapy strategies, with optional guidance by a trained e-helper through 5 weekly phone calls. ECAU consisted of a static web page providing basic psychoeducation. Online questionnaires were administered at baseline (week 0) and postassessment (week 8) to assess depression (Hopkins Symptom Checklist-25 [HSCL-25]), anxiety (HSCL-25), functional impairment (WHO Disability Assessment Schedule [WHODAS] 2.0), psychological well-being (WHO-Five Well-Being Index [WHO-5]), and agency (State Hope Scale). Process evaluation interviews with stakeholders were conducted after the postassessment. Results: Participants were recruited in December 2022 and January 2023. Of 700 screening website visits, 160 participants were eligible, and 60 participants (mean age 19.7, SD 1.16 years; 49/60, 82% female) continued to baseline and were randomized into STARS (n=30) or ECAU (n=30). Of those who received STARS, 37% (11/30) completed at least 8 chatbot lessons, and 13% (4/30) completed all 5 support calls. The research protocol functioned well in terms of balanced randomization, high retention at postassessment (48/60, 80%), and good psychometric properties of the online questionnaires. Process evaluation interviews with STARS participants, ECAU participants, e-helpers, and the clinical supervisor indicated the acceptability of the study procedures and the STARS and ECAU conditions and highlighted several aspects that could be improved, including the e-helper support and features of the STARS chatbot. Conclusions: This study demonstrated the feasibility and acceptability of the STARS intervention and research procedures. A fully powered, definitive randomized controlled trial will be conducted to evaluate the effectiveness of STARS. © 2025 Elsevier B.V., All rights reserved."
36,1,0.27666963620894536,"Purpose: The diagnosis and management of prostate cancer (PCa), the second most common cancer in men worldwide, are highly complex. Hence, patients often seek knowledge through additional resources, including AI chatbots such as ChatGPT and Google Bard. This study aimed to evaluate the performance of LLMs in providing education on PCa. Methods: Common patient questions about PCa were collected from reliable educational websites and evaluated for accuracy, comprehensiveness, readability, and stability by two independent board-certified urologists, with a third resolving discrepancy. Accuracy was measured on a 3-point scale, comprehensiveness was measured on a 5-point Likert scale, and readability was measured using the Flesch Reading Ease (FRE) score and Flesch–Kincaid FK Grade Level. Results: A total of 52 questions on general knowledge, diagnosis, treatment, and prevention of PCa were provided to three LLMs. Although there was no significant difference in the overall accuracy of LLMs, ChatGPT-3.5 demonstrated superiority over the other LLMs in terms of general knowledge of PCa (p = 0.018). ChatGPT-4 achieved greater overall comprehensiveness than ChatGPT-3.5 and Bard (p = 0.028). For readability, Bard generated simpler sentences with the highest FRE score (54.7, p < 0.001) and lowest FK reading level (10.2, p < 0.001). Conclusion: ChatGPT-3.5, ChatGPT-4 and Bard generate accurate, comprehensive, and easily readable PCa material. These AI models might not replace healthcare professionals but can assist in patient education and guidance. © 2024 Elsevier B.V., All rights reserved."
37,-1,0.31338533281618014,"Clinicians and patients seeking electronic health applications face challenges in selecting effective solutions due to a high market failure rate. Conversational agent applications (“chatbots”) show promise in increasing healthcare user engagement by creating bonds between the applications and users. It is unclear if chatbots improve patient adherence or if past trends to include chatbots in electronic health applications were due to technology hype dynamics and competitive pressure to innovate. We conducted a systematic literature review using Preferred Reporting Items for Systematic reviews and Meta-Analyses methodology on health chatbot randomized control trials. The goal of this review was to identify if user engagement indicators are published in eHealth chatbot studies. A meta-analysis examined patient clinical trial retention of chatbot apps. The results showed no chatbot arm patient retention effect. The small number of studies suggests a need for ongoing eHealth chatbot research, especially given the claims regarding their effectiveness made outside the scientific literatures. © 2024 Elsevier B.V., All rights reserved."
38,1,0.6303757728278206,"Background: Chat Generative Pretrained Transformer (ChatGPT), a generative artificial intelligence chatbot, may have broad applications in healthcare delivery and patient education due to its ability to provide human-like responses to a wide range of patient queries. However, there is limited evidence regarding its ability to provide reliable and useful information on orthopaedic procedures. This study seeks to evaluate the accuracy and relevance of responses provided by ChatGPT to frequently asked questions (FAQs) regarding total knee replacement (TKR). Methods: A list of 50 clinically-relevant FAQs regarding TKR was collated. Each question was individually entered as a prompt to ChatGPT (version 3.5), and the first response generated was recorded. Responses were then reviewed by two independent orthopaedic surgeons and graded on a Likert scale for their factual accuracy and relevance. These responses were then classified into accurate versus inaccurate and relevant versus irrelevant responses using preset thresholds on the Likert scale. Results: Most responses were accurate, while all responses were relevant. Of the 50 FAQs, 44/50 (88%) of ChatGPT responses were classified as accurate, achieving a mean Likert grade of 4.6/5 for factual accuracy. On the other hand, 50/50 (100%) of responses were classified as relevant, achieving a mean Likert grade of 4.9/5 for relevance. Conclusion: ChatGPT performed well in providing accurate and relevant responses to FAQs regarding TKR, demonstrating great potential as a tool for patient education. However, it is not infallible and can occasionally provide inaccurate medical information. Patients and clinicians intending to utilize this technology should be mindful of its limitations and ensure adequate supervision and verification of information provided. © 2024 Elsevier B.V., All rights reserved."
39,-1,0.24169900179318712,"Introduction: ChatGPT, a recently released chatbot from OpenAI, has found applications in various aspects of life, including academic research. This study investigated the knowledge, perceptions, and attitudes of researchers towards using ChatGPT and other chatbots in academic research. Methods: A pre-designed, self-administered survey using Google Forms was employed to conduct the study. The questionnaire assessed participants’ knowledge of ChatGPT and other chatbots, their awareness of current chatbot and artificial intelligence (AI) applications, and their attitudes towards ChatGPT and its potential research uses. Results: Two hundred researchers participated in the survey. A majority were female (57.5%), and over two-thirds belonged to the medical field (68%). While 67% had heard of ChatGPT, only 11.5% had employed it in their research, primarily for rephrasing paragraphs and finding references. Interestingly, over one-third supported the notion of listing ChatGPT as an author in scientific publications. Concerns emerged regarding AI’s potential to automate researcher tasks, particularly in language editing, statistics, and data analysis. Additionally, roughly half expressed ethical concerns about using AI applications in scientific research. Conclusion: The increasing use of chatbots in academic research necessitates thoughtful regulation that balances potential benefits with inherent limitations and potential risks. Chatbots should not be considered authors of scientific publications but rather assistants to researchers during manuscript preparation and review. Researchers should be equipped with proper training to utilize chatbots and other AI tools effectively and ethically. © 2024 Elsevier B.V., All rights reserved."
40,0,1.0,"Background: Digital mental health interventions (DMHIs) may reduce treatment access issues for those experiencing depressive and/or anxiety symptoms. DMHIs that incorporate relational agents may offer unique ways to engage and respond to users and to potentially help reduce provider burden. This study tested Woebot for Mood & Anxiety (W-MA-02), a DMHI that employs Woebot, a relational agent that incorporates elements of several evidence-based psychotherapies, among those with baseline clinical levels of depressive or anxiety symptoms. Changes in self-reported depressive and anxiety symptoms over 8 weeks were measured, along with the association between each of these outcomes and demographic and clinical characteristics. Methods: This exploratory, single-arm, 8-week study of 256 adults yielded non-mutually exclusive subsamples with either clinical levels of depressive or anxiety symptoms at baseline. Week 8 Patient Health Questionnaire-8 (PHQ-8) changes were measured in the depressive subsample (PHQ-8 ≥ 10). Week 8 Generalized Anxiety Disorder-7 (GAD-7) changes were measured in the anxiety subsample (GAD-7 ≥ 10). Demographic and clinical characteristics were examined in association with symptom changes via bivariate and multiple regression models adjusted for W-MA-02 utilization. Characteristics included age, sex at birth, race/ethnicity, marital status, education, sexual orientation, employment status, health insurance, baseline levels of depressive and anxiety symptoms, and concurrent psychotherapeutic or psychotropic medication treatments during the study. Results: Both the depressive and anxiety subsamples were predominantly female, educated, non-Hispanic white, and averaged 38 and 37 years of age, respectively. The depressive subsample had significant reductions in depressive symptoms at Week 8 (mean change =—7.28, SD = 5.91, Cohen’s d = -1.23, p < 0.01); the anxiety subsample had significant reductions in anxiety symptoms at Week 8 (mean change = -7.45, SD = 5.99, Cohen’s d = -1.24, p < 0.01). No significant associations were found between sex at birth, age, employment status, educational background and Week 8 symptom changes. Significant associations between depressive and anxiety symptom outcomes and sexual orientation, marital status, concurrent mental health treatment, and baseline symptom severity were found. Conclusions: The present study suggests early promise for W-MA-02 as an intervention for depression and/or anxiety symptoms. Although exploratory in nature, this study revealed potential user characteristics associated with outcomes that can be investigated in future studies. Trial Registration: This study was retrospectively registered on ClinicalTrials.gov (#NCT05672745) on January 5th, 2023. © 2024 Elsevier B.V., All rights reserved."
41,-1,0.17106418188824032,"Objective: (1) Primary: Determine healthcare professionals' knowledge, attitudes, and practices (KAP) related to AI Chatbots. (2) Secondary: Assess healthcare professionals' perspectives on using Chatbots as teaching tools and implementing them in the Competency-Based Medical Education curriculum. Methods: An online questionnaire was distributed to 132 health professionals, including faculty and CRMIs, through Google Forms. Data on artificial intelligence (AI)-related KAP and barriers were collected following IHEC approval. The KAP scores, along with the relationship between categorical variables - such as population type and the use of AI Chatbots - were analyzed using Statistical Package for the Social Sciences software. Results: The study revealed that participants had a moderate level of knowledge about AI Chatbots. Attitudes were mixed, with some skepticism about AI replacing human teachers but also recognition of its benefits. Most participants infrequently used AI Chatbots in their daily activities. Barriers to usage included lack of knowledge, limited access, time constraints, and curriculum gaps. Conclusion: This study underscored the need to enhance medical education with AI topics and address existing barriers. It is crucial to better prepare health professionals for AI integration to leverage AI's potential for improving patient care and training. © 2024 Elsevier B.V., All rights reserved."
42,1,0.2775381448381802,"Background and objective: Artificial intelligence (AI)-powered conversational agents are increasingly finding application in health care, as these can provide patient education at any time. However, their effectiveness in medical settings remains largely unexplored. This study aimed to assess the impact of the chatbot “PROState cancer Conversational Agent” (PROSCA), which was trained to provide validated support from diagnostic tests to treatment options for men facing prostate cancer (PC) diagnosis. Methods: The chatbot PROSCA, developed by urologists at Heidelberg University Hospital and SAP SE, was evaluated through a randomized controlled trial (RCT). Patients were assigned to either the chatbot group, receiving additional access to PROSCA alongside standard information by urologists, or the control group (1:1), receiving standard information. A total of 112 men were included, of whom 103 gave feedback at study completion. Key findings and limitations: Over time, patients’ information needs decreased significantly more in the chatbot group than in the control group (p = 0.035). In the chatbot group, 43/54 men (79.6%) used PROSCA, and all of them found it easy to use. Of the men, 71.4% agreed that the chatbot improved their informedness about PC and 90.7% would like to use PROSCA again. Limitations are study sample size, single-center design, and specific clinical application. Conclusions and clinical implications: With the introduction of the PROSCA chatbot, we created and evaluated an innovative, evidence-based AI health information tool as an additional source of information for PC. Our RCT results showed significant benefits of the chatbot in reducing patients’ information needs and enhancing their understanding of PC. This easy-to-use AI tool provides accurate, timely, and accessible support, demonstrating its value in the PC diagnosis process. Future steps include further customization of the chatbot's responses and integration with the existing health care systems to maximize its impact on patient outcomes. Patient summary: This study evaluated an artificial intelligence–powered chatbot—PROSCA, a digital tool designed to support men facing prostate cancer diagnosis by providing validated information from diagnosis to treatment. Results showed that patients who used the chatbot as an additional tool felt better informed than those who received standard information from urologists. The majority of users appreciated the ease of use of the chatbot and expressed a desire to use it again; this suggests that PROSCA could be a valuable resource to improve patient understanding in prostate cancer diagnosis. © 2024 Elsevier B.V., All rights reserved."
43,1,0.7463062382848632,"Objectives: Laboratory medical reports are often not intuitively comprehensible to non-medical professionals. Given their recent advancements, easier accessibility and remarkable performance on medical licensing exams, patients are therefore likely to turn to artificial intelligence-based chatbots to understand their laboratory results. However, empirical studies assessing the efficacy of these chatbots in responding to real-life patient queries regarding laboratory medicine are scarce. Methods: Thus, this investigation included 100 patient inquiries from an online health forum, specifically addressing Complete Blood Count interpretation. The aim was to evaluate the proficiency of three artificial intelligence-based chatbots (ChatGPT, Gemini and Le Chat) against the online responses from certified physicians. Results: The findings revealed that the chatbots' interpretations of laboratory results were inferior to those from online medical professionals. While the chatbots exhibited a higher degree of empathetic communication, they frequently produced erroneous or overly generalized responses to complex patient questions. The appropriateness of chatbot responses ranged from 51 to 64%, with 22 to 33% of responses overestimating patient conditions. A notable positive aspect was the chatbots' consistent inclusion of disclaimers regarding its non-medical nature and recommendations to seek professional medical advice. Conclusions: The chatbots' interpretations of laboratory results from real patient queries highlight a dangerous dichotomy - a perceived trustworthiness potentially obscuring factual inaccuracies. Given the growing inclination towards self-diagnosis using AI platforms, further research and improvement of these chatbots is imperative to increase patients' awareness and avoid future burdens on the healthcare system. © 2024 Elsevier B.V., All rights reserved."
44,3,1.0,"Background: Black patients with cancer are less likely to receive precision cancer treatments than White patients and are underrepresented in clinical trials. To address these disparities, the study aimed to develop and pilot-test a digital intervention to improve Black patients’ knowledge about precision oncology and clinical trials, empower patients to increase relevant discussion, and promote informed decision-making. Methods: A community-engaged approach, including a Community Advisory Board and two rounds of key informant interviews with Black patients with cancer, their relatives, and providers (n = 48) was used to develop and refine the multimedia digital intervention. Thematic analysis was conducted for qualitative data. The intervention was then pilot-tested with 30 Black patients with cancer to assess feasibility, acceptability, appropriateness, knowledge, decision self-efficacy, and patient empowerment; Wilcoxon matched pairs signed-rank test was used to analyze quantitative data. Results: The digital tool was found to be feasible, acceptable, and culturally appropriate. Key informants shared their preferences and recommendations for the digital intervention and helped improve cultural appropriateness through user and usability testing. In the pilot test, appreciable improvement was found in participants’ knowledge about precision oncology (z = –2.04, p =.052), knowledge about clinical trials (z = –3.14, p =.001), and decisional self-efficacy for targeted/immune therapy (z = –1.96, p =.0495). Conclusions: The digital intervention could be a promising interactive decision-support tool for increasing Black patients’ participation in clinical trials and receipt of precision treatments, including immunotherapy. Its use in clinical practice may reduce disparities in oncology care and research. Plain Language Summary: We developed a digital interactive decision support tool for Black patients with cancer by convening a Community Advisory Board and conducting interviews with Black patients with cancer, their relatives, and providers. We then pilot-tested the intervention with newly diagnosed Black patients with cancer and found appreciable improvement in participants’ knowledge about precision oncology, knowledge about clinical trials, and confidence in making decisions for targeted/immune therapy. Our digital tool has great potential to be an affordable and scalable solution for empowering and educating Black patients with cancer to help them make informed decisions about precision oncology and clinical trials and ultimately reducing racial disparities. © 2024 Elsevier B.V., All rights reserved."
45,1,0.5030159911027219,"Diabetic foot ulcers (DFUs) are a growing public health problem, paralleling the increasing incidence of diabetes. While prevention is most effective treatment for DFUs, challenge remains on selecting the optimal treatment in cases with DFUs. Health sciences have greatly benefited from the integration of artificial intelligence (AI) applications across various fields. Regarding amputations in DFUs, both literature and clinical practice have mainly focused on strategies to prevent amputation and identify avoidable risk factor. However, there are very limited data on assistive parameters/tools that can be used to determine the level of amputation. This study investigated how well ChatGPT, with its lately released version 4o, matches the amputation level selection of an experienced team in this field. For this purpose, clinical photographs from patients who underwent amputations due to diabetic foot ulcers between May 2023 and May 2024 were submitted to the ChatGPT-4o program. The AI was tasked with recommending an appropriate amputation level based on these clinical photographs. Data from a total of 60 patients were analysed, with a median age of 64.5 years (range: 41–91). According to the Wagner Classification, 32 patients (53.3%) had grade 4 ulcers, 16 patients (26.6%) had grade 5 ulcers, 10 patients (16.6%) had grade 3 ulcers and 2 patients (3.3%) had grade 2 ulcers. A one-to-one correspondence between the AI tool's recommended amputation level and the level actually performed was observed in 50 out of 60 cases (83.3%). In the remaining 10 cases, discrepancies were noted, with the AI consistently recommending a more proximal level of amputation than what was performed. The inter-rater agreement analysis between the actual surgeries and the AI tool's recommendations yielded a Cohen's kappa coefficient of 0.808 (SD: 0.055, 95% CI: 0.701–0.916), indicating substantial agreement. Relying solely on clinical photographs, ChatGPT-4.0 demonstrates decisions that are largely consistent with those of an experienced team in determining the optimal level of amputation for DFUs, with the exception of hindfoot amputations. © 2024 Elsevier B.V., All rights reserved."
46,2,0.32334256329812555,"Chatbots can effect large-scale behaviour change because they are accessible through social media, flexible, scalable, and gather data automatically. Yet research on the feasibility and effectiveness of chatbot-administered behaviour change interventions is sparse. The effectiveness of established behaviour change interventions when implemented in chatbots is not guaranteed, given the unique human–machine interaction dynamics. We pilot-tested chatbot-based behaviour change through information provision and embedded animations. We evaluated whether the chatbot could increase understanding and intentions to adopt protective behaviours during the pandemic. Fifty-nine culturally and linguistically diverse participants received a compassion intervention, an exponential growth intervention, or no intervention. We measured participants’ COVID-19 testing intentions and measured their staying-home attitudes before and after their chatbot interaction. We found reduced uncertainty about protective behaviours. The exponential growth intervention increased participants’ testing intentions. This study provides preliminary evidence that chatbots can spark behaviour change, with applications in diverse and underrepresented groups. © 2024 Elsevier B.V., All rights reserved."
47,1,1.0,"Background and objective: To develop a healthcare chatbot service (AI-guided bot) that conducts real-time conversations using large language models to provide accurate health information to patients. Methods: To provide accurate and specialized medical responses, we integrated several cancer practice guidelines. The size of the integrated meta-dataset was 1.17 million tokens. The integrated and classified metadata were extracted, transformed into text, segmented to specific character lengths, and vectorized using the embedding model. The AI-guide bot was implemented using Python 3.9. To enhance the scalability and incorporate the integrated dataset, we combined the AI-guide bot with OpenAI and the LangChain framework. To generate user-friendly conversations, a language model was developed based on Chat-Generative Pretrained Transformer (ChatGPT), an interactive conversational chatbot powered by GPT-3.5. The AI-guide bot was implemented using ChatGPT3.5 from Sep. 2023 to Jan. 2024. Results: The AI-guide bot allowed users to select their desired cancer type and language for conversational interactions. The AI-guided bot was designed to expand its capabilities to encompass multiple major cancer types. The performance of the AI-guide bot responses was 90.98 ± 4.02 (obtained by summing up the Likert scores). Conclusions: The AI-guide bot can provide medical information quickly and accurately to patients with cancer who are concerned about their health. © 2024 Elsevier B.V., All rights reserved."
48,1,0.605890128257606,"Introduction: Despite direct access to clinicians through the electronic health record, patients are increasingly turning to the internet for information related to their health, especially with sensitive urologic conditions such as Peyronie's disease (PD). Large language model (LLM) chatbots are a form of artificial intelligence that rely on user prompts to mimic conversation, and they have shown remarkable capabilities. The conversational nature of these chatbots has the potential to answer patient questions related to PD; however, the accuracy, comprehensiveness, and readability of these LLMs related to PD remain unknown. Aims: To assess the quality and readability of information generated from 4 LLMs with searches related to PD; to see if users could improve responses; and to assess the accuracy, completeness, and readability of responses to artificial preoperative patient questions sent through the electronic health record prior to undergoing PD surgery. Methods: The National Institutes of Health's frequently asked questions related to PD were entered into 4 LLMs, unprompted and prompted. The responses were evaluated for overall quality by the previously validated DISCERN questionnaire. Accuracy and completeness of LLM responses to 11 presurgical patient messages were evaluated with previously accepted Likert scales. All evaluations were performed by 3 independent reviewers in October 2023, and all reviews were repeated in April 2024. Descriptive statistics and analysis were performed. Results: Without prompting, the quality of information was moderate across all LLMs but improved to high quality with prompting. LLMs were accurate and complete, with an average score of 5.5 of 6.0 (SD, 0.8) and 2.8 of 3.0 (SD, 0.4), respectively. The average Flesch-Kincaid reading level was grade 12.9 (SD, 2.1). Chatbots were unable to communicate at a grade 8 reading level when prompted, and their citations were appropriate only 42.5% of the time. Conclusion: LLMs may become a valuable tool for patient education for PD, but they currently rely on clinical context and appropriate prompting by humans to be useful. Unfortunately, their prerequisite reading level remains higher than that of the average patient, and their citations cannot be trusted. However, given their increasing uptake and accessibility, patients and physicians should be educated on how to interact with these LLMs to elicit the most appropriate responses. In the future, LLMs may reduce burnout by helping physicians respond to patient messages. © 2024 Elsevier B.V., All rights reserved."
49,4,1.0,"Background: Pharmacists need up-to-date knowledge and decision-making support in HIV care. We aim to develop MARVIN-Pharma, an adapted artificial intelligence-based chatbot initially for people with HIV, to assist pharmacists in considering evidence-based needs. Methods: From December 2022 to December 2023, an online needs-assessment survey evaluated Québec pharmacists’ knowledge, attitudes, involvement, and barriers relative to HIV care, alongside perceptions relevant to the usability of MARVIN-Pharma. Recruitment involved convenience and snowball sampling, targeting National HIV and Hepatitis Mentoring Program affiliates. Results: Forty-one pharmacists (28 community, 13 hospital-based) across 15 Québec municipalities participated. Participants perceived their HIV knowledge as moderate (M = 3.74/6). They held largely favorable attitudes towards providing HIV care (M = 4.02/6). They reported a “little” involvement in the delivery of HIV care services (M = 2.08/5), most often ART adherence counseling, refilling, and monitoring. The most common barriers reported to HIV care delivery were a lack of time, staff resources, clinical tools, and HIV information/training, with pharmacists at least somewhat agreeing that they experienced each (M ≥ 4.00/6). On average, MARVIN-Pharma’s acceptability and compatibility were in the ‘undecided’ range (M = 4.34, M = 4.13/7, respectively), while pharmacists agreed to their self-efficacy to use online health services (M = 5.6/7). Conclusion: MARVIN-Pharma might help address pharmacists’ knowledge gaps and barriers to HIV treatment and care, but pharmacist engagement in the chatbot’s development seems vital for its future uptake and usability. © 2024 Elsevier B.V., All rights reserved."
50,0,0.8358432059616733,"Background: The increasing prevalence of artificial intelligence (AI)-driven mental health conversational agents necessitates a comprehensive understanding of user engagement and user perceptions of this technology. This study aims to fill the existing knowledge gap by focusing on Wysa, a commercially available mobile conversational agent designed to provide personalized mental health support. Methods: A total of 159 user reviews posted between January, 2020 and March, 2024, on the Wysa app’s Google Play page were collected. Thematic analysis was then used to perform open and inductive coding of the collected data. Results: Seven major themes emerged from the user reviews: “a trusting environment promotes wellbeing”, “ubiquitous access offers real-time support”, “AI limitations detract from the user experience”, “perceived effectiveness of Wysa”, “desire for cohesive and predictable interactions”, “humanness in AI is welcomed”, and “the need for improvements in the user interface”. These themes highlight both the benefits and limitations of the AI-driven mental health conversational agents. Conclusions: Users find that Wysa is effective in fostering a strong connection with its users, encouraging them to engage with the app and take positive steps towards emotional resilience and self-improvement. However, its AI needs several improvements to enhance user experience with the application. The findings contribute to the design and implementation of more effective, ethical, and user-aligned AI-driven mental health support systems. © 2024 Elsevier B.V., All rights reserved."
51,4,1.0,"Background: Sexually transmitted infections (STIs) present a significant global public health issue, with disparities in STI rates often observed across ethnic groups. The study investigates the impact of Chatbot-Assisted Self Assessment (CASA) on the intentions for sexual health screening within minoritised ethnic groups (MEGs) at risk of STIs as well as the subsequent use of a chatbot for booking STI screening. Methods: A simulation within-subject design was utilised to evaluate the effect of CASA on intentions for STI/HIV screening, concern about STIs, and attitudes towards STI screening. Screening intentions served as the dependent variable, while demographic and behavioural factors related to STI/HIV risk were the independent variables. ANCOVA tests were conducted to measure the impact of CASA on these perceptions. Results: Involving 548 participants (54% women, 66% black, average age = 30 years), the study found that CASA positively influenced screening intentions t(547) = -10.3, P < 0.001], concerns about STIs t(544) = -4.96, P < 0.001, and attitudes towards sexual health screening [t(543) = -4.36, P < 0.001. Positive attitudes towards CASA were observed (mean, 13.30; s.d., 6.73; range, -17 to 21). About 72% of users who booked STI screening appointments via chatbot were from MEGs. Conclusion: CASA increased motivations for STI screening intentions among ethnically diverse communities. The intervention's non-judgemental nature and the chatbot's ability to emulate sexual history-taking were critical in fostering an environment conducive to behavioural intention change. The study's high acceptability indicates the potential for broader application in digital health interventions. However, the limitation of not tracking actual post-intervention behaviour warrants further investigation into CASA's real-world efficacy. © 2024 Elsevier B.V., All rights reserved."
52,1,0.594268929171586,"Importance: There is an increasing use of artificial intelligence (AI) in ophthalmology to respond to the needs of patients to access reliable, easy-to-understand medical information. Objective: To assess patient satisfaction with the usability of MonŒil, an AI-based platform designed for patient education in ophthalmology. Design: This was a pilot cross-sectional study of the usability of MonŒil by patients followed for advanced age-related macular degeneration (AMD). MonŒil is based on ChatGPT-4 technology with specific ophthalmology-focused customizations and accessibility enhancements, and is freely available at monoeil.help. Patients were given 20 min of unsupervised interaction with no prior training or guidance, after which their feedback was collected. Setting: The study was performed in the ophthalmology department at the Creteil University Hospital. Participants: Participants included 54 patients diagnosed with advanced AMD defined presenting for follow-up. Patients had to be older than 50 years of age, capable of giving informed consent, and able to understand and interact with MonŒil. Exclusion criteria were severe visual and cognitive impairment that prevented interaction with MonŒil. Main Outcome(s) and Measure(s): The primary outcome was the usability of MonŒil as measured by the System Usability Scale (SUS) questionnaire. Results: Of the 54 participants, 34 were female (62.96 %). The mean age of the cohort was 77.76±8.14 years (range 58 to 97 years). The mean SUS score was 90.23±12.04 with a median of 92.50 (range 42.50 to 100.00), indicating excellent usability. There was a positive relationship between visual acuity and SUS score (regression coefficient 0.30 (95 % CI 0.08 to 0.51), r2=0.19, p = 0.0077). Conclusions and Relevance: MonŒil demonstrated excellent usability and satisfaction in a sample population of elderly patients with advanced AMD. These results suggest that AI-based tools like MonŒil can enhance patient education with minimal oversight in a complex field like ophthalmology, supporting its use as an adjunct to the physician-patient discussion. Further studies may be necessary to establish the applicability of MonŒil to a broader user base, and to assess its usefulness and clinical impact on patient outcomes such as patient knowledge and vision-related quality of life. © 2025 Elsevier B.V., All rights reserved."
53,2,0.39599952848262676,"Objective: While most patients with COVID-19-induced olfactory dysfunction (OD) recover spontaneously, those with persistent OD face significant physical and psychological sequelae. ChatGPT, an artificial intelligence chatbot, has grown as a tool for patient education. This study seeks to evaluate the quality of ChatGPT-generated responses for COVID-19 OD. Study Design: Quantitative observational study. Setting: Publicly available online website. Methods: ChatGPT (GPT-4) was queried 4 times with 30 identical questions. Prior to questioning, Chat-GPT was “prompted” to respond (1) to a patient, (2) to an eighth grader, (3) with references, and (4) no prompt. Answer accuracy was independently scored by 4 rhinologists using the Global Quality Score (GCS, range: 1-5). Proportions of responses at incremental score thresholds were compared using χ2 analysis. Flesch-Kincaid grade level was calculated for each answer. Relationship between prompt type and grade level was assessed via analysis of variance. Results: Across all graded responses (n = 480), 364 responses (75.8%) were “at least good” (GCS ≥ 4). Proportions of responses that were “at least good” (P <.0001) or “excellent” (GCS = 5) (P <.0001) differed by prompt; “at least moderate” (GCS ≥ 3) responses did not (P =.687). Eighth-grade level (14.06 ± 2.3) and patient-friendly (14.33 ± 2.0) responses were significantly lower mean grade level than no prompting (P <.0001). Conclusion: ChatGPT provides appropriate answers to most questions on COVID-19 OD regardless of prompting. However, prompting influences response quality and grade level. ChatGPT responds at grade levels above accepted recommendations for presenting medical information to patients. Currently, ChatGPT offers significant potential for patient education as an adjunct to the conventional patient-physician relationship. © 2024 Elsevier B.V., All rights reserved."
54,2,1.0,"Vaccine hesitancy is one of the top ten threats to global health. Artificial intelligence-driven chatbots and motivational interviewing skills show promise in addressing vaccine hesitancy. This study aimed to develop and validate an artificial intelligence-driven motivational digital assistant in decreasing COVID-19 vaccine hesitancy among Hong Kong adults. The intervention development and validation were guided by the Medical Research Council’s framework with four major steps: logic model development based on theory and qualitative interviews (n = 15), digital assistant development, expert evaluation (n = 5), and a pilot test (n = 12). The Vaccine Hesitancy Matrix model and qualitative findings guided the development of the intervention logic model and content with five web-based modules. An artificial intelligence-driven chatbot tailored to each module was embedded in the website to motivate vaccination intention using motivational interviewing skills. The content validity index from expert evaluation was 0.85. The pilot test showed significant improvements in vaccine-related health literacy (p = 0.021) and vaccine confidence (p = 0.027). This digital assistant is effective in improving COVID-19 vaccine literacy and confidence through valid educational content and motivational conversations. The intervention is ready for testing in a randomized controlled trial and has high potential to be a useful toolkit for addressing ambivalence and facilitating informed decision making regarding vaccination. © 2024 Elsevier B.V., All rights reserved."
55,1,1.0,"Objective: To assess the quality, empathy, and safety of expert edited large language model (LLM), human expert created, and LLM responses to common retina patient questions. Design: Randomized, masked multicenter study. Participants: Twenty-one common retina patient questions were randomly assigned among 13 retina specialists. Methods: Each expert created a response (Expert) and then edited a LLM (ChatGPT-4)-generated response to that question (Expert + artificial intelligence [AI]), timing themselves for both tasks. Five LLMs (ChatGPT-3.5, ChatGPT-4, Claude 2, Bing, and Bard) also generated responses to each question. The original question along with anonymized and randomized Expert + AI, Expert, and LLM responses were evaluated by the other experts who did not write an expert response to the question. Evaluators judged quality and empathy (very poor, poor, acceptable, good, or very good) along with safety metrics (incorrect information, likelihood to cause harm, extent of harm, and missing content). Main Outcome: Mean quality and empathy score, proportion of responses with incorrect information, likelihood to cause harm, extent of harm, and missing content for each response type. Results: There were 4008 total grades collected (2608 for quality and empathy; 1400 for safety metrics), with significant differences in both quality and empathy (P < 0.001, P < 0.001) between LLM, Expert and Expert + AI groups. For quality, Expert + AI (3.86 ± 0.85) performed the best overall while GPT-3.5 (3.75 ± 0.79) was the top performing LLM. For empathy, GPT-3.5 (3.75 ± 0.69) had the highest mean score followed by Expert + AI (3.73 ± 0.63). By mean score, Expert placed 4 out of 7 for quality and 6 out of 7 for empathy. For both quality (P < 0.001) and empathy (P < 0.001), expert-edited LLM responses performed better than expert-created responses. There were time savings for an expert-edited LLM response versus expert-created response (P = 0.02). ChatGPT-4 performed similar to Expert for inappropriate content (P = 0.35), missing content (P = 0.001), extent of possible harm (P = 0.356), and likelihood of possible harm (P = 0.129). Conclusions: In this randomized, masked, multicenter study, LLM responses were comparable with experts in terms of quality, empathy, and safety metrics, warranting further exploration of their potential benefits in clinical settings. Financial Disclosure(s): Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of the article. © 2024 Elsevier B.V., All rights reserved."
56,0,1.0,"Objective: We developed a chatbot aimed to facilitate mental health services use for eating disorders (EDs) and offered the opportunity to enrol in a research study and use the chatbot to all adult respondents to a publicly available online ED screen who screened positive for clinical/subclinical EDs and reported not currently being in treatment. We examined the rates and correlates of enrolment in the study and uptake of the chatbot. Method: Following screening, eligible respondents (≥18 years, screened positive for a clinical/subclinical ED, not in treatment for an ED) were shown the study opportunity. Chi-square tests and logistic regressions explored differences in demographics, ED symptoms, suicidality, weight, and probable ED diagnoses between those who enroled and engaged with the chatbot versus those who did not. Results: 6747 respondents were shown the opportunity (80.0% of all adult screens). 3.0% enroled, of whom 90.2% subsequently used the chatbot. Enrolment and chatbot uptake were more common among respondents aged ≥25 years old versus those aged 18–24 and less common among respondents who reported engaging in regular dietary restriction. Conclusions: Overall enrolment was low, yet uptake was high among those that enroled and did not differ across most demographics and symptom presentations. Future directions include evaluating respondents' attitudes towards treatment-promoting tools and removing barriers to uptake. © 2024 Elsevier B.V., All rights reserved."
57,1,0.5671748499843873,"Background: Premature ejaculation (PE) is the most prevalent sexual dysfunction in men, and like many diseases and conditions, patients use Internet sources like ChatGPT, which is a popular artificial intelligence-based language model, for queries about this andrological disorder. Aim: The objective of this research was to evaluate the quality, readability, and understanding of texts produced by ChatGPT in response to frequently requested inquiries on PE. Methods: In this study we used Google Trends to identify the most frequently searched phrases related to PE. Subsequently, the discovered keywords were methodically entered into ChatGPT, and the resulting replies were assessed for quality using the Ensuring Quality Information for Patients (EQIP) program. The produced texts were assessed for readability using the Flesch-Kincaid Grade Level (FKGL), Flesch Reading Ease Score (FRES), and DISCERN metrics. Outcomes: This investigation has identified substantial concerns about the quality of texts produced by ChatGPT, highlighting severe problems with reading and understanding. Results: The mean EQIP score for the texts was determined to be 45.93 ± 4.34, while the FRES was 15.8 ± 8.73. Additionally, the FKGL score was computed to be 15.68 ± 1.67 and the DISCERN score was 38.1 ± 3.78. The comparatively low average EQIP and DISCERN scores suggest that improvements are required to increase the quality and dependability of the presented information. In addition, the FKGL scores indicate a significant degree of linguistic intricacy, requiring a level of knowledge comparable to about 14 to 15 years of formal schooling in order to understand. The texts about treatment, which are the most frequently searched items, are more difficult to understand compared to other texts about other categories. Clinical Implications: The results of this research suggest that compared to texts on other topics the PE texts produced by ChatGPT exhibit a higher degree of complexity, which exceeds the recommended reading threshold for effective health communication. Currently, ChatGPT is cannot be considered a substitute for comprehensive medical consultations. Strengths and Limitations: This study is to our knowledge the first reported research investigating the quality and comprehensibility of information generated by ChatGPT in relation to frequently requested queries about PE. The main limitation is that the investigation included only the first 25 popular keywords in English. Conclusion: ChatGPT is incapable of replacing the need for thorough medical consultations. © 2024 Elsevier B.V., All rights reserved."
58,1,1.0,"Purpose The latest iteration of GPT4 (generative pretrained transformer) is a large multimodal model that can integrate both text and image input, but its performance with medical images has not been systematically evaluated. We studied whether ChatGPT with GPT-4V(ision) can recognize images from common nuclear medicine examinations and interpret them. Patients and Methods Fifteen representative images (scintigraphy, 11; PET, 4) were submitted to ChatGPT with GPT-4V(ision), both in its Default and ""Advanced Data Analysis (beta)""version. ChatGPT was asked to name the type of examination and tracer, explain the findings and whether there are abnormalities. ChatGPT should also mark anatomical structures or pathological findings. The appropriateness of the responses was rated by 3 nuclear medicine physicians. Results The Default version identified the examination and the tracer correctly in the majority of the 15 cases (60% or 53%) and gave an ""appropriate""description of the findings or abnormalities in 47% or 33% of cases, respectively. The Default version cannot manipulate images. ""Advanced Data Analysis (beta)""failed in all tasks in >90% of cases. A ""major""or ""incompatible""inconsistency between 3 trials of the same prompt was observed in 73% (Default version) or 87% of cases (""Advanced Data Analysis (beta)""version). Conclusions Although GPT-4V(ision) demonstrates preliminary capabilities in analyzing nuclear medicine images, it exhibits significant limitations, particularly in its reliability (ie, correctness, predictability, and consistency). © 2024 Elsevier B.V., All rights reserved."
59,1,1.0,"Background: Patients are increasingly using artificial intelligence (AI) chatbots to seek answers to medical queries. Methods: Ten frequently asked questions in anaesthesia were posed to three AI chatbots: ChatGPT4 (OpenAI), Bard (Google), and Bing Chat (Microsoft). Each chatbot's answers were evaluated in a randomised, blinded order by five residency programme directors from 15 medical institutions in the USA. Three medical content quality categories (accuracy, comprehensiveness, safety) and three communication quality categories (understandability, empathy/respect, and ethics) were scored between 1 and 5 (1 representing worst, 5 representing best). Results: ChatGPT4 and Bard outperformed Bing Chat (median [inter-quartile range] scores: 4 [3–4], 4 [3–4], and 3 [2–4], respectively; P<0.001 with all metrics combined). All AI chatbots performed poorly in accuracy (score of ≥4 by 58%, 48%, and 36% of experts for ChatGPT4, Bard, and Bing Chat, respectively), comprehensiveness (score ≥4 by 42%, 30%, and 12% of experts for ChatGPT4, Bard, and Bing Chat, respectively), and safety (score ≥4 by 50%, 40%, and 28% of experts for ChatGPT4, Bard, and Bing Chat, respectively). Notably, answers from ChatGPT4, Bard, and Bing Chat differed statistically in comprehensiveness (ChatGPT4, 3 [2–4] vs Bing Chat, 2 [2–3], P<0.001; and Bard 3 [2–4] vs Bing Chat, 2 [2–3], P=0.002). All large language model chatbots performed well with no statistical difference for understandability (P=0.24), empathy (P=0.032), and ethics (P=0.465). Conclusions: In answering anaesthesia patient frequently asked questions, the chatbots perform well on communication metrics but are suboptimal for medical content metrics. Overall, ChatGPT4 and Bard were comparable to each other, both outperforming Bing Chat. © 2024 Elsevier B.V., All rights reserved."
60,-1,0.29582861300184227,"Artificial Intelligence (AI) chatbots provide a novel format for individuals to interact with large language models (LLMs). Recently released tools allow nontechnical users to develop chatbots using natural language. Surgical education is an exciting area in which chatbots developed in this manner may be rapidly deployed, though additional work will be required to ensure their accuracy and safety. In this paper, we outline our initial experience with AI chatbot creation in surgical education and offer considerations for future use of this technology. © 2024 Elsevier B.V., All rights reserved."
61,1,0.2664609332838501,[No abstract available] Evaluating the efficacy of artificial intelligence chatbots in urological health: insights for urologists on patient interactions with large language models Artificial Intelligence (ai); Chatbot; Urology; Chatgpt V3.5; Article; Artificial Intelligence; Bladder Cancer; Chatgpt; Decision Making; Education; Health; Health Care; Health Care Personnel; Human; Kidney Cancer; Large Language Model; Likert Scale; Myopia; Prostate Cancer; Questionnaire; Social Media; Testis Cancer; Urological Health; Urologist; Urology
62,1,1.0,"This study aimed to evaluate the readability, reliability, and quality of responses by 4 selected artificial intelligence (AI)-based large language model (LLM) chatbots to questions related to cardiopulmonary resuscitation (CPR). This was a cross-sectional study. Responses to the 100 most frequently asked questions about CPR by 4 selected chatbots (ChatGPT-3.5 [Open AI], Google Bard [Google AI], Google Gemini [Google AI], and Perplexity [Perplexity AI]) were analyzed for readability, reliability, and quality. The chatbots were asked the following question: ""What are the 100 most frequently asked questions about cardio pulmonary resuscitation?"" in English. Each of the 100 queries derived from the responses was individually posed to the 4 chatbots. The 400 responses or patient education materials (PEM) from the chatbots were assessed for quality and reliability using the modified DISCERN Questionnaire, Journal of the American Medical Association and Global Quality Score. Readability assessment utilized 2 different calculators, which computed readability scores independently using metrics such as Flesch Reading Ease Score, Flesch-Kincaid Grade Level, Simple Measure of Gobbledygook, Gunning Fog Readability and Automated Readability Index. Analyzed 100 responses from each of the 4 chatbots. When the readability values of the median results obtained from Calculators 1 and 2 were compared with the 6th-grade reading level, there was a highly significant difference between the groups (P < .001). Compared to all formulas, the readability level of the responses was above 6thgrade. It can be seen that the order of readability from easy to difficult is Bard, Perplexity, Gemini, and ChatGPT-3.5. The readability of the text content provided by all 4 chatbots was found to be above the 6th-grade level. We believe that enhancing the quality, reliability, and readability of PEMs will lead to easier understanding by readers and more accurate performance of CPR. So, patients who receive bystander CPR may experience an increased likelihood of survival. © 2024 Elsevier B.V., All rights reserved."
63,3,1.0,"Objective: Family health history (FHx) is an important tool in assessing one’s risk towards specific health conditions. However, user experience of FHx collection tools is rarely studied. ItRunsInMyFamily.com (ItRuns) was developed to assess FHx and hereditary cancer risk. This study reports a quantitative user experience analysis of ItRuns. Methods: We conducted a public health campaign in November 2019 to promote FHx collection using ItRuns. We used software telemetry to quantify abandonment and time spent on ItRuns to identify user behaviors and potential areas of improvement. Results: Of 11,065 users who started the ItRuns assessment, 4305 (38.91%) reached the final step to receive recommendations about hereditary cancer risk. Highest abandonment rates were during Introduction (32.82%), Invite Friends (29.03%), and Family Cancer History (12.03%) subflows. Median time to complete the assessment was 636 s. Users spent the highest median time on Proband Cancer History (124.00 s) and Family Cancer History (119.00 s) subflows. Search list questions took the longest to complete (median 19.50 s), followed by free text email input (15.00 s). Conclusion: Knowledge of objective user behaviors at a large scale and factors impacting optimal user experience will help enhance the ItRuns workflow and improve future FHx collection. © 2024 Elsevier B.V., All rights reserved."
64,1,1.0,"Techniques of artificial intelligence (AI) are increasingly used in the treatment of patients, such as providing a diagnosis in radiological imaging, improving workflow by triaging patients or providing an expert opinion based on clinical symptoms; however, such AI techniques also hold intrinsic risks as AI algorithms may point in the wrong direction and constitute a black box without explaining the reason for the decision-making process. This article outlines a case where an erroneous ChatGPT diagnosis, relied upon by the patient to evaluate symptoms, led to a significant treatment delay and a potentially life-threatening situation. With this case, we would like to point out the typical risks posed by the widespread application of AI tools not intended for medical decision-making. © 2024 Elsevier B.V., All rights reserved."
65,1,1.0,"Purpose: The usage of Chatbots as a kind of Artificial Intelligence in medicine is getting to increase in recent years. UpToDate® is another well-known search tool established on evidence-based knowledge and is used daily by doctors worldwide. In this study, we aimed to investigate the usefulness and reliability of ChatGPT compared to UpToDate in Otorhinolaryngology and Head and Neck Surgery (ORL–HNS). Materials and methods: ChatGPT-3.5 and UpToDate were interrogated for the management of 25 common clinical case scenarios (13 males/12 females) recruited from literature considering the daily observation at the Department of Otorhinolaryngology of Ege University Faculty of Medicine. Scientific references for the management were requested for each clinical case. The accuracy of the references in the ChatGPT answers was assessed on a 0–2 scale and the usefulness of the ChatGPT and UpToDate answers was assessed with 1–3 scores by reviewers. UpToDate and ChatGPT 3.5 responses were compared. Results: ChatGPT did not give references in some questions in contrast to UpToDate. Information on the ChatGPT was limited to 2021. UpToDate supported the paper with subheadings, tables, figures, and algorithms. The mean accuracy score of references in ChatGPT answers was 0.25–weak/unrelated. The median (Q1–Q3) was 1.00 (1.25–2.00) for ChatGPT and 2.63 (2.75–3.00) for UpToDate, the difference was statistically significant (p < 0.001). UpToDate was observed more useful and reliable than ChatGPT. Conclusions: ChatGPT has the potential to support the physicians to find out the information but our results suggest that ChatGPT needs to be improved to increase the usefulness and reliability of medical evidence-based knowledge. © 2024 Elsevier B.V., All rights reserved."
66,1,1.0,"The accurate interpretation of CRRT machine alarms is crucial in the intensive care setting. ChatGPT, with its advanced natural language processing capabilities, has emerged as a tool that is evolving and advancing in its ability to assist with healthcare information. This study is designed to evaluate the accuracy of the ChatGPT-3.5 and ChatGPT-4 models in addressing queries related to CRRT alarm troubleshooting. This study consisted of two rounds of ChatGPT-3.5 and ChatGPT-4 responses to address 50 CRRT machine alarm questions that were carefully selected by two nephrologists in intensive care. Accuracy was determined by comparing the model responses to predetermined answer keys provided by critical care nephrologists, and consistency was determined by comparing outcomes across the two rounds. The accuracy rate of ChatGPT-3.5 was 86% and 84%, while the accuracy rate of ChatGPT-4 was 90% and 94% in the first and second rounds, respectively. The agreement between the first and second rounds of ChatGPT-3.5 was 84% with a Kappa statistic of 0.78, while the agreement of ChatGPT-4 was 92% with a Kappa statistic of 0.88. Although ChatGPT-4 tended to provide more accurate and consistent responses than ChatGPT-3.5, there was no statistically significant difference between the accuracy and agreement rate between ChatGPT-3.5 and -4. ChatGPT-4 had higher accuracy and consistency but did not achieve statistical significance. While these findings are encouraging, there is still potential for further development to achieve even greater reliability. This advancement is essential for ensuring the highest-quality patient care and safety standards in managing CRRT machine-related issues. © 2024 Elsevier B.V., All rights reserved."
67,1,1.0,"The advent of modern technologies like Artificial Intelligence(AI), Internet of Things(IoT) and Deep Learning(DL) has ushered in a transformative era in healthcare, offering innovative solutions towards personalized healthcare by enhancing the quality of various medical services. Our proposed methodology involves the development of a BERT-based medical chatbot, leveraging cutting-edge deep learning technology to significantly enhance healthcare communication and accessibility. The traditional challenges faced by medical chatbots, such as imprecise understanding of medical conversations, inaccurate responses to jargon, and the inability to offer personalized feedback, are addressed through the utilization of Bidirectional Encoder Representations from Transformers (BERT). The performance metrics of our chatbot underscore its effectiveness. With an accuracy of 98%, the chatbot ensures a high level of precision in handling medical queries. The precision score of 97% attests to the accuracy and reliability of its responses. The AUC-ROC score of 97% indicates the chatbot's exceptional ability to predict specific diseases based on user queries and symptoms, showcasing its robust predictive power. Furthermore, a recall of 96% demonstrates the chatbot's capability to avoid missing cases in medical diagnoses, ensuring comprehensive coverage of potential conditions. The F1 score of 98% showcases the chatbot's proficiency in delivering accurate and personalized healthcare information, striking a harmonious balance between precision and recall. Our BERT-based medical chatbot not only addresses the limitations of traditional approaches but also achieves a remarkable performance with high accuracy, precision, predictive power, and comprehensive coverage, making it a valuable tool for advancing the quality of healthcare services. © 2024 Elsevier B.V., All rights reserved."
68,-1,0.2392385493942452,"eHealth lifestyle interventions without human support (self-help interventions) are generally less effective, as they suffer from lower adherence levels. To solve this, we investigated whether (1) using a text-based conversational agent (TCA) and applying human cues contribute to a working alliance with the TCA, and whether (2) adding human cues and establishing a positive working alliance increase intervention adherence. Participants (N = 121) followed a TCA-supported app-based physical activity intervention. We manipulated two types of human cues: visual (ie, message appearance) and relational (ie, message content). We employed a 2 (visual cues: yes, no) x 2 (relational cues: yes, no) between-subjects design, resulting in four experimental groups: (1) visual and relational cues, (2) visual cues only, (3) relational cues only, or (4) no human cues. We measured the working alliance with the Working Alliance Inventory Short Revised form and intervention adherence as the number of days participants responded to the TCA's messages. Contrary to expectations, the working alliance was unaffected by using human cues. Working alliance was positively related to adherence (t(78) = 3.606, p = .001). Furthermore, groups who received visual cues showed lower adherence levels compared to those who received relational cues only or no cues (U = 1140.5, z = −3.520, p < .001). We replicated the finding that establishing a working alliance contributes to intervention adherence, independently of the use of human cues in a TCA. However, we were unable to show that adding human cues impacted the working alliance and increased adherence. The results indicate that adding visual cues to a TCA may even negatively affect adherence, possibly because it may create confusion concerning the true nature of the coach, which may prompt unrealistic expectations. © 2024 Elsevier B.V., All rights reserved."
69,1,1.0,"Background and aims: ChatGPT is a powerful artificial intelligence (AI) chatbot developed by the OpenAI research laboratory which is capable of analysing human input and generating human-like responses. Early research into the potential application of ChatGPT in healthcare has focused mainly on clinical and administrative functions. The diagnostic ability and utility of ChatGPT in histopathology is not well defined. We benchmarked the performance of ChatGPT against pathologists in diagnostic histopathology, and evaluated the collaborative potential between pathologists and ChatGPT to deliver more accurate diagnoses. Methods and results: In Part 1 of the study, pathologists and ChatGPT were subjected to a series of questions encompassing common diagnostic conundrums in histopathology. For Part 2, pathologists reviewed a series of challenging virtual slides and provided their diagnoses before and after consultation with ChatGPT. We found that ChatGPT performed worse than pathologists in reaching the correct diagnosis. Consultation with ChatGPT provided limited help and information generated from ChatGPT is dependent on the prompts provided by the pathologists and is not always correct. Finally, we surveyed pathologists who rated the diagnostic accuracy of ChatGPT poorly, but found it useful as an advanced search engine. Conclusions: The use of ChatGPT4 as a diagnostic tool in histopathology is limited by its inherent shortcomings. Judicious evaluation of the information and histopathology diagnosis generated from ChatGPT4 is essential and cannot replace the acuity and judgement of a pathologist. However, future advances in generative AI may expand its role in the field of histopathology. © 2024 Elsevier B.V., All rights reserved."
70,-1,0.22507444776132943,"Background and Objectives: Taking a medical history is a core competence of the diagnostic process. At the beginning of their study medical students need to learn and practice the necessary techniques, initially focusing on good structuring and completeness. For this purpose, an interactive software system (ViPATalk) was developed in which the student can train to pose questions to virtual patient avatars in free conversation. At the end, the student receives feedback on the completeness of the questioning and an explanation of the essential items. The use of this software was compared to the traditional format of student role play in a randomized trial. Methods: The central component of ViPATalk is a chatbot based on the AI language AIML, which generates an appropriate answer based on keywords in the student's question. To enable a realistic use, the student can enter the question via microphone (speech-to-text) and the answer generated by the chatbot is presented as a short video sequence, where the avatar is generated from a real image. Here, the transition between the sequences is seamless, resulting in a continuous movement of the avatar during the conversation. Results: The learning success by practicing with ViPATalk was tested in an anamnestic interview with actors as simulated patients. The completeness of the conversation was evaluated with regard to numerous aspects and also certain behaviors during the conversation. These results were compared with those after practicing using peer role play. Conclusions: It was found that practicing with ViPATalk was mostly equivalent to the students' role play. In the subsequent survey of the students, the wish was expressed that the ViPATalk software should also be used as an online tool for self-study and that there should be more cases for practicing. © 2023 Elsevier B.V., All rights reserved."
71,-1,0.26181692795376577,"Background: The evolution of artificial intelligence (AI) has significantly impacted various sectors, with health care witnessing some of its most groundbreaking contributions. Contemporary models, such as ChatGPT-4 and Microsoft Bing, have showcased capabilities beyond just generating text, aiding in complex tasks like literature searches and refining web-based queries. Objective: This study explores a compelling query: can AI author an academic paper independently? Our assessment focuses on four core dimensions: relevance (to ensure that AI’s response directly addresses the prompt), accuracy (to ascertain that AI’s information is both factually correct and current), clarity (to examine AI’s ability to present coherent and logical ideas), and tone and style (to evaluate whether AI can align with the formality expected in academic writings). Additionally, we will consider the ethical implications and practicality of integrating AI into academic writing. Methods: To assess the capabilities of ChatGPT-4 and Microsoft Bing in the context of academic paper assistance in general practice, we used a systematic approach. ChatGPT-4, an advanced AI language model by Open AI, excels in generating human-like text and adapting responses based on user interactions, though it has a knowledge cut-off in September 2021. Microsoft Bing's AI chatbot facilitates user navigation on the Bing search engine, offering tailored search Results: In terms of relevance, ChatGPT-4 delved deeply into AI’s health care role, citing academic sources and discussing diverse applications and concerns, while Microsoft Bing provided a concise, less detailed overview. In terms of accuracy, ChatGPT-4 correctly cited 72% (23/32) of its peer-reviewed articles but included some nonexistent references. Microsoft Bing’s accuracy stood at 46% (6/13), supplemented by relevant non–peer-reviewed articles. In terms of clarity, both models conveyed clear, coherent text. ChatGPT-4 was particularly adept at detailing technical concepts, while Microsoft Bing was more general. In terms of tone, both models maintained an academic tone, but ChatGPT-4 exhibited superior depth and breadth in content delivery. Conclusions: Comparing ChatGPT-4 and Microsoft Bing for academic assistance revealed strengths and limitations. ChatGPT-4 excels in depth and relevance but falters in citation accuracy. Microsoft Bing is concise but lacks robust detail. Though both models have potential, neither can independently handle comprehensive academic tasks. As AI evolves, combining ChatGPT-4’s depth with Microsoft Bing’s up-to-date referencing could optimize academic support. Researchers should critically assess AI outputs to maintain academic credibility. © 2025 Elsevier B.V., All rights reserved."
72,-1,0.09085410030873606,"Background: There are numerous communication barriers between family caregivers and providers of people living with dementia, which can pose challenges to caregiving and clinical decision-making. To address these barriers, a new web and mobile-enabled app, called CareHeroes, was developed, which promotes the collection and secured sharing of clinical information between caregivers and providers. It also provides caregiver support and education. Objective: The primary study objective was to examine whether dementia caregivers would use CareHeroes as an adjunct to care and gather psychosocial data from those who used the app. Methods: This paper presents the implementation process used to integrate CareHeroes into clinical care at 2 memory clinics and preliminary outcome evaluation. Family caregivers receiving services at clinics were asked to use the app for a 12-month period to collect, track, and share clinical information with the care recipient’s provider. They also used it to assess their own mental health symptoms. Psychosocial outcomes were assessed through telephone interviews and user data were collected by the app. Results: A total of 21 caregivers enrolled in the pilot study across the 2 memory clinics. Usage data indicated that caregivers used many of the features in the CareHeroes app, though the chatbot was the most frequently used feature. Outcome data indicated that caregivers’ depression was lower at 3-month follow-up (t<inf>11</inf>=2.03, P=.03). Conclusions: Recruitment and retention of the pilot study were impacted by COVID-19 restrictions, and therefore more testing is needed with a larger sample to determine the potential impact of CareHeroes on caregivers’ mental health. Despite this limitation, the pilot study demonstrated that integrating a new supportive app for caregivers as an adjunct to clinical dementia care is feasible. Implications for future technology intervention development, implementation planning, and testing for caregivers of people living with dementia are discussed. © 2025 Elsevier B.V., All rights reserved."
73,-1,0.1333749756554924,"Background: The 42 days after delivery (“fourth trimester”) are a high-risk period for birthing individuals and newborns, especially those who are racially and ethnically marginalized due to structural racism. Objective: To fill a gap in the critical “fourth trimester,” we developed 2 ruled-based chatbots—one for birthing individuals and one for newborn caregivers—that provided trusted information about postbirth warning signs and newborn care and connected patients with health care providers. Methods: A total of 4370 individuals received the newborn chatbot outreach between September 1, 2022, and December 31, 2023, and 3497 individuals received the postpartum chatbot outreach between November 16, 2022, and December 31, 2023. We conducted surveys and interviews in English and Spanish to understand the acceptability and usability of the chatbot and identify areas for improvement. We sampled from hospital discharge lists that distributed the chatbot, stratified by prenatal care location, age, type of insurance, and racial and ethnic group. We analyzed quantitative results using descriptive analyses in SPSS (IBM Corp) and qualitative results using deductive coding in Dedoose (SocioCultural Research Consultants). Results: Overall, 2748 (63%) individuals opened the newborn chatbot messaging, and 2244 (64%) individuals opened the postpartum chatbot messaging. A total of 100 patients engaged with the chatbot and provided survey feedback; of those, 40% (n=40) identified as Black, 27% (n=27) identified as Hispanic/Latina, and 18% (n=18) completed the survey in Spanish. Payer distribution was 55% (n=55) for individuals with public insurance, 39% (n=39) for those with commercial insurance, and 2% (n=2) for uninsured individuals. The majority of surveyed participants indicated that chatbot messaging was timely and easy to use (n=80, 80%) and found the reminders to schedule the newborn visit (n=59, 59%) and postpartum visit (n=66, 66%) useful. Across 23 interviews (n=14, 61% Black; n=4, 17% Hispanic/Latina; n=2, 9% in Spanish; n=11, 48% public insurance), 78% (n=18) of interviewees engaged with the chatbot. Interviewees provided positive feedback on usability and content and recommendations for improving the outreach messages. Conclusions: Chatbots are a promising strategy to reach birthing individuals and newborn caregivers with information about postpartum recovery and newborn care, but intentional outreach and engagement strategies are needed to optimize interaction. Future work should measure the chatbot’s impact on health outcomes and reduce disparities. © 2025 Elsevier B.V., All rights reserved."
74,0,0.3209243200720811,"Background: Up to 13% of adolescents suffer from depressive disorders. Despite the high psychological burden, adolescents rarely decide to contact child and adolescent psychiatric services. To provide a low-barrier alternative, our long-term goal is to develop a chatbot for early identification of depressive symptoms. To test feasibility, we followed a two-step procedure, a) collection and linguistic analysis of psychiatric interviews with healthy adolescents and adolescents with depressive disorders and training of classifiers for detection of disorders from their answers in interviews, and b) generation of additional adolescent utterances via Chat GPT to improve the previously created model. Methods: For step a), we collected standardized interviews with 53 adolescents, n = 40 with and n = 13 without depressive disorders. The transcribed interviews comprised 4,077 question-answer-pairs, with which we predicted the clinical rating (depressive/non-depressive) with use of a feedforward neural network that received BERT (Bidirectional Encoder Representations from Transformers) vectors of interviewer questions and patient answers as input. For step b), we used the answers of all 53 interviews to instruct Chat GPT to generate new similar utterances. Results: In step a), the classifier based on BERT was able to discriminate answers by adolescents with and without depression with accuracies up to 97% and identified commonly used words and phrases. Evaluating the quality of utterances generated in step b), we found that prompt engineering for this task is difficult as Chat GPT performs poorly with long prompts and abstract descriptions of expectations on appropriate responses. The best approach was to cite original answers from the transcripts in order to optimally mimic the style of language used by patients and to find a practicable compromise between the length of prompts that Chat GPT can handle and the number of examples presented in order to minimize literal repetitions in Chat GPT’s output. Conclusion: The results indicate that identifying linguistic patterns in adolescents’ transcribed verbal responses is promising and that Chat GPT can be leveraged to generate a large dataset of interviews. The main benefit is that without any loss of validity the synthetic data are significantly easier to obtain than interview transcripts. © 2025 Elsevier B.V., All rights reserved."
75,1,1.0,"Background: Structured and standardized documentation is critical for accurately recording diagnostic findings, treatment plans, and patient progress in health care. Manual documentation can be labor-intensive and error-prone, especially under time constraints, prompting interest in the potential of artificial intelligence (AI) to automate and optimize these processes, particularly in medical documentation. Objective: This study aimed to assess the effectiveness of ChatGPT (OpenAI) in generating radiology reports from dental panoramic radiographs, comparing the performance of AI-generated reports with those manually created by dental students. Methods: A total of 100 dental students were tasked with analyzing panoramic radiographs and generating radiology reports manually or assisted by ChatGPT using a standardized prompt derived from a diagnostic checklist. Results: Reports generated by ChatGPT showed a high degree of textual similarity to reference reports; however, they often lacked critical diagnostic information typically included in reports authored by students. Despite this, the AI-generated reports were consistent in being error-free and matched the readability of student-generated reports. Conclusions: The findings from this study suggest that ChatGPT has considerable potential for generating radiology reports, although it currently faces challenges in accuracy and reliability. This underscores the need for further refinement in the AI’s prompt design and the development of robust validation mechanisms to enhance its use in clinical settings. © 2025 Elsevier B.V., All rights reserved."
76,1,1.0,"Background: Human digital twins have the potential to change the practice of personalizing cognitive health diagnosis because these systems can integrate multiple sources of health information and influence into a unified model. Cognitive health is multifaceted, yet researchers and clinical professionals struggle to align diverse sources of information into a single model. Objective: This study aims to introduce a method called HDTwin, for unifying heterogeneous data using large language models. HDTwin is designed to predict cognitive diagnoses and offer explanations for its inferences. Methods: HDTwin integrates cognitive health data from multiple sources, including demographic, behavioral, ecological momentary assessment, n-back test, speech, and baseline experimenter testing session markers. Data are converted into text prompts for a large language model. The system then combines these inputs with relevant external knowledge from scientific literature to construct a predictive model. The model's performance is validated using data from 3 studies involving 124 participants, comparing its diagnostic accuracy with baseline machine learning classifiers. Results: HDTwin achieves a peak accuracy of 0.81 based on the automated selection of markers, significantly outperforming baseline classifiers. On average, HDTwin yielded accuracy=0.77, precision=0.88, recall=0.63, and Matthews correlation coefficient=0.57. In comparison, the baseline classifiers yielded average accuracy=0.65, precision=0.86, recall=0.35, and Matthews correlation coefficient=0.36. The experiments also reveal that HDTwin yields superior predictive accuracy when information sources are fused compared to single sources. HDTwin's chatbot interface provides interactive dialogues, aiding in diagnosis interpretation and allowing further exploration of patient data. Conclusions: HDTwin integrates diverse cognitive health data, enhancing the accuracy and explainability of cognitive diagnoses. This approach outperforms traditional models and provides an interface for navigating patient information. The approach shows promise for improving early detection and intervention strategies in cognitive health. © 2024 Elsevier B.V., All rights reserved."
77,0,1.0,"Background: There is an urgent need to innovate methods of health education, which can often be resource- and time-intensive. Microinterventions have shown promise as a platform for rapid, tailored resource dissemination yet have been underexplored as a method of standardized health or dietary education; social media chatbots display unique potential as a modality for accessible, efficient, and affordable educational microinterventions. Objective: This study aims to provide public health professionals with practical recommendations on the use of social media chatbots for health education by (1) documenting the development of a novel social media chatbot intervention aimed at improving dietary attitudes and self-efficacy among South Asian American young adults and (2) describing the applied experiences of implementing the chatbot, along with user experience and engagement data. Methods: In 2023, the “Roti” chatbot was developed on Facebook and Instagram to administer a 4-lesson tailored dietary health curriculum, informed by formative research and the Theory of Planned Behavior, to 18- to 29-year-old South Asian American participants (recruited through social media from across the United States). Each lesson (10-15 minutes) consisted of 40-50 prescripted interactive texts with the chatbot (including multiple-choice and open-response questions). A preintervention survey determined which lesson(s) were suggested to participants based on their unique needs, followed by a postintervention survey informed by the Theory of Planned Behavior to assess changes in attitudes, self-efficacy, and user experiences (User Experience Questionnaire). This study uses a cross-sectional design to examine postintervention user experiences, engagement, challenges encountered, and solutions developed during the chatbot implementation. Results: Data from 168 participants of the intervention (n=92, 54.8% Facebook; n=76, 45.2% Instagram) were analyzed (mean age 24.5, SD 3.1 years; n=129, 76.8% female). Participants completed an average of 2.6 lessons (13.9 minutes per lesson) and answered an average of 75% of questions asked by the chatbot. Most reported a positive chatbot experience (User Experience Questionnaire: 1.34; 81/116, 69.8% positive), with pragmatic quality (ease of use) being higher than hedonic quality (how interesting it felt; 88/116, 75.9% vs 64/116, 55.2% positive evaluation); younger participants reported greater hedonic quality (P=.04). On a scale out of 10 (highest agreement), participants reported that the chatbot was relevant (8.53), that they learned something new (8.24), and that the chatbot was helpful (8.28). Qualitative data revealed an appreciation for the cheerful, interactive messaging of the chatbot and outlined areas of improvement for the length, timing, and scope of text content. Quick replies, checkpoints, online forums, and self-administered troubleshooting were some solutions developed to meet the challenges experienced. Conclusions: The implementation of a standardized, tailored health education curriculum through an interactive social media chatbot displayed strong feasibility. Lessons learned from challenges encountered and user input provide a tangible roadmap for future exploration of such chatbots for accessible, engaging health interventions. © 2024 Elsevier B.V., All rights reserved."
78,0,0.47007154098044707,"Background: Health promotion and growth-based interventions can effectively improve individual well-being; however, significant gaps in access and utilization still exist. Objective: This study aims to develop and test the effectiveness and implementation of a new, widely targeted conversational agent prevention program (Zenny) designed to enhance well-being. Methods: A total of 1345 individuals in the United States were recruited online and randomly assigned to either (1) a self-help program intervention delivered via an automated conversational agent on WhatsApp or (2) an active control group that had access to evidence-based wellness resources available online. The primary outcomes were well-being (measured using the 5-item World Health Organization Well-being Scale), psychosocial flourishing (assessed with the Flourishing Scale), and positive psychological health (evaluated with the Mental Health Continuum-Short Form). Outcome measures were collected at baseline and again 1 month postassessment. All analyses were conducted using an intention-to-treat approach. Results: Both groups showed significant improvements in well-being (self-help program intervention group effect size: Cohen d=0.26, P<.001; active control group effect size: d=0.24, P<.001), psychosocial flourishing (intervention: d=0.19, P<.001; active control: d=0.18, P<.001), and positive psychological health (intervention: d=0.17, P=.001; active control: d=0.24, P<.001) at postassessment. However, there were no significant differences in effectiveness between the 2 groups (P ranged from.56 to.92). As hypothesized a priori, a greater number of days spent actively engaging with the conversational agent was associated with larger improvements in well-being at postassessment among participants in the intervention group (β=.109, P=.04). Conclusions: The findings from this study suggest that the free conversational agent wellness self-help program was as effective as evidence-based web resources. Further research should explore strategies to increase participant engagement over time, as only a portion of participants were actively involved, and higher engagement was linked to greater improvements in well-being. Long-term follow-up studies are also necessary to assess whether these effects remain stable over time. © 2024 Elsevier B.V., All rights reserved."
79,-1,0.2560642765823347,"Background: Older African American and Black adults are twice as likely to develop Alzheimer disease and related dementias (ADRD) and have the lowest level of ADRD health literacy compared to any other ethnic group in the United States. Low health literacy concerning ADRD negatively impacts African American and Black people in accessing adequate health care. Objective: This study explored how 3 technological modalities-voice assistants, chatbots, and mobile apps-can assist older African American and Black adults in accessing ADRD information to improve ADRD health literacy. By testing each modality independently, the focus could be kept on understanding the unique needs and challenges of this population concerning the use of each modality when accessing ADRD-related information. Methods: Using the Wizard of Oz usability testing method, we assessed the 3 modalities with a sample of 15 older African American and Black adults aged >55 years. The 15 participants were asked to interact with the 3 modalities to search for information on local events happening in their geographical area and search for ADRD-related health information. Results: Our findings revealed that, across the 3 modalities, the content should avoid convoluted and complex language and give the possibility to save, store, and share it to be fully accessible by this population. In addition, content should come from credible sources, including information tailored to the participants' cultural values, as it has to be culturally relevant for African American and Black communities. Finally, the interaction with the tool must be time efficient, and it should be adapted to the user's needs to foster a sense of control and representation. Conclusions: We conclude that, when designing ADRD-related interventions for African American and Black older adults, it proves to be crucial to tailor the content provided by the technology to the community's values and construct an interaction with the technology that is built on African American and Black communities' needs and demands. © 2024 Elsevier B.V., All rights reserved."
80,5,1.0,"Background: Chatbots are increasingly integrated into the lives of older adults to assist with health and wellness tasks. This study aimed to understand the factors that enhance older adults’ acceptance of chatbots in healthcare delivery. Methods: This study proposed an extended Unified Theory of Acceptance and Use of Technology model (UTAUT), including aging factors of perceived physical condition, self-actualization needs, and technology anxiety. The model was tested by PLS (Partial Least Squares) with data collected from 428 Chinese citizens aged 60 and above. Results: The results reveal that performance expectancy, effort expectancy, and social influence significantly affected older adults’ behavioral intention to use chatbots. The facilitating conditions, self-actualization needs, and perceived physical condition significantly affected the actual use behavior of chatbots by older adults, whereas technology anxiety did not. Furthermore, the influence of effort expectancy and social influence on behavioral intention were moderated by experience. Conclusion: The behavioral intentions of older adults with low experience are more strongly influenced by social influences and effort expectancy. Furthermore, healthcare providers, designers, and policymakers should emphasize the impact of facilitating conditions, self-actualization needs, and perceived physical conditions on chatbot applications among older adults. © 2024 Elsevier B.V., All rights reserved."
81,3,1.0,"Background: Hereditary breast and ovarian cancer (HBOC) is a major type of hereditary cancer. Establishing effective screening to identify high-risk individuals for HBOC remains a challenge. We developed a prototype of a chatbot system that uses artificial intelligence (AI) for preliminary HBOC screening to determine whether individuals meet the National Comprehensive Cancer Network BRCA1/2 testing criteria. Objective: This study’s objective was to validate the feasibility of this chatbot in a clinical setting by using it on a patient population that visited a hospital. Methods: We validated the medical accuracy of the chatbot system by performing a test on patients who consecutively visited the Kanagawa Cancer Center. The participants completed a preoperation questionnaire to understand their background, including information technology literacy. After the operation, qualitative interviews were conducted to collect data on the usability and acceptability of the system and examine points needing improvement. Results: A total of 11 participants were enrolled between October and December 2020. All of the participants were women, and among them, 10 (91%) had cancer. According to the questionnaire, 6 (54%) participants had never heard of a chatbot, while 7 (64%) had never used one. All participants were able to complete the chatbot operation, and the average time required for the operation was 18.0 (SD 5.44) minutes. The determinations by the chatbot of whether the participants met the BRCA1/2 testing criteria based on their medical and family history were consistent with those by certified genetic counselors (CGCs). We compared the medical histories obtained from the participants by the CGCs with those by the chatbot. Of the 11 participants, 3 (27%) entered information different from that obtained by the CGCs. These discrepancies were caused by the participant’s omissions or communication errors with the chatbot. Regarding the family histories, the chatbot provided new information for 3 (27%) of the 11 participants and complemented information for the family members of 5 (45%) participants not interviewed by the CGCs. The chatbot could not obtain some information on the family history of 6 (54%) participants due to several reasons, such as being outside of the scope of the chatbot’s interview questions, the participant’s omissions, and communication errors with the chatbot. Interview data were classified into the following: (1) features, (2) appearance, (3) usability and preferences, (4) concerns, (5) benefits, and (6) implementation. Favorable comments on implementation feasibility and comments on improvements were also obtained. Conclusions: This study demonstrated that the preliminary screening system for HBOC using an AI chatbot was feasible for real patients. © 2024 Elsevier B.V., All rights reserved."
82,3,0.7498501104978549,"Introduction: Digital health interventions specifically those realized as chatbots are increasingly available for mental health. They include technologies based on artificial intelligence that assess user’s sentiment and emotions for the purpose of responding in an empathetic way, or for treatment purposes, e.g. for analyzing the expressed emotions and suggesting interventions. Methods: In this paper, we study the ethical dimensions of integrating these technologies in chatbots for depression intervention using the digital ethics canvas and the DTx Risk Assessment Canvas. Results: As result, we identified some specific risks associated with the integration of sentiment and emotion analysis methods into these systems related to the difficulty to recognize correctly the expressed sentiment or emotion from statements of individuals with depressive symptoms and the appropriate system reaction including risk detection. Depending on the realization of the sentiment or emotion analysis, which might be dictionary-based or machine-learning based, additional risks occur from biased training data or misinterpretations. Discussion: While technology decisions during system development can be made carefully depending on the use case, other ethical risks cannot be prevented on a technical level, but by carefully integrating such chatbots into the care process allowing for supervision by health professionals. We conclude that a careful reflection is needed when integrating sentiment and emotion analysis into chatbots for depression intervention. Balancing risk factors is key to leveraging technology in mental health in a way that enhances, rather than diminishes, user autonomy and agency. © 2024 Elsevier B.V., All rights reserved."
83,1,1.0,"Introduction: ChatGPT, as an AI tool, has been introduced in healthcare for various purposes. The objective of the study was to investigate the principal benefits of ChatGPT utilization in healthcare services and to identify potential domains for its expansion within the building blocks of the healthcare industry. Methods: A comprehensive three-phase study was conducted employing mixed methods. The initial phase comprised a systematic review and thematic analysis of the data. In the subsequent phases, a questionnaire, developed based on the findings from the first phase, was distributed to a sample of eight experts. The objective was to prioritize the benefits and potential expansion domains of ChatGPT in healthcare building blocks, utilizing gray SWARA (Stepwise Weight Assessment Ratio Analysis) and gray MABAC (Multi-Attributive Border Approximation Area Comparison), respectively. Results: The systematic review yielded 74 studies. A thematic analysis of the data from these studies identified 11 unique themes. In the second phase, employing the gray SWARA method, clinical decision-making (weight: 0.135), medical diagnosis (weight: 0.098), medical procedures (weight: 0.070), and patient-centered care (weight: 0.053) emerged as the most significant benefit of ChatGPT in the healthcare sector. Subsequently, it was determined that ChatGPT demonstrated the highest level of usefulness in the information and infrastructure, information and communication technologies blocks. Conclusion: The study concluded that, despite the significant benefits of ChatGPT in the clinical domains of healthcare, it exhibits a more pronounced potential for growth within the informational domains of the healthcare industry's building blocks, rather than within the domains of intervention and clinical services. © 2024 Elsevier B.V., All rights reserved."
84,1,1.0,"Background: Recent surveys indicate that 48% of consumers actively use generative artificial intelligence (AI) for health-related inquiries. Despite widespread adoption and the potential to improve health care access, scant research examines the performance of AI chatbot responses regarding emergency care advice. Objective: We assessed the quality of AI chatbot responses to common emergency care questions. We sought to determine qualitative differences in responses from 4 free-access AI chatbots, for 10 different serious and benign emergency conditions. Methods: We created 10 emergency care questions that we fed into the free-access versions of ChatGPT 3.5 (OpenAI), Google Bard, Bing AI Chat (Microsoft), and Claude AI (Anthropic) on November 26, 2023. Each response was graded by 5 board-certified emergency medicine (EM) faculty for 8 domains of percentage accuracy, presence of dangerous information, factual accuracy, clarity, completeness, understandability, source reliability, and source relevancy. We determined the correct, complete response to the 10 questions from reputable and scholarly emergency medical references. These were compiled by an EM resident physician. For the readability of the chatbot responses, we used the Flesch-Kincaid Grade Level of each response from readability statistics embedded in Microsoft Word. Differences between chatbots were determined by the chi-square test. Results: Each of the 4 chatbots’ responses to the 10 clinical questions were scored across 8 domains by 5 EM faculty, for 400 assessments for each chatbot. Together, the 4 chatbots had the best performance in clarity and understandability (both 85%), intermediate performance in accuracy and completeness (both 50%), and poor performance (10%) for source relevance and reliability (mostly unreported). Chatbots contained dangerous information in 5% to 35% of responses, with no statistical difference between chatbots on this metric (P=.24). ChatGPT, Google Bard, and Claud AI had similar performances across 6 out of 8 domains. Only Bing AI performed better with more identified or relevant sources (40%; the others had 0%-10%). Flesch-Kincaid Reading level was 7.7-8.9 grade for all chatbots, except ChatGPT at 10.8, which were all too advanced for average emergency patients. Responses included both dangerous (eg, starting cardiopulmonary resuscitation with no pulse check) and generally inappropriate advice (eg, loosening the collar to improve breathing without evidence of airway compromise). Conclusions: AI chatbots, though ubiquitous, have significant deficiencies in EM patient advice, despite relatively consistent performance. Information for when to seek urgent or emergent care is frequently incomplete and inaccurate, and patients may be unaware of misinformation. Sources are not generally provided. Patients who use AI to guide health care decisions assume potential risks. AI chatbots for health should be subject to further research, refinement, and regulation. We strongly recommend proper medical consultation to prevent potential adverse outcomes. © 2024 Elsevier B.V., All rights reserved."
85,1,1.0,"Background: Patients often struggle with determining which outpatient specialist to consult based on their symptoms. Natural language processing models in health care offer the potential to assist patients in making these decisions before visiting a hospital. Objective: This study aimed to evaluate the performance of ChatGPT in recommending medical specialties for medical questions. Methods: We used a dataset of 31,482 medical questions, each answered by doctors and labeled with the appropriate medical specialty from the health consultation board of NAVER (NAVER Corp), a major Korean portal. This dataset includes 27 distinct medical specialty labels. We compared the performance of the fine-tuned Korean Medical bidirectional encoder representations from transformers (KM-BERT) and ChatGPT models by analyzing their ability to accurately recommend medical specialties. We categorized responses from ChatGPT into those matching the 27 predefined specialties and those that did not. Both models were evaluated using performance metrics of accuracy, precision, recall, and F<inf>1</inf>-score. Results: ChatGPT demonstrated an answer avoidance rate of 6.2% but provided accurate medical specialty recommendations with explanations that elucidated the underlying pathophysiology of the patient’s symptoms. It achieved an accuracy of 0.939, precision of 0.219, recall of 0.168, and an F<inf>1</inf>-score of 0.134. In contrast, the KM-BERT model, fine-tuned for the same task, outperformed ChatGPT with an accuracy of 0.977, precision of 0.570, recall of 0.652, and an F<inf>1</inf>-score of 0.587. Conclusions: Although ChatGPT did not surpass the fine-tuned KM-BERT model in recommending the correct medical specialties, it showcased notable advantages as a conversational artificial intelligence model. By providing detailed, contextually appropriate explanations, ChatGPT has the potential to significantly enhance patient comprehension of medical information, thereby improving the medical referral process. © 2024 Elsevier B.V., All rights reserved."
86,4,0.2882495995025737,"Background: As the age of initiating sexual intercourse has gradually decreased among South Korean adolescents, earlier vaccination of adolescents for human papillomavirus (HPV) is necessary before their exposure to HPV. Health communication includes “cues to action” that lead to preventive health behaviors, and recently, social networking services, which operate with fewer time and space constraints, have been used in various studies as a form of eHealth communication. Objective: This study aims to investigate the feasibility and usability of an eHealth communication intervention for HPV vaccination in middle-school girls aimed at the girls and their mothers. Methods: The eHealth communication intervention for HPV vaccination was developed using a 6-step intervention mapping process: needs assessments, setting program outcomes, selection of a theory-based method and practical strategies, development of the intervention, implementation plan, and testing the validity of the intervention. Results: A review of 10 studies identified effective health communication messages, delivery methods, and theories for HPV vaccination among adolescents. Barriers including low knowledge, perceived threat, and the inconvenience of taking 2 doses of the vaccine were identified through focus groups, suggesting a need for youth-friendly and easy-to-understand information for adolescents delivered via mobile phones. The expected outcomes and the performance objectives are specifically tailored to reflect the vaccination intention. Behavior change techniques were applied using trusted sources and a health belief model. Health messages delivered through a KakaoTalk chatbot improved awareness and self-efficacy. Quality control was ensured with the use of a log system. The experts’ chatbot usability average score was 80.13 (SD 8.15) and the average score of girls was 84.06 (SD 7.61). Conclusions: Future studies need to verify the effectiveness of health communication strategies in promoting HPV vaccination and the effectiveness of scientific intervention using a chatbot as a delivery method for the intervention. © 2024 Elsevier B.V., All rights reserved."
87,-1,0.20694003967970712,"Objective: Most smokers who achieve short-term abstinence relapse even when aided by evidence-based cessation treatment. Mobile health presents a promising but largely untested avenue for providing adjunct behavioral support for relapse prevention. This paper presents the rationale and design of a randomized controlled trial aimed at evaluating the effectiveness of personalized mobile chat messaging support for relapse prevention among people who recently quit smoking. Methods: This is a two-arm, assessor-blinded, randomized controlled trial conducted in two clinic-based smoking cessation services in Hong Kong. An estimated 586 daily tobacco users who have abstained for 3 to 30 days will be randomized (1:1) to intervention group or control group. Both groups receive standard-of-care smoking cessation treatment from the services. The intervention group additionally receives 3-month relapse prevention support via mobile chat messaging, including cessation advice delivered by a live counselor and access to a supportive chatbot via WhatsApp. The control group receives text messaging on generic cessation advice for 3 months as attention control. The primary outcome is tobacco abstinence verified by an exhaled carbon monoxide of <5 parts per million or a negative salivary cotinine test at 6 months after randomization. Secondary outcomes include self-reported 6-month prolonged tobacco abstinence, 7-day point-prevalent abstinence, and relapse rate. The primary analyses will be by intention-to-treat, assuming participants with missing data are non-abstinent. This trial is registered with ClinicalTrials.gov (NCT05370352) and follows CONSORT-EHEALTH. Conclusion: This trial will provide new evidence on the effectiveness of mobile chat messaging as a scalable and accessible intervention for relapse prevention. © 2024 Elsevier B.V., All rights reserved."
88,5,1.0,"Background: Older adults, a population particularly susceptible to misinformation, may experience attempts at health-related scams or defrauding, and they may unknowingly spread misinformation. Previous research has investigated managing misinformation through media literacy education or supporting users by fact-checking information and cautioning for potential misinformation content, yet studies focusing on older adults are limited. Chatbots have the potential to educate and support older adults in misinformation management. However, many studies focusing on designing technology for older adults use the needs-based approach and consider aging as a deficit, leading to issues in technology adoption. Instead, we adopted the asset-based approach, inviting older adults to be active collaborators in envisioning how intelligent technologies can enhance their misinformation management practices. Objective: This study aims to understand how older adults may use chatbots’ capabilities for misinformation management. Methods: We conducted 5 participatory design workshops with a total of 17 older adult participants to ideate ways in which chatbots can help them manage misinformation. The workshops included 3 stages: developing scenarios reflecting older adults’ encounters with misinformation in their lives, understanding existing chatbot platforms, and envisioning how chatbots can help intervene in the scenarios from stage 1. Results: We found that issues with older adults’ misinformation management arose more from interpersonal relationships than individuals’ ability to detect misinformation in pieces of information. This finding underscored the importance of chatbots to act as mediators that facilitate communication and help resolve conflict. In addition, participants emphasized the importance of autonomy. They desired chatbots to teach them to navigate the information landscape and come to conclusions about misinformation on their own. Finally, we found that older adults’ distrust in IT companies and governments’ ability to regulate the IT industry affected their trust in chatbots. Thus, chatbot designers should consider using well-trusted sources and practicing transparency to increase older adults’ trust in the chatbot-based tools. Overall, our results highlight the need for chatbot-based misinformation tools to go beyond fact checking. Conclusions: This study provides insights for how chatbots can be designed as part of technological systems for misinformation management among older adults. Our study underscores the importance of inviting older adults to be active co-designers of chatbot-based interventions. © 2024 Elsevier B.V., All rights reserved."
89,3,0.321414932625026,"Artificial intelligence (AI) offers a wealth of opportunities for medicine, if we also bear in mind the risks associated with this technology. In recent years the potential future integration of AI with medicine has been the subject of much debate, although practical clinical experience of relevant cases is still largely absent. This case study examines a particular patient’s experience with different forms of care. Initially, the patient communicated with the conversation (chat) based AI (CAI) for self-treatment. However, over time she found herself increasingly drawn to a low-threshold internal company support system that is grounded in an existing, more traditional human-based care structure. This pattern of treatment May represent a useful addition to existing care structures, particularly for patients receptive to technology. © 2024 Elsevier B.V., All rights reserved."
90,1,1.0,"Background: Artificial intelligence and the language models derived from it, such as ChatGPT, offer immense possibilities, particularly in the field of medicine. It is already evident that ChatGPT can provide adequate and, in some cases, expert-level responses to health-related queries and advice for patients. However, it is currently unknown how patients perceive these capabilities, whether they can derive benefit from them, and whether potential risks, such as harmful suggestions, are detected by patients. Objective: This study aims to clarify whether patients can get useful and safe health care advice from an artificial intelligence chatbot assistant. Methods: This cross-sectional study was conducted using 100 publicly available health-related questions from 5 medical specialties (trauma, general surgery, otolaryngology, pediatrics, and internal medicine) from a web-based platform for patients. Responses generated by ChatGPT-4.0 and by an expert panel (EP) of experienced physicians from the aforementioned web-based platform were packed into 10 sets consisting of 10 questions each. The blinded evaluation was carried out by patients regarding empathy and usefulness (assessed through the question: “Would this answer have helped you?”) on a scale from 1 to 5. As a control, evaluation was also performed by 3 physicians in each respective medical specialty, who were additionally asked about the potential harm of the response and its correctness. Results: In total, 200 sets of questions were submitted by 64 patients (mean 45.7, SD 15.9 years; 29/64, 45.3% male), resulting in 2000 evaluated answers of ChatGPT and the EP each. ChatGPT scored higher in terms of empathy (4.18 vs 2.7; P<.001) and usefulness (4.04 vs 2.98; P<.001). Subanalysis revealed a small bias in terms of levels of empathy given by women in comparison with men (4.46 vs 4.14; P=.049). Ratings of ChatGPT were high regardless of the participant’s age. The same highly significant results were observed in the evaluation of the respective specialist physicians. ChatGPT outperformed significantly in correctness (4.51 vs 3.55; P<.001). Specialists rated the usefulness (3.93 vs 4.59) and correctness (4.62 vs 3.84) significantly lower in potentially harmful responses from ChatGPT (P<.001). This was not the case among patients. Conclusions: The results indicate that ChatGPT is capable of supporting patients in health-related queries better than physicians, at least in terms of written advice through a web-based platform. In this study, ChatGPT’s responses had a lower percentage of potentially harmful advice than the web-based EP. However, it is crucial to note that this finding is based on a specific study design and may not generalize to all health care settings. Alarmingly, patients are not able to independently recognize these potential dangers. © 2024 Elsevier B.V., All rights reserved."
91,-1,0.19578774976879632,"Background: China has a large population of smokers, with half of them dependent on tobacco and in need of cessation assistance, indicating the need for mobile health (mHealth) to provide cessation support. Objective: The study aims to assess the feasibility and preliminary effectiveness of combining chatbot-led support with counselor-led support for smoking cessation among community smokers in China. Methods: This is a 2-arm, parallel, assessor-blinded, pilot randomized controlled trial nested in a smoke-free campus campaign in Zhuhai, China. All participants will receive brief face-to-face cessation advice and group cessation support led by a chatbot embedded in WeChat. In addition, participants in the intervention group will receive personalized WeChat-based counseling from trained counselors. Follow-up will occur at 1, 3, and 6 months after treatment initiation. The primary smoking outcome is bioverified abstinence (exhaled carbon monoxide <4 parts per million or salivary cotinine <30 ng/mL) at 6 months. Secondary outcomes include self-reported 7-day point prevalence of abstinence, smoking reduction rate, and quit attempts. Feasibility outcomes include eligibility rate, consent rate, intervention engagement, and retention rate. An intention-to-treat approach and regression models will be used for primary analyses. Results: Participant recruitment began in March 2023, and the intervention began in April 2023. The data collection was completed in June 2024. The results of the study will be published in peer-reviewed journals and presented at international conferences. Conclusions: This study will provide novel insights into the feasibility and preliminary effectiveness of a chatbot-led intervention for smoking cessation in China. The findings of this study will inform the development and optimization of mHealth interventions for smoking cessation in China and other low- and middle-income countries. © 2024 Elsevier B.V., All rights reserved."
92,-1,0.20698865301481104,"Objectives: This study systematically reviewed research on the utilization of chatbot-related technologies for the prevention, assessment, and treatment of various substance uses, including alcohol, nicotine, and other drugs. Methods: Following PRISMA guidelines, 28 articles were selected for final analysis from an initial screening of 998 references. Data were coded for multiple components, including study characteristics, intervention types, intervention contents, sample characteristics, substance use details, measurement tools, and main findings, particularly emphasizing the effectiveness of chatbot-assisted interventions on substance use and the facilitators and barriers affecting program effectiveness. Results: Half of the studies specifically targeted smoking. Furthermore, over 85% of interventions were designed to treat substance use, with 7.14% focusing on prevention and 3.57% on assessment. Perceptions of effectiveness in quitting substance use varied, ranging from 25% to 50%, while for reduced substance use, percentages ranged from 66.67% to 83.33%. Among the studies assessing statistical effectiveness (46.43%), all experimental studies, including quasi-experiments, demonstrated significant and valid effects. Notably, 30% of studies emphasized personalization and providing relevant tips or information as key facilitators. Conclusion: This study offers valuable insights into the development and validation of chatbot-assisted interventions, thereby establishing a robust foundation for their efficacy. © 2025 Elsevier B.V., All rights reserved."
93,1,0.5211823993411344,"Objective: Large language models and artificial intelligence (AI) based chatbots have brought new insights in healthcare, but they also raise major concerns. Their applications in vascular surgery have scarcely been investigated to date. This international survey aimed to evaluate the perceptions and feedback from vascular surgeons on the use of AI chatbots in vascular surgery. Methods: This international open e-survey comprised 50 items that covered participant characteristics, their perceptions on the use of AI chatbots in vascular surgery, and their user experience. The study was designed in accordance with the Checklist for reporting Results of Internet E-Surveys and was critically reviewed and approved by international members of the European Vascular Research Collaborative (EVRC) prior to distribution. Participation was open to self reported health professionals specialised (or specialising) in vascular surgery, including residents or fellows. Results: Of the 342 individuals who visited the survey page, 318 (93%) agreed to participate; 262 (82.4%) finished the survey and were included in the analysis. Most were consultants or attending physicians (64.1%), most declared not having any training or education related to AI in healthcare (221; 84.4%), and 198 (75.6%) rated their knowledge about the abilities of AI chatbots between average to very poor. Interestingly, 95 participants (36.3%) found that AI chatbots were very useful or somewhat useful in clinical practice at this stage and 229 (87.4%) agreed that they should be systematically validated prior to being used. Eighty participants (30.5%) had specifically tested it for questions related to clinical practice and 59 (73.8%) of them experienced issues or limitations. Conclusion: This international survey provides an overview of perceptions of AI chatbots by vascular surgeons and highlights the need to improve knowledge and training of health professionals to better evaluate, define, and implement their use in vascular surgery. © 2024 Elsevier B.V., All rights reserved."
94,1,0.6537922215242086,"Background: The public launch of OpenAI’s ChatGPT platform generated immediate interest in the use of large language models (LLMs). Health care institutions are now grappling with establishing policies and guidelines for the use of these technologies, yet little is known about how health care providers view LLMs in medical settings. Moreover, there are no studies assessing how pediatric providers are adopting these readily accessible tools. Objective: The aim of this study was to determine how pediatric providers are currently using LLMs in their work as well as their interest in using a Health Insurance Portability and Accountability Act (HIPAA)–compliant version of ChatGPT in the future. Methods: A survey instrument consisting of structured and unstructured questions was iteratively developed by a team of informaticians from various pediatric specialties. The survey was sent via Research Electronic Data Capture (REDCap) to all Boston Children’s Hospital pediatric providers. Participation was voluntary and uncompensated, and all survey responses were anonymous. Results: Surveys were completed by 390 pediatric providers. Approximately 50% (197/390) of respondents had used an LLM; of these, almost 75% (142/197) were already using an LLM for nonclinical work and 27% (52/195) for clinical work. Providers detailed the various ways they are currently using an LLM in their clinical and nonclinical work. Only 29% (n=105) of 362 respondents indicated that ChatGPT should be used for patient care in its present state; however, 73.8% (273/368) reported they would use a HIPAA-compliant version of ChatGPT if one were available. Providers’ proposed future uses of LLMs in health care are described. Conclusions: Despite significant concerns and barriers to LLM use in health care, pediatric providers are already using LLMs at work. This study will give policy makers needed information about how providers are using LLMs clinically. © 2024 Elsevier B.V., All rights reserved."
95,2,1.0,"Background: Throughout the COVID-19 pandemic, multiple policies and guidelines were issued and updated for health care personnel (HCP) for COVID-19 testing and returning to work after reporting symptoms, exposures, or infection. The high frequency of changes and complexity of the policies made it difficult for HCP to understand when they needed testing and were eligible to return to work (RTW), which increased calls to Occupational Health Services (OHS), creating a need for other tools to guide HCP. Chatbots have been used as novel tools to facilitate immediate responses to patients’ and employees’ queries about COVID-19, assess symptoms, and guide individuals to appropriate care resources. Objective: This study aims to describe the development of an RTW chatbot and report its impact on demand for OHS support services during the first Omicron variant surge. Methods: This study was conducted at Mass General Brigham, an integrated health care system with over 80,000 employees. The RTW chatbot was developed using an agile design methodology. We mapped the RTW policy into a unified flow diagram that included all required questions and recommendations, then built and tested the chatbot using the Microsoft Azure Healthbot Framework. Using chatbot data and OHS call data from December 10, 2021, to February 17, 2022, we compared OHS resource use before and after the deployment of the RTW chatbot, including the number of calls to the OHS hotline, wait times, call length, and time OHS hotline staff spent on the phone. We also assessed Centers for Disease Control and Prevention data for COVID-19 case trends during the study period. Results: In the 5 weeks post deployment, 5575 users used the RTW chatbot with a mean interaction time of 1 minute and 17 seconds. The highest engagement was on January 25, 2022, with 368 users, which was 2 weeks after the peak of the first Omicron surge in Massachusetts. Among users who completed all the chatbot questions, 461 (71.6%) met the RTW criteria. During the 10 weeks, the median (IQR) number of daily calls that OHS received before and after deployment of the chatbot were 633 (251-934) and 115 (62-167), respectively (U=163; P<.001). The median time from dialing the OHS phone number to hanging up decreased from 28 minutes and 22 seconds (IQR 25:14-31:05) to 6 minutes and 25 seconds (IQR 5:32-7:08) after chatbot deployment (U=169; P<.001). Over the 10 weeks, the median time OHS hotline staff spent on the phone declined from 3 hours and 11 minutes (IQR 2:32-4:15) per day to 47 (IQR 42-54) minutes (U=193; P<.001), saving approximately 16.8 hours per OHS staff member per week. Conclusions: Using the agile methodology, a chatbot can be rapidly designed and deployed for employees to efficiently receive guidance regarding RTW that complies with the complex and shifting RTW policies, which may reduce use of OHS resources. © 2024 Elsevier B.V., All rights reserved."
96,-1,0.19378418082968923,"Background: Our prototype smoking cessation chatbot, Quin, provides evidence-based, personalized support delivered via a smartphone app to help people quit smoking. We developed Quin using a multiphase program of co-design research, part of which included focus group evaluation of Quin among stakeholders prior to clinical testing. Objective: This study aimed to gather and compare feedback on the user experience of the Quin prototype from end users and smoking cessation professionals (SCPs) via a beta testing process to inform ongoing chatbot iterations and refinements. Methods: Following active and passive recruitment, we conducted web-based focus groups with SCPs and end users from Queensland, Australia. Participants tested the app for 1-2 weeks prior to focus group discussion and could also log conversation feedback within the app. Focus groups of SCPs were completed first to review the breadth and accuracy of information, and feedback was prioritized and implemented as major updates using Agile processes prior to end user focus groups. We categorized logged in-app feedback using content analysis and thematically analyzed focus group transcripts. Results: In total, 6 focus groups were completed between August 2022 and June 2023; 3 for SCPs (n=9 participants) and 3 for end users (n=7 participants). Four SCPs had previously smoked, and most end users currently smoked cigarettes (n=5), and 2 had quit smoking. The mean duration of focus groups was 58 (SD 10.9; range 46-74) minutes. We identified four major themes from focus group feedback: (1) conversation design, (2) functionality, (3) relationality and anthropomorphism, and (4) role as a smoking cessation support tool. In response to SCPs’ feedback, we made two major updates to Quin between cohorts: (1) improvements to conversation flow and (2) addition of the “Moments of Crisis” conversation tree. Participant feedback also informed 17 recommendations for future smoking cessation chatbot developments. Conclusions: Feedback from end users and SCPs highlighted the importance of chatbot functionality, as this underpinned Quin’s conversation design and relationality. The ready accessibility of accurate cessation information and impartial support that Quin provided was recognized as a key benefit for end users, the latter of which contributed to a feeling of accountability to the chatbot. Findings will inform the ongoing development of a mature prototype for clinical testing. © 2024 Elsevier B.V., All rights reserved."
97,-1,0.11145778339975429,"Background: Patients find technology tools to be more approachable for seeking sensitive health-related information, such as reproductive health information. The inventive conversational ability of artificial intelligence (AI) chatbots, such as ChatGPT (OpenAI Inc), offers a potential means for patients to effectively locate answers to their health-related questions digitally. Objective: A pilot study was conducted to compare the novel ChatGPT with the existing Google Search technology for their ability to offer accurate, effective, and current information regarding proceeding action after missing a dose of oral contraceptive pill. Methods: A sequence of 11 questions, mimicking a patient inquiring about the action to take after missing a dose of an oral contraceptive pill, were input into ChatGPT as a cascade, given the conversational ability of ChatGPT. The questions were input into 4 different ChatGPT accounts, with the account holders being of various demographics, to evaluate potential differences and biases in the responses given to different account holders. The leading question, ""what should I do if I missed a day of my oral contraception birth control?"" alone was then input into Google Search, given its nonconversational nature. The results from the ChatGPT questions and the Google Search results for the leading question were evaluated on their readability, accuracy, and effective delivery of information. Results: The ChatGPT results were determined to be at an overall higher-grade reading level, with a longer reading duration, less accurate, less current, and with a less effective delivery of information. In contrast, the Google Search resulting answer box and snippets were at a lower-grade reading level, shorter reading duration, more current, able to reference the origin of the information (transparent), and provided the information in various formats in addition to text. Conclusions: ChatGPT has room for improvement in accuracy, transparency, recency, and reliability before it can equitably be implemented into health care information delivery and provide the potential benefits it poses. However, AI may be used as a tool for providers to educate their patients in preferred, creative, and efficient ways, such as using AI to generate accessible short educational videos from health care provider-vetted information. Larger studies representing a diverse group of users are needed. © 2024 Elsevier B.V., All rights reserved."
98,-1,0.32460448713213863,"The article provides current information regarding medical errors in diagnosing diabetes mellitus (DM), analyzes their factors, and outlines preventive measures. The causes of the most common diagnostic errors in diabetology include limited access to quality healthcare, insufficient training and number of qualified personnel, low quality of teamwork and medical information exchange, inadequate availability of diagnostic tests, poor coordination of care and follow-up, lack of medical informatics resources, human factors, and cognitive biases (such as misidentification of DM and its type, incorrect context creation, overestimation/underestimation of incidental findings, premature termination of the diagnostic process, and lack of knowledge and skills in diabetology). The most typical diagnostic discrepancies involve misidentifying type 1 DM (including latent autoimmune diabetes in adults), type 2 DM, and other specific types of DM. This is due to the increasing heterogeneity of DM, blurring of the boundaries between its types, atypical disease course, the decreased diagnostic value of the essential criteria for DM types (age, presence of metabolic syndrome signs, ketosis, dependency on insulin therapy), presence of comorbid conditions, and limited availability of diagnostic tests to specify the type of diabetes. To optimize diagnosis and prevent diagnostic errors, we have developed a Telegram bot DiaType based on a multilevel algorithm for the differential diagnosis of various types of DM. The testing of this Telegram bot has shown its high effectiveness in identifying DM variants. The advantages of DiaType include accessibility, interactivity, accuracy, and support for medical professionals, which helps improve diagnostic efficiency, simplify the diagnostic process, especially for primary care physicians, prevent diagnostic errors, and, consequently, improve treatment outcomes. © 2024 Elsevier B.V., All rights reserved."
99,3,1.0,"Background: Artificial intelligence (AI) chatbots have the potential to assist individuals with chronic health conditions by providing tailored information, monitoring symptoms, and offering mental health support. Despite their potential benefits, research on public attitudes toward health care chatbots is still limited. To effectively support individuals with long-term health conditions like long COVID (or post–COVID-19 condition), it is crucial to understand their perspectives and preferences regarding the use of AI chatbots. Objective: This study has two main objectives: (1) provide insights into AI chatbot acceptance among people with chronic health conditions, particularly adults older than 55 years and (2) explore the perceptions of using AI chatbots for health self-management and long COVID support. Methods: A web-based survey study was conducted between January and March 2023, specifically targeting individuals with diabetes and other chronic conditions. This particular population was chosen due to their potential awareness and ability to self-manage their condition. The survey aimed to capture data at multiple intervals, taking into consideration the public launch of ChatGPT, which could have potentially impacted public opinions during the project timeline. The survey received 1310 clicks and garnered 900 responses, resulting in a total of 888 usable data points. Results: Although past experience with chatbots (P<.001, 95% CI .110-.302) and online information seeking (P<.001, 95% CI .039-.084) are strong indicators of respondents’ future adoption of health chatbots, they are in general skeptical or unsure about the use of AI chatbots for health care purposes. Less than one-third of the respondents (n=203, 30.1%) indicated that they were likely to use a health chatbot in the next 12 months if available. Most were uncertain about a chatbot’s capability to provide accurate medical advice. However, people seemed more receptive to using voice-based chatbots for mental well-being, health data collection, and analysis. Half of the respondents with long COVID showed interest in using emotionally intelligent chatbots. Conclusions: AI hesitancy is not uniform across all health domains and user groups. Despite persistent AI hesitancy, there are promising opportunities for chatbots to offer support for chronic conditions in areas of lifestyle enhancement and mental well-being, potentially through voice-based user interfaces. © 2024 Elsevier B.V., All rights reserved."
100,5,1.0,"Background: Health outcomes are significantly influenced by unmet social needs. Although screening for social needs has become common in health care settings, there is often poor linkage to resources after needs are identified. The structural barriers (eg, staffing, time, and space) to helping address social needs could be overcome by a technology-based solution. Objective: This study aims to present the design and evaluation of a chatbot, DAPHNE (Dialog-Based Assistant Platform for Healthcare and Needs Ecosystem), which screens for social needs and links patients and families to resources. Methods: This research used a three-stage study approach: (1) an end-user survey to understand unmet needs and perception toward chatbots, (2) iterative design with interdisciplinary stakeholder groups, and (3) a feasibility and usability assessment. In study 1, a web-based survey was conducted with low-income US resident households (n=201). Following that, in study 2, web-based sessions were held with an interdisciplinary group of stakeholders (n=10) using thematic and content analysis to inform the chatbot’s design and development. Finally, in study 3, the assessment on feasibility and usability was completed via a mix of a web-based survey and focus group interviews following scenario-based usability testing with community health workers (family advocates; n=4) and social workers (n=9). We reported descriptive statistics and chi-square test results for the household survey. Content analysis and thematic analysis were used to analyze qualitative data. Usability score was descriptively reported. Results: Among the survey participants, employed and younger individuals reported a higher likelihood of using a chatbot to address social needs, in contrast to the oldest age group. Regarding designing the chatbot, the stakeholders emphasized the importance of provider-technology collaboration, inclusive conversational design, and user education. The participants found that the chatbot’s capabilities met expectations and that the chatbot was easy to use (System Usability Scale score=72/100). However, there were common concerns about the accuracy of suggested resources, electronic health record integration, and trust with a chatbot. Conclusions: Chatbots can provide personalized feedback for families to identify and meet social needs. Our study highlights the importance of user-centered iterative design and development of chatbots for social needs. Future research should examine the efficacy, cost-effectiveness, and scalability of chatbot interventions to address social needs. © 2024 Elsevier B.V., All rights reserved."
101,4,1.0,"Background: HIV pre-exposure prophylaxis (PrEP) is a critical biomedical strategy to prevent HIV transmission among cisgender women. Despite its proven effectiveness, Black cisgender women remain significantly underrepresented throughout the PrEP care continuum, facing barriers such as limited access to care, medical mistrust, and intersectional racial or HIV stigma. Addressing these disparities is vital to improving HIV prevention outcomes within this community. On the other hand, nurse practitioners (NPs) play a pivotal role in PrEP utilization but are underrepresented due to a lack of awareness, a lack of human resources, and insufficient support. Equipped with the rapid evolution of artificial intelligence (AI) and advanced large language models, chatbots effectively facilitate health care communication and linkage to care in various domains, including HIV prevention and PrEP care. Objective: Our study harnesses NPs’ holistic care capabilities and the power of AI through natural language processing algorithms, providing targeted, patient-centered facilitation for PrEP care. Our overarching goal is to create a nurse-led, stakeholder-inclusive, and AI-powered program to facilitate PrEP utilization among Black cisgender women, ultimately enhancing HIV prevention efforts in this vulnerable group in 3 phases. This project aims to mitigate health disparities and advance innovative, technology-based solutions. Methods: The study uses a mixed methods design involving semistructured interviews with key stakeholders, including 50 PrEP-eligible Black women, 10 NPs, and a community advisory board representing various socioeconomic backgrounds. The AI-powered chatbot is developed using HumanX technology and SmartBot360’s Health Insurance Portability and Accountability Act–compliant framework to ensure data privacy and security. The study spans 18 months and consists of 3 phases: exploration, development, and evaluation. Results: As of May 2024, the institutional review board protocol for phase 1 has been approved. We plan to start recruitment for Black cisgender women and NPs in September 2024, with the aim to collect information to understand their preferences regarding chatbot development. While institutional review board approval for phases 2 and 3 is still in progress, we have made significant strides in networking for participant recruitment. We plan to conduct data collection soon, and further updates on the recruitment and data collection progress will be provided as the study advances. Conclusions: The AI-powered chatbot offers a novel approach to improving PrEP care utilization among Black cisgender women, with opportunities to reduce barriers to care and facilitate a stigma-free environment. However, challenges remain regarding health equity and the digital divide, emphasizing the need for culturally competent design and robust data privacy protocols. The implications of this study extend beyond PrEP care, presenting a scalable model that can address broader health disparities. © 2024 Elsevier B.V., All rights reserved."
102,-1,0.19350094823697855,"Background: Cigarette smoking poses a major public health risk. Chatbots may serve as an accessible and useful tool to promote cessation due to their high accessibility and potential in facilitating long-term personalized interactions. To increase effectiveness and acceptability, there remains a need to identify and evaluate counseling strategies for these chatbots, an aspect that has not been comprehensively addressed in previous research. Objective: This study aims to identify effective counseling strategies for such chatbots to support smoking cessation. In addition, we sought to gain insights into smokers’ expectations of and experiences with the chatbot. Methods: This mixed methods study incorporated a web-based experiment and semistructured interviews. Smokers (N=229) interacted with either a motivational interviewing (MI)–style (n=112, 48.9%) or a confrontational counseling–style (n=117, 51.1%) chatbot. Both cessation-related (ie, intention to quit and self-efficacy) and user experience–related outcomes (ie, engagement, therapeutic alliance, perceived empathy, and interaction satisfaction) were assessed. Semistructured interviews were conducted with 16 participants, 8 (50%) from each condition, and data were analyzed using thematic analysis. Results: Results from a multivariate ANOVA showed that participants had a significantly higher overall rating for the MI (vs confrontational counseling) chatbot. Follow-up discriminant analysis revealed that the better perception of the MI chatbot was mostly explained by the user experience–related outcomes, with cessation-related outcomes playing a lesser role. Exploratory analyses indicated that smokers in both conditions reported increased intention to quit and self-efficacy after the chatbot interaction. Interview findings illustrated several constructs (eg, affective attitude and engagement) explaining people’s previous expectations and timely and retrospective experience with the chatbot. Conclusions: The results confirmed that chatbots are a promising tool in motivating smoking cessation and the use of MI can improve user experience. We did not find extra support for MI to motivate cessation and have discussed possible reasons. Smokers expressed both relational and instrumental needs in the quitting process. Implications for future research and practice are discussed. © 2024 Elsevier B.V., All rights reserved."
103,1,0.29959136562942007,"Background: Many patients use artificial intelligence (AI) chatbots as a rapid source of health information. This raises important questions about the reliability and effectiveness of AI chatbots in delivering accurate and understandable information. Purpose: To evaluate and compare the accuracy, conciseness, and readability of responses from OpenAI ChatGPT-4 and Google Bard to patient inquiries concerning the novel 177Lu-PSMA-617 therapy for prostate cancer. Materials and methods: Two experts listed the 12 most commonly asked questions by patients on 177Lu-PSMA-617 therapy. These twelve questions were prompted to OpenAI ChatGPT-4 and Google Bard. AI-generated responses were distributed using an online survey platform (Qualtrics) and blindly rated by eight experts. The performances of the AI chatbots were evaluated and compared across three domains: accuracy, conciseness, and readability. Additionally, potential safety concerns associated with AI-generated answers were also examined. The Mann-Whitney U and chi-square tests were utilized to compare the performances of AI chatbots. Results: Eight experts participated in the survey, evaluating 12 AI-generated responses across the three domains of accuracy, conciseness, and readability, resulting in 96 assessments (12 responses x 8 experts) for each domain per chatbot. ChatGPT-4 provided more accurate answers than Bard (2.95 ± 0.671 vs 2.73 ± 0.732, p=0.027). Bard’s responses had better readability than ChatGPT-4 (2.79 ± 0.408 vs 2.94 ± 0.243, p=0.003). Both ChatGPT-4 and Bard achieved comparable conciseness scores (3.14 ± 0.659 vs 3.11 ± 0.679, p=0.798). Experts categorized the AI-generated responses as incorrect or partially correct at a rate of 16.6% for ChatGPT-4 and 29.1% for Bard. Bard’s answers contained significantly more misleading information than those of ChatGPT-4 (p = 0.039). Conclusion: AI chatbots have gained significant attention, and their performance is continuously improving. Nonetheless, these technologies still need further improvements to be considered reliable and credible sources for patients seeking medical information on 177Lu-PSMA-617 therapy. © 2024 Elsevier B.V., All rights reserved."
104,1,1.0,"Background: Accurate medical advice is paramount in ensuring optimal patient care, and misinformation can lead to misguided decisions with potentially detrimental health outcomes. The emergence of large language models (LLMs) such as OpenAI’s GPT-4 has spurred interest in their potential health care applications, particularly in automated medical consultation. Yet, rigorous investigations comparing their performance to human experts remain sparse. Objective: This study aims to compare the medical accuracy of GPT-4 with human experts in providing medical advice using real-world user-generated queries, with a specific focus on cardiology. It also sought to analyze the performance of GPT-4 and human experts in specific question categories, including drug or medication information and preliminary diagnoses. Methods: We collected 251 pairs of cardiology-specific questions from general users and answers from human experts via an internet portal. GPT-4 was tasked with generating responses to the same questions. Three independent cardiologists (SL, JHK, and JJC) evaluated the answers provided by both human experts and GPT-4. Using a computer interface, each evaluator compared the pairs and determined which answer was superior, and they quantitatively measured the clarity and complexity of the questions as well as the accuracy and appropriateness of the responses, applying a 3-tiered grading scale (low, medium, and high). Furthermore, a linguistic analysis was conducted to compare the length and vocabulary diversity of the responses using word count and type-token ratio. Results: GPT-4 and human experts displayed comparable efficacy in medical accuracy (“GPT-4 is better” at 132/251, 52.6% vs “Human expert is better” at 119/251, 47.4%). In accuracy level categorization, humans had more high-accuracy responses than GPT-4 (50/237, 21.1% vs 30/238, 12.6%) but also a greater proportion of low-accuracy responses (11/237, 4.6% vs 1/238, 0.4%; P=.001). GPT-4 responses were generally longer and used a less diverse vocabulary than those of human experts, potentially enhancing their comprehensibility for general users (sentence count: mean 10.9, SD 4.2 vs mean 5.9, SD 3.7; P<.001; type-token ratio: mean 0.69, SD 0.07 vs mean 0.79, SD 0.09; P<.001). Nevertheless, human experts outperformed GPT-4 in specific question categories, notably those related to drug or medication information and preliminary diagnoses. These findings highlight the limitations of GPT-4 in providing advice based on clinical experience. Conclusions: GPT-4 has shown promising potential in automated medical consultation, with comparable medical accuracy to human experts. However, challenges remain particularly in the realm of nuanced clinical judgment. Future improvements in LLMs may require the integration of specific clinical reasoning pathways and regulatory oversight for safe use. Further research is needed to understand the full potential of LLMs across various medical specialties and conditions. © 2024 Elsevier B.V., All rights reserved."
105,-1,0.11338217533171724,"Large language models (LLMs) such as ChatGPT have become widely applied in the field of medical research. In the process of conducting systematic reviews, similar tools can be used to expedite various steps, including defining clinical questions, performing the literature search, document screening, information extraction, and language refinement, thereby conserving resources and enhancing efficiency. However, when using LLMs, attention should be paid to transparent reporting, distinguishing between genuine and false content, and avoiding academic misconduct. In this viewpoint, we highlight the potential roles of LLMs in the creation of systematic reviews and meta-analyses, elucidating their advantages, limitations, and future research directions, aiming to provide insights and guidance for authors planning systematic reviews and meta-analyses. © 2024 Elsevier B.V., All rights reserved."
106,1,0.8534170360065592,"Background: Artificial intelligence, particularly chatbot systems, is becoming an instrumental tool in health care, aiding clinical decision-making and patient engagement. Objective: This study aims to analyze the performance of ChatGPT-3.5 and ChatGPT-4 in addressing complex clinical and ethical dilemmas, and to illustrate their potential role in health care decision-making while comparing seniors’ and residents’ ratings, and specific question types. Methods: A total of 4 specialized physicians formulated 176 real-world clinical questions. A total of 8 senior physicians and residents assessed responses from GPT-3.5 and GPT-4 on a 1-5 scale across 5 categories: accuracy, relevance, clarity, utility, and comprehensiveness. Evaluations were conducted within internal medicine, emergency medicine, and ethics. Comparisons were made globally, between seniors and residents, and across classifications. Results: Both GPT models received high mean scores (4.4, SD 0.8 for GPT-4 and 4.1, SD 1.0 for GPT-3.5). GPT-4 outperformed GPT-3.5 across all rating dimensions, with seniors consistently rating responses higher than residents for both models. Specifically, seniors rated GPT-4 as more beneficial and complete (mean 4.6 vs 4.0 and 4.6 vs 4.1, respectively; P<.001), and GPT-3.5 similarly (mean 4.1 vs 3.7 and 3.9 vs 3.5, respectively; P<.001). Ethical queries received the highest ratings for both models, with mean scores reflecting consistency across accuracy and completeness criteria. Distinctions among question types were significant, particularly for the GPT-4 mean scores in completeness across emergency, internal, and ethical questions (4.2, SD 1.0; 4.3, SD 0.8; and 4.5, SD 0.7, respectively; P<.001), and for GPT-3.5’s accuracy, beneficial, and completeness dimensions. Conclusions: ChatGPT’s potential to assist physicians with medical issues is promising, with prospects to enhance diagnostics, treatments, and ethics. While integration into clinical workflows may be valuable, it must complement, not replace, human expertise. Continued research is essential to ensure safe and effective implementation in clinical environments. © 2024 Elsevier B.V., All rights reserved."
107,0,0.3949352138856269,"An international research collaboration with researchers from northern Sweden, Finland, Ireland, Northern Ireland, Scotland and developed the ChatPal chatbot to explore the possibility of a multilingual chatbot to promote mental wellbeing in people of all ages. In Sweden the end users were young people. The aim of the current study was to explore and discuss Swedish young peoples’ experiences of using a chatbot designed to promote their mental wellbeing. Young people aged 15–19 filled out an open-ended survey giving feedback on the ChatPal chatbot and their suggestions on improvements. A total of 122 survey responses were analysed. The qualitative content analysis of the survey responses resulted in three themes each containing two to three sub-themes. Theme 1, feeling as if someone is there when needed, which highlighted positive aspects regarding availability and accessibility. Theme 2, human-robot interaction has its limitations, which included aspects such as unnatural and impersonal conversations and limited content availability. Theme 3, usability can be improved, given technical errors due to lack of internet connection and difficulty navigating the chatbot were brought up as issues. The findings are discussed, and potential implications are offered for those designing and developing digital mental health technologies for young people. © 2024 Elsevier B.V., All rights reserved."
108,-1,0.132943271026866,"Background: Parents experience many challenges during the perinatal period. Mobile app-based interventions and chatbots show promise in delivering health care support for parents during the perinatal period. Objective: This descriptive qualitative process evaluation study aims to explore the perinatal experiences of parents in Singapore, as well as examine the user experiences of the mobile app-based intervention with an in-built chatbot titled Parentbot-a Digital Healthcare Assistant (PDA). Methods: A total of 20 heterosexual English-speaking parents were recruited via purposive sampling from a single tertiary hospital in Singapore. The parents (control group: 10/20, 50%; intervention group: 10/20, 50%) were also part of an ongoing randomized trial between November 2022 and August 2023 that aimed to evaluate the effectiveness of the PDA in improving parenting outcomes. Semistructured one-to-one interviews were conducted via Zoom from February to June 2023. All interviews were conducted in English, audio recorded, and transcribed verbatim. Data analysis was guided by the thematic analysis framework. The COREQ (Consolidated Criteria for Reporting Qualitative Research) checklist was used to guide the reporting of data. Results: Three themes with 10 subthemes describing parents' perceptions of their parenting journeys and their experiences with the PDA were identified. The main themes were (1) new babies, new troubles, and new wonders; (2) support system for the parents; and (3) reshaping perinatal support for future parents. Conclusions: Overall, the PDA provided parents with informational, socioemotional, and psychological support and could be used to supplement the perinatal care provided for future parents. To optimize users' experience with the PDA, the intervention could be equipped with a more sophisticated chatbot, equipped with more gamification features, and programmed to deliver personalized care to parents. Researchers and health care providers could also strive to promote more peer-to-peer interactions among users. The provision of continuous, holistic, and family-centered care by health care professionals could also be emphasized. Moreover, policy changes regarding maternity and paternity leaves, availability of infant care centers, and flexible work arrangements could be further explored to promote healthy work-family balance for parents. © 2024 Elsevier B.V., All rights reserved."
109,-1,0.36941474886743314,"Families of individuals with neurodevelopmental disabilities or differences (NDDs) often struggle to find reliable health information on the web. NDDs encompass various conditions affecting up to 14% of children in high-income countries, and most individuals present with complex phenotypes and related conditions. It is challenging for their families to develop literacy solely by searching information on the internet. While in-person coaching can enhance care, it is only available to a minority of those with NDDs. Chatbots, or computer programs that simulate conversation, have emerged in the commercial sector as useful tools for answering questions, but their use in health care remains limited. To address this challenge, the researchers developed a chatbot named CAMI (Coaching Assistant for Medical/Health Information) that can provide information about trusted resources covering core knowledge and services relevant to families of individuals with NDDs. The chatbot was developed, in collaboration with individuals with lived experience, to provide information about trusted resources covering core knowledge and services that may be of interest. The developers used the Django framework (Django Software Foundation) for the development and used a knowledge graph to depict the key entities in NDDs and their relationships to allow the chatbot to suggest web resources that may be related to the user queries. To identify NDD domain-specific entities from user input, a combination of standard sources (the Unified Medical Language System) and other entities were used which were identified by health professionals as well as collaborators. Although most entities were identified in the text, some were not captured in the system and therefore went undetected. Nonetheless, the chatbot was able to provide resources addressing most user queries related to NDDs. The researchers found that enriching the vocabulary with synonyms and lay language terms for specific subdomains enhanced entity detection. By using a data set of numerous individuals with NDDs, the researchers developed a knowledge graph that established meaningful connections between entities, allowing the chatbot to present related symptoms, diagnoses, and resources. To the researchers' knowledge, CAMI is the first chatbot to provide resources related to NDDs. Our work highlighted the importance of engaging end users to supplement standard generic ontologies to named entities for language recognition. It also demonstrates that complex medical and health-related information can be integrated using knowledge graphs and leveraging existing large datasets. This has multiple implications: generalizability to other health domains as well as reducing the need for experts and optimizing their input while keeping health care professionals in the loop. The researchers' work also shows how health and computer science domains need to collaborate to achieve the granularity needed to make chatbots truly useful and impactful. © 2024 Elsevier B.V., All rights reserved."
110,0,1.0,"Background: Stress levels and the prevalence of mental disorders in the general population have been rising in recent years. Chatbot-based interventions represent novel and promising digital approaches to improve health-related parameters. However, there is a lack of research on chatbot-based interventions in the area of mental health. Objective: The aim of this study was to investigate the effects of a 3-week chatbot-based intervention guided by the chatbot ELME, specifically with respect to the ability to reduce stress and improve various health-related parameters in a stressed sample. Methods: In this multicenter two-armed randomized controlled trial, 118 individuals with medium to high stress levels were randomized to the intervention group (n=59) or the treatment-as-usual control group (n=59). The ELME chatbot guided participants of the intervention group through 3 weeks of training based on the topics stress, mindfulness, and interoception, with practical and psychoeducative elements delivered in two daily interactive intervention sessions via a smartphone (approximately 10-20 minutes each). The primary outcome (perceived stress) and secondary outcomes (mindfulness; interoception or interoceptive sensibility; subjective well-being; and emotion regulation, including the subfacets reappraisal and suppression) were assessed preintervention (T1), post intervention (T2; after 3 weeks), and at follow-up (T3; after 6 weeks). During both conditions, participants also underwent ecological momentary assessments of stress and interoceptive sensibility. Results: There were no significant changes in perceived stress (β<inf>03</inf>=–.018, SE=.329; P=.96) and momentary stress. Mindfulness and the subfacet reappraisal significantly increased in the intervention group over time, whereas there was no change in the subfacet suppression. Well-being and momentary interoceptive sensibility increased in both groups over time. Conclusions: To gain insight into how the intervention can be improved to achieve its full potential for stress reduction, besides a longer intervention duration, specific sample subgroups should be considered. The chatbot-based intervention seems to have the potential to improve mindfulness and emotion regulation in a stressed sample. Future chatbot-based studies and interventions in health care should be designed based on the latest findings on the efficacy of rule-based and artificial intelligence–based chatbots. © 2024 Elsevier B.V., All rights reserved."
111,0,1.0,"Background: People with chronic diseases tend to experience more mental health issues than their peers without these health conditions. Mental health chatbots offer a potential source of mental health support for people with chronic diseases. Objective: The aim of this study was to determine whether a mental health chatbot can improve mental health in people with chronic diseases. We focused on 2 chronic diseases in particular: arthritis and diabetes. Methods: Individuals with arthritis or diabetes were recruited using various web-based methods. Participants were randomly assigned to 1 of 2 groups. Those in the treatment group used a mental health chatbot app (Wysa [Wysa Inc]) over a period of 4 weeks. Those in the control group received no intervention. Participants completed measures of depression (Patient Health Questionnaire-9), anxiety (Generalized Anxiety Disorder Scale-7), and stress (Perceived Stress Scale-10) at baseline, with follow-up testing 2 and 4 weeks later. Participants in the treatment group completed feedback questions on their experiences with the app at the final assessment point. Results: A total of 68 participants (n=47, 69% women; mean age 42.87, SD 11.27 years) were included in the analysis. Participants were divided evenly between the treatment and control groups. Those in the treatment group reported decreases in depression (P<.001) and anxiety (P<.001) severity over the study period. No such changes were found among participants in the control group. No changes in stress were reported by participants in either group. Participants with arthritis reported higher levels of depression (P=.004) and anxiety (P=.004) severity than participants with diabetes over the course of the study, as well as higher levels of stress (P=.01); otherwise, patterns of results were similar across these health conditions. In response to the feedback questions, participants in the treatment group said that they liked many of the functions and features of the app, the general design of the app, and the user experience. They also disliked some aspects of the app, with most of these reports focusing on the chatbot's conversational abilities. Conclusions: The results of this study suggest that mental health chatbots can be an effective source of mental health support for people with chronic diseases such as arthritis and diabetes. Although cost-effective and accessible, these programs have limitations and may not be well suited for all individuals. © 2024 Elsevier B.V., All rights reserved."
112,-1,0.24868441715198245,[No abstract available] Virtual health assistants: a grand challenge in health communications and behavior change Ai; Behavior; Chatbot; Digital; Ethical Considerations; Health; Lifestyle; User Engagement; Acceptance And Commitment Therapy; Article; Artificial Intelligence Chatbot; Behavior Change; Computer Security; Confidentiality; Decision Making; Demographics; Depression; Digital Health; Digital Technology; Drug Use; Economic Incentive; Health Behavior; Health Care; Health Care Disparity; Health Care Organization; Health Care Personnel; Health Care System; Healthy Lifestyle; Help Seeking Behavior; Human; Medical Information; Paramedical Personnel; Privacy; Security; Socioeconomics; Stigma; Trustworthiness; Virtual Health Assistant
113,0,0.3520451115058324,"Background: Oral health is closely related to general health and quality of life. School-aged children are at a critical stage for developing their self-care ability in oral health. Digital interventions can encourage and facilitate oral self-care in children. Objective: This study aims to present the development of an educational chatbot for school-aged children to address their oral self-care and evaluate its usability. Methods: The development and evaluation of the chatbot for oral self-care consisted of four stages: target behavior analysis, intervention design, system development, and the chatbot evaluation. The target behavior analysis identified barriers to children's engagement in oral self-care based on dentists’ clinical observations; hence, the requirements for achieving the desired behavior were categorized according to the capability-opportunity-motivation behavior model. Interventional functions were created following the behavior change wheel. A menu-driven chatbot was created and evaluated for usability as well as likeability. Results: The barriers and requirements for achieving good behavior in school-aged children's oral self-care were identified by the dental professionals. Intervention strategy incorporated specific functions enriched with gamification features to support school-aged children in developing their abilities for engaging in oral self-care. The intervention functions consist of capability establishment, motivation enhancement, and opportunity creation, which were designed to support children in their oral self-care practices. The designed chatbot was piloted with a convenient sample of 30 school-aged children and their accompanying parents at the pediatric dental clinic. The results indicated good usability, with a mean usability score of 79.91, and high likeability with a mean score of 4.32 out of 5 for the designed chatbot. Conclusions: The educational chatbot incorporated a combination of clinical dentistry practice and guidelines, aiming to promote oral self-care behavior in school-aged children. The designed chatbot achieved high scores for its usability and user likability. © 2024 Elsevier B.V., All rights reserved."
114,1,1.0,"Background: Large Language Models (LLMs) might offer a solution for the lack of trained health personnel, particularly in low- and middle-income countries. However, their strengths and weaknesses remain unclear. Aims/objectives: Here we benchmark different LLMs (Bard 2023.07.13, Claude 2, ChatGPT 4) against six consultants in otorhinolaryngology (ORL). Material and methods: Case-based questions were extracted from literature and German state examinations. Answers from Bard 2023.07.13, Claude 2, ChatGPT 4, and six ORL consultants were rated blindly on a 6-point Likert-scale for medical adequacy, comprehensibility, coherence, and conciseness. Given answers were compared to validated answers and evaluated for hazards. A modified Turing test was performed and character counts were compared. Results: LLMs answers ranked inferior to consultants in all categories. Yet, the difference between consultants and LLMs was marginal, with the clearest disparity in conciseness and the smallest in comprehensibility. Among LLMs Claude 2 was rated best in medical adequacy and conciseness. Consultants’ answers matched the validated solution in 93% (228/246), ChatGPT 4 in 85% (35/41), Claude 2 in 78% (32/41), and Bard 2023.07.13 in 59% (24/41). Answers were rated as potentially hazardous in 10% (24/246) for ChatGPT 4, 14% (34/246) for Claude 2, 19% (46/264) for Bard 2023.07.13, and 6% (71/1230) for consultants. Conclusions and significance: Despite consultants superior performance, LLMs show potential for clinical application in ORL. Future studies should assess their performance on larger scale. © 2024 Elsevier B.V., All rights reserved."
115,4,0.5823537691481134,"Background: Adolescents living with HIV are disproportionally affected by depression, which worsens antiretroviral therapy adherence, increases viral load, and doubles the risk of mortality. Because most adolescents living with HIV live in low- and middle-income countries, few receive depression treatment due to a lack of mental health services and specialists in low-resource settings. Chatbot technology, used increasingly in health service delivery, is a promising approach for delivering low-intensity depression care to adolescents living with HIV in resource-constrained settings. Objective: The goal of this study is to develop and pilot-test for the feasibility and acceptability of a prototype, optimized conversational agent (chatbot) to provide mental health education, self-help skills, and care linkage for adolescents living with HIV. Methods: Chatbot development comprises 3 phases conducted over 2 years. In the first phase (year 1), formative research will be conducted to understand the views, opinions, and preferences of up to 48 youths aged 10-19 years (6 focus groups of up to 8 adolescents living with HIV per group), their caregivers (5 in-depth interviews), and HIV program personnel (5 in-depth interviews) regarding depression among adolescents living with HIV. We will also investigate the perceived acceptability of a mental health chatbot, including barriers and facilitators to accessing and using a chatbot for depression care by adolescents living with HIV. In the second phase (year 1), we will iteratively program a chatbot using the SmartBot360 software with successive versions (0.1, 0.2, and 0.3), meeting regularly with a Youth Advisory Board comprised of adolescents living with HIV who will guide and inform the chatbot development and content to arrive at a prototype version (version 1.0) for pilot-testing. In the third phase (year 2), we will pilot-test the prototype chatbot among 50 adolescents living with HIV naïve to its development. Participants will interact with the chatbot for up to 2 weeks, and data will be collected on the acceptability of the chatbot-delivered depression education and self-help strategies, depression knowledge changes, and intention to seek care linkage. Results: The study was awarded in April 2022, received institutional review board approval in November 2022, received funding in December 2022, and commenced recruitment in March 2023. By the completion of study phases 1 and 2, we expect our chatbot to incorporate key needs and preferences gathered from focus groups and interviews to develop the chatbot. By the completion of study phase 3, we will have assessed the feasibility and acceptability of the prototype chatbot. Study phase 3 began in April 2024. Final results are expected by January 2025 and published thereafter. Conclusions: The study will produce a prototype mental health chatbot developed with and for adolescents living with HIV that will be ready for efficacy testing in a subsequent, larger study. © 2024 Elsevier B.V., All rights reserved."
116,0,0.2846876695579059,"Background: The use of chatbots in mental health support has increased exponentially in recent years, with studies showing that they may be effective in treating mental health problems. More recently, the use of visual avatars called digital humans has been introduced. Digital humans have the capability to use facial expressions as another dimension in human-computer interactions. It is important to study the difference in emotional response and usability preferences between text-based chatbots and digital humans for interacting with mental health services. Objective: This study aims to explore to what extent a digital human interface and a text-only chatbot interface differed in usability when tested by healthy participants, using BETSY (Behavior, Emotion, Therapy System, and You) which uses 2 distinct interfaces: a digital human with anthropomorphic features and a text-only user interface. We also set out to explore how chatbot-generated conversations on mental health (specific to each interface) affected self-reported feelings and biometrics. Methods: We explored to what extent a digital human with anthropomorphic features differed from a traditional text-only chatbot regarding perception of usability through the System Usability Scale, emotional reactions through electroencephalography, and feelings of closeness. Healthy participants (n=45) were randomized to 2 groups that used a digital human with anthropomorphic features (n=25) or a text-only chatbot with no such features (n=20). The groups were compared by linear regression analysis and t tests. Results: No differences were observed between the text-only and digital human groups regarding demographic features. The mean System Usability Scale score was 75.34 (SD 10.01; range 57-90) for the text-only chatbot versus 64.80 (SD 14.14; range 40-90) for the digital human interface. Both groups scored their respective chatbot interfaces as average or above average in usability. Women were more likely to report feeling annoyed by BETSY.Conclusions: The text-only chatbot was perceived as significantly more user-friendly than the digital human, although there were no significant differences in electroencephalography measurements. Male participants exhibited lower levels of annoyance with both interfaces, contrary to previously reported findings. © 2024 Elsevier B.V., All rights reserved."
117,1,1.0,"Background: Artificial intelligence is increasingly being applied to many workflows. Large language models (LLMs) are publicly accessible platforms trained to understand, interact with, and produce human-readable text; their ability to deliver relevant and reliable information is also of particular interest for the health care providers and the patients. Hematopoietic stem cell transplantation (HSCT) is a complex medical field requiring extensive knowledge, background, and training to practice successfully and can be challenging for the nonspecialist audience to comprehend. Objective: We aimed to test the applicability of 3 prominent LLMs, namely ChatGPT-3.5 (OpenAI), ChatGPT-4 (OpenAI), and Bard (Google AI), in guiding nonspecialist health care professionals and advising patients seeking information regarding HSCT. Methods: We submitted 72 open-ended HSCT–related questions of variable difficulty to the LLMs and rated their responses based on consistency—defined as replicability of the response—response veracity, language comprehensibility, specificity to the topic, and the presence of hallucinations. We then rechallenged the 2 best performing chatbots by resubmitting the most difficult questions and prompting to respond as if communicating with either a health care professional or a patient and to provide verifiable sources of information. Responses were then rerated with the additional criterion of language appropriateness, defined as language adaptation for the intended audience. Results: ChatGPT-4 outperformed both ChatGPT-3.5 and Bard in terms of response consistency (66/72, 92%; 54/72, 75%; and 63/69, 91%, respectively; P=.007), response veracity (58/66, 88%; 40/54, 74%; and 16/63, 25%, respectively; P<.001), and specificity to the topic (60/66, 91%; 43/54, 80%; and 27/63, 43%, respectively; P<.001). Both ChatGPT-4 and ChatGPT-3.5 outperformed Bard in terms of language comprehensibility (64/66, 97%; 53/54, 98%; and 52/63, 83%, respectively; P=.002). All displayed episodes of hallucinations. ChatGPT-3.5 and ChatGPT-4 were then rechallenged with a prompt to adapt their language to the audience and to provide source of information, and responses were rated. ChatGPT-3.5 showed better ability to adapt its language to nonmedical audience than ChatGPT-4 (17/21, 81% and 10/22, 46%, respectively; P=.03); however, both failed to consistently provide correct and up-to-date information resources, reporting either out-of-date materials, incorrect URLs, or unfocused references, making their output not verifiable by the reader. Conclusions: In conclusion, despite LLMs’ potential capability in confronting challenging medical topics such as HSCT, the presence of mistakes and lack of clear references make them not yet appropriate for routine, unsupervised clinical use, or patient counseling. Implementation of LLMs’ ability to access and to reference current and updated websites and research papers, as well as development of LLMs trained in specialized domain knowledge data sets, may offer potential solutions for their future clinical application. © 2024 Elsevier B.V., All rights reserved."
118,0,1.0,"Background: A plethora of weight management apps are available, but many individuals, especially those living with overweight and obesity, still struggle to achieve adequate weight loss. An emerging area in weight management is the support for one’s self-regulation over momentary eating impulses. Objective: This study aims to examine the feasibility and effectiveness of a novel artificial intelligence–assisted weight management app in improving eating behaviors in a Southeast Asian cohort. Methods: A single-group pretest-posttest study was conducted. Participants completed the 1-week run-in period of a 12-week app-based weight management program called the Eating Trigger-Response Inhibition Program (eTRIP). This self-monitoring system was built upon 3 main components, namely, (1) chatbot-based check-ins on eating lapse triggers, (2) food-based computer vision image recognition (system built based on local food items), and (3) automated time-based nudges and meal stopwatch. At every mealtime, participants were prompted to take a picture of their food items, which were identified by a computer vision image recognition technology, thereby triggering a set of chatbot-initiated questions on eating triggers such as who the users were eating with. Paired 2-sided t tests were used to compare the differences in the psychobehavioral constructs before and after the 7-day program, including overeating habits, snacking habits, consideration of future consequences, self-regulation of eating behaviors, anxiety, depression, and physical activity. Qualitative feedback were analyzed by content analysis according to 4 steps, namely, decontextualization, recontextualization, categorization, and compilation. Results: The mean age, self-reported BMI, and waist circumference of the participants were 31.25 (SD 9.98) years, 28.86 (SD 7.02) kg/m2, and 92.60 (SD 18.24) cm, respectively. There were significant improvements in all the 7 psychobehavioral constructs, except for anxiety. After adjusting for multiple comparisons, statistically significant improvements were found for overeating habits (mean –0.32, SD 1.16; P<.001), snacking habits (mean –0.22, SD 1.12; P<.002), self-regulation of eating behavior (mean 0.08, SD 0.49; P=.007), depression (mean –0.12, SD 0.74; P=.007), and physical activity (mean 1288.60, SD 3055.20 metabolic equivalent task-min/day; P<.001). Forty-one participants reported skipping at least 1 meal (ie, breakfast, lunch, or dinner), summing to 578 (67.1%) of the 862 meals skipped. Of the 230 participants, 80 (34.8%) provided textual feedback that indicated satisfactory user experience with eTRIP. Four themes emerged, namely, (1) becoming more mindful of self-monitoring, (2) personalized reminders with prompts and chatbot, (3) food logging with image recognition, and (4) engaging with a simple, easy, and appealing user interface. The attrition rate was 8.4% (21/251). Conclusions: eTRIP is a feasible and effective weight management program to be tested in a larger population for its effectiveness and sustainability as a personalized weight management program for people with overweight and obesity. © 2024 Elsevier B.V., All rights reserved."
119,-1,0.15743333715637556,"Background: There is a dearth of feasibility assessments regarding using large language models (LLMs) for responding to inquiries from autistic patients within a Chinese-language context. Despite Chinese being one of the most widely spoken languages globally, the predominant research focus on applying these models in the medical field has been on English-speaking populations. Objective: This study aims to assess the effectiveness of LLM chatbots, specifically ChatGPT-4 (OpenAI) and ERNIE Bot (version 2.2.3; Baidu, Inc), one of the most advanced LLMs in China, in addressing inquiries from autistic individuals in a Chinese setting. Methods: For this study, we gathered data from DXY—a widely acknowledged, web-based, medical consultation platform in China with a user base of over 100 million individuals. A total of 100 patient consultation samples were rigorously selected from January 2018 to August 2023, amounting to 239 questions extracted from publicly available autism-related documents on the platform. To maintain objectivity, both the original questions and responses were anonymized and randomized. An evaluation team of 3 chief physicians assessed the responses across 4 dimensions: relevance, accuracy, usefulness, and empathy. The team completed 717 evaluations. The team initially identified the best response and then used a Likert scale with 5 response categories to gauge the responses, each representing a distinct level of quality. Finally, we compared the responses collected from different sources. Results: Among the 717 evaluations conducted, 46.86% (95% CI 43.21%-50.51%) of assessors displayed varying preferences for responses from physicians, with 34.87% (95% CI 31.38%-38.36%) of assessors favoring ChatGPT and 18.27% (95% CI 15.44%-21.10%) of assessors favoring ERNIE Bot. The average relevance scores for physicians, ChatGPT, and ERNIE Bot were 3.75 (95% CI 3.69-3.82), 3.69 (95% CI 3.63-3.74), and 3.41 (95% CI 3.35-3.46), respectively. Physicians (3.66, 95% CI 3.60-3.73) and ChatGPT (3.73, 95% CI 3.69-3.77) demonstrated higher accuracy ratings compared to ERNIE Bot (3.52, 95% CI 3.47-3.57). In terms of usefulness scores, physicians (3.54, 95% CI 3.47-3.62) received higher ratings than ChatGPT (3.40, 95% CI 3.34-3.47) and ERNIE Bot (3.05, 95% CI 2.99-3.12). Finally, concerning the empathy dimension, ChatGPT (3.64, 95% CI 3.57-3.71) outperformed physicians (3.13, 95% CI 3.04-3.21) and ERNIE Bot (3.11, 95% CI 3.04-3.18). Conclusions: In this cross-sectional study, physicians’ responses exhibited superiority in the present Chinese-language context. Nonetheless, LLMs can provide valuable medical guidance to autistic patients and may even surpass physicians in demonstrating empathy. However, it is crucial to acknowledge that further optimization and research are imperative prerequisites before the effective integration of LLMs in clinical settings across diverse linguistic environments can be realized. © 2024 Elsevier B.V., All rights reserved."
120,-1,0.13279838711547295,"Background: Pediatric rheumatology is a term that encompasses over 80 conditions affecting different organs and systems. Children and young people with rheumatological chronic conditions are known to have high levels of mental health problems and therefore are at risk of poor health outcomes. Clinical psychologists can help children and young people manage the daily difficulties of living with one of these conditions; however, there are insufficient pediatric psychologists in the United Kingdom. We urgently need to consider other ways of providing early, essential support to improve their current well-being. One way of doing this is to empower parents and caregivers to have more of the answers that their children and young people need to support them further between their hospital appointments. Objective: The objective of this co-designed proof-of-concept study is to design, develop, and test a chatbot intervention to support parents and caregivers of children and young people with rheumatological conditions. Methods: This study will explore the needs and views of children and young people with rheumatological conditions, their siblings, parents, and caregivers, as well as health care professionals working in pediatric rheumatology. We will ask approximately 100 participants in focus groups where they think the gaps are in current clinical care and what ideas they have for improving upon them. Creative experience-based co-design workshops will then decide upon top priorities to develop further while informing the appearance, functionality, and practical delivery of a chatbot intervention. Upon completion of a minimum viable product, approximately 100 parents and caregivers will user-test the chatbot intervention in an iterative sprint methodology to determine its worth as a mechanism for support for parents. Results: A total of 73 children, young people, parents, caregivers, and health care professionals have so far been enrolled in the study, which began in November 2023. The anticipated completion date of the study is April 2026. The data analysis is expected to be completed in January 2026, with the results being published in April 2026. Conclusions: This study will provide evidence on the accessibility, acceptability, and usability of a chatbot intervention for parents and caregivers of children and young people with rheumatological conditions. If proven useful, it could lead to a future efficacy trial of one of the first chatbot interventions to provide targeted and user-suggested support for parents and caregivers of children with chronic health conditions in health care services. This study is unique in that it will detail the needs and wants of children, young people, siblings, parents, and caregivers to improve the current support given to families living with pediatric rheumatological conditions. It will be conducted across the whole of the United Kingdom for all pediatric rheumatological conditions at all stages of the disease trajectory. © 2024 Elsevier B.V., All rights reserved."
121,4,1.0,"Background: The HIV epidemic continues to grow fastest among men who have sex with men (MSM) in Malaysia in the presence of stigma and discrimination. Engaging MSM on the internet using chatbots supported through artificial intelligence (AI) can potentially help HIV prevention efforts. We previously identified the benefits, limitations, and preferred features of HIV prevention AI chatbots and developed an AI chatbot prototype that is now tested for feasibility and acceptability. Objective: This study aims to test the feasibility and acceptability of an AI chatbot in promoting the uptake of HIV testing and pre-exposure prophylaxis (PrEP) in MSM. Methods: We conducted beta testing with 14 MSM from February to April 2022 using Zoom (Zoom Video Communications, Inc). Beta testing involved 3 steps: a 45-minute human-chatbot interaction using the think-aloud method, a 35-minute semistructured interview, and a 10-minute web-based survey. The first 2 steps were recorded, transcribed verbatim, and analyzed using the Unified Theory of Acceptance and Use of Technology. Emerging themes from the qualitative data were mapped on the 4 domains of the Unified Theory of Acceptance and Use of Technology: performance expectancy, effort expectancy, facilitating conditions, and social influence. Results: Most participants (13/14, 93%) perceived the chatbot to be useful because it provided comprehensive information on HIV testing and PrEP (performance expectancy). All participants indicated that the chatbot was easy to use because of its simple, straightforward design and quick, friendly responses (effort expectancy). Moreover, 93% (13/14) of the participants rated the overall chatbot quality as high, and all participants perceived the chatbot as a helpful tool and would refer it to others. Approximately 79% (11/14) of the participants agreed they would continue using the chatbot. They suggested adding a local language (ie, Bahasa Malaysia) to customize the chatbot to the Malaysian context (facilitating condition) and suggested that the chatbot should also incorporate more information on mental health, HIV risk assessment, and consequences of HIV. In terms of social influence, all participants perceived the chatbot as helpful in avoiding stigma-inducing interactions and thus could increase the frequency of HIV testing and PrEP uptake among MSM. Conclusions: The current AI chatbot is feasible and acceptable to promote the uptake of HIV testing and PrEP. To ensure the successful implementation and dissemination of AI chatbots in Malaysia, they should be customized to communicate in Bahasa Malaysia and upgraded to provide other HIV-related information to improve usability, such as mental health support, risk assessment for sexually transmitted infections, AIDS treatment, and the consequences of contracting HIV. © 2024 Elsevier B.V., All rights reserved."
122,0,1.0,"Background: There has been an increased need to provide specialized help for people with depressive and anxiety symptoms, particularly teenagers and young adults. There is evidence from a 2-week intervention that chatbots (eg, Woebot) are effective in reducing depression and anxiety, an effect that was not detected in the control group that was provided self-help materials. Although chatbots are a promising solution, there is limited scientific evidence for the efficacy of agent-guided cognitive behavioral therapy (CBT) outside the English language, especially for highly inflected languages. Objective: This study aimed to measure the efficacy of Fido, a therapy chatbot that uses the Polish language. It targets depressive and anxiety symptoms using CBT techniques. We hypothesized that participants using Fido would show a greater reduction in anxiety and depressive symptoms than the control group. Methods: We conducted a 2-arm, open-label, randomized controlled trial with 81 participants with subclinical depression or anxiety who were recruited via social media. Participants were divided into experimental (interacted with a fully automated Fido chatbot) and control (received a self-help book) groups. Both intervention methods addressed topics such as general psychoeducation and cognitive distortion identification and modification via Socratic questioning. The chatbot also featured suicidal ideation identification and redirection to suicide hotlines. We used self-assessment scales to measure primary outcomes, including the levels of depression, anxiety, worry tendencies, satisfaction with life, and loneliness at baseline, after the 2-week intervention and at the 1-month follow-up. We also controlled for secondary outcomes, including engagement and frequency of use. Results: There were no differences in anxiety and depressive symptoms between the groups at enrollment and baseline. After the intervention, depressive and anxiety symptoms were reduced in both groups (chatbot: n=36; control: n=38), which remained stable at the 1-month follow-up. Loneliness was not significantly different between the groups after the intervention, but an exploratory analysis showed a decline in loneliness among participants who used Fido more frequently. Both groups used their intervention technique with similar frequency; however, the control group spent more time (mean 117.57, SD 72.40 minutes) on the intervention than the Fido group (mean 79.44, SD 42.96 minutes). Conclusions: We did not replicate the findings from previous (eg, Woebot) studies, as both arms yielded therapeutic effects. However, such results are in line with other research of Internet interventions. Nevertheless, Fido provided sufficient help to reduce anxiety and depressive symptoms and decreased perceived loneliness among high-frequency users, which is one of the first pieces of evidence of chatbot efficacy with agents that use a highly inflected language. Further research is needed to determine the long-term, real-world effectiveness of Fido and its efficacy in a clinical sample. © 2024 Elsevier B.V., All rights reserved."
123,0,0.16309037185542571,"Background: To safeguard the most vulnerable individuals during the COVID-19 pandemic, numerous governments enforced measures such as stay-at-home orders, social distancing, and self-isolation. These social restrictions had a particularly negative effect on older adults, as they are more vulnerable and experience increased loneliness, which has various adverse effects, including increasing the risk of mental health problems and mortality. Chatbots can potentially reduce loneliness and provide companionship during a pandemic. However, existing chatbots do not cater to the specific needs of older adult populations. Objective: We aimed to develop a user-friendly chatbot tailored to the specific needs of older adults with anxiety or depressive disorders during the COVID-19 pandemic and to examine their perspectives on mental health chatbot use. The primary research objective was to investigate whether chatbots can mitigate the psychological stress of older adults during COVID-19. Methods: Participants were older adults belonging to two age groups (≥65 years and <65 years) from a psychiatric outpatient department who had been diagnosed with depressive or anxiety disorders by certified psychiatrists according to the Diagnostic and Statistical Manual of Mental Disorders (Fifth Edition) (DSM-5) criteria. The participants were required to use mobile phones, have internet access, and possess literacy skills. The chatbot’s content includes monitoring and tracking health data and providing health information. Participants had access to the chatbot for at least 4 weeks. Self-report questionnaires for loneliness, depression, and anxiety were administered before and after chatbot use. The participants also rated their attitudes toward the chatbot. Results: A total of 35 participants (mean age 65.21, SD 7.51 years) were enrolled in the trial, comprising 74% (n=26) female and 26% (n=9) male participants. The participants demonstrated a high utilization rate during the intervention, with over 82% engaging with the chatbot daily. Loneliness significantly improved in the older group ≥65 years. This group also responded positively to the chatbot, as evidenced by changes in University of California Los Angeles Loneliness Scale scores, suggesting that this demographic can derive benefits from chatbot interaction. Conversely, the younger group, <65 years, exhibited no significant changes in loneliness after the intervention. Both the older and younger age groups provided good scores in relation to chatbot design with respect to usability (mean scores of 6.33 and 6.05, respectively) and satisfaction (mean scores of 5.33 and 5.15, respectively), rated on a 7-point Likert scale. Conclusions: The chatbot interface was found to be user-friendly and demonstrated promising results among participants 65 years and older who were receiving care at psychiatric outpatient clinics and experiencing relatively stable symptoms of depression and anxiety. The chatbot not only provided caring companionship but also showed the potential to alleviate loneliness during the challenging circumstances of a pandemic. © 2024 Elsevier B.V., All rights reserved."
124,1,0.6428769182170188,"Background: Adequate sleep is essential for maintaining individual and public health, positively affecting cognition and well-being, and reducing chronic disease risks. It plays a significant role in driving the economy, public safety, and managing health care costs. Digital tools, including websites, sleep trackers, and apps, are key in promoting sleep health education. Conversational artificial intelligence (AI) such as ChatGPT (OpenAI, Microsoft Corp) offers accessible, personalized advice on sleep health but raises concerns about potential misinformation. This underscores the importance of ensuring that AI-driven sleep health information is accurate, given its significant impact on individual and public health, and the spread of sleep-related myths. Objective: This study aims to examine ChatGPT’s capability to debunk sleep-related disbeliefs. Methods: A mixed methods design was leveraged. ChatGPT categorized 20 sleep-related myths identified by 10 sleep experts and rated them in terms of falseness and public health significance, on a 5-point Likert scale. Sensitivity, positive predictive value, and interrater agreement were also calculated. A qualitative comparative analysis was also conducted. Results: ChatGPT labeled a significant portion (n=17, 85%) of the statements as “false” (n=9, 45%) or “generally false” (n=8, 40%), with varying accuracy across different domains. For instance, it correctly identified most myths about “sleep timing,” “sleep duration,” and “behaviors during sleep,” while it had varying degrees of success with other categories such as “pre-sleep behaviors” and “brain function and sleep.” ChatGPT’s assessment of the degree of falseness and public health significance, on the 5-point Likert scale, revealed an average score of 3.45 (SD 0.87) and 3.15 (SD 0.99), respectively, indicating a good level of accuracy in identifying the falseness of statements and a good understanding of their impact on public health. The AI-based tool showed a sensitivity of 85% and a positive predictive value of 100%. Overall, this indicates that when ChatGPT labels a statement as false, it is highly reliable, but it may miss identifying some false statements. When comparing with expert ratings, high intraclass correlation coefficients (ICCs) between ChatGPT’s appraisals and expert opinions could be found, suggesting that the AI’s ratings were generally aligned with expert views on falseness (ICC=.83, P<.001) and public health significance (ICC=.79, P=.001) of sleep-related myths. Qualitatively, both ChatGPT and sleep experts refuted sleep-related misconceptions. However, ChatGPT adopted a more accessible style and provided a more generalized view, focusing on broad concepts, while experts sometimes used technical jargon, providing evidence-based explanations. Conclusions: ChatGPT-4 can accurately address sleep-related queries and debunk sleep-related myths, with a performance comparable to sleep experts, even if, given its limitations, the AI cannot completely replace expert opinions, especially in nuanced and complex fields such as sleep health, but can be a valuable complement in the dissemination of updated information and promotion of healthy behaviors. © 2024 Elsevier B.V., All rights reserved."
125,-1,0.3401931132423692,"Background: Utilizing artificial intelligence (AI) in chatbots, especially for chronic diseases, has become increasingly prevalent. These AI-powered chatbots serve as crucial tools for enhancing patient communication, addressing the rising prevalence of chronic conditions, and meeting the growing demand for supportive healthcare applications. However, there is a notable gap in comprehensive reviews evaluating the impact of AI-powered chatbot interventions in healthcare within academic literature. This study aimed to assess user satisfaction, intervention efficacy, and the specific characteristics and AI architectures of chatbot systems designed for chronic diseases. Method: A thorough exploration of the existing literature was undertaken by employing diverse databases such as PubMed MEDLINE, CINAHL, EMBASE, PsycINFO, ACM Digital Library and Scopus. The studies incorporated in this analysis encompassed primary research that employed chatbots or other forms of AI architecture in the context of preventing, treating or rehabilitating chronic diseases. The assessment of bias risk was conducted using Risk of 2.0 Tools. Results: Seven hundred and eighty-four results were obtained, and subsequently, eight studies were found to align with the inclusion criteria. The intervention methods encompassed health education (n = 3), behaviour change theory (n = 1), stress and coping (n = 1), cognitive behavioural therapy (n = 2) and self-care behaviour (n = 1). The research provided valuable insights into the effectiveness and user-friendliness of AI-powered chatbots in handling various chronic conditions. Overall, users showed favourable acceptance of these chatbots for self-managing chronic illnesses. Conclusions: The reviewed studies suggest promising acceptance of AI-powered chatbots for self-managing chronic conditions. However, limited evidence on their efficacy due to insufficient technical documentation calls for future studies to provide detailed descriptions and prioritize patient safety. These chatbots employ natural language processing and multimodal interaction. Subsequent research should focus on evidence-based evaluations, facilitating comparisons across diverse chronic health conditions. © 2024 Elsevier B.V., All rights reserved."
126,3,1.0,"Artificial intelligence (AI) chatbots have the potential to revolutionize online health information-seeking behavior by delivering up-to-date information on a wide range of health topics. They generate personalized responses to user queries through their ability to process extensive amounts of text, analyze trends, and generate natural language responses. Chatbots can manage infodemic by debunking online health misinformation on a large scale. Nevertheless, system accuracy remains technically challenging. Chatbots require training on diverse and representative datasets, security to protect against malicious actors, and updates to keep up-to-date on scientific progress. Therefore, although AI chatbots hold significant potential in assisting infodemic management, it is essential to approach their outputs with caution due to their current limitations. © 2024 Elsevier B.V., All rights reserved."
127,-1,0.12682300627596713,"Background: A chatbot is a computer program that is designed to simulate conversation with humans. Chatbots may offer rapid, responsive, and private contraceptive information; counseling; and linkages to products and services, which could improve contraceptive knowledge, attitudes, and behaviors. Objective: This review aimed to systematically collate and interpret evidence to determine whether and how chatbots improve contraceptive knowledge, attitudes, and behaviors. Contraceptive knowledge, attitudes, and behaviors include access to contraceptive information, understanding of contraceptive information, access to contraceptive services, contraceptive uptake, contraceptive continuation, and contraceptive communication or negotiation skills. A secondary aim of the review is to identify and summarize best practice recommendations for chatbot development to improve contraceptive outcomes, including the cost-effectiveness of chatbots where evidence is available. Methods: We systematically searched peer-reviewed and gray literature (2010-2022) for papers that evaluated chatbots offering contraceptive information and services. Sources were included if they featured a chatbot and addressed an element of contraception, for example, uptake of hormonal contraceptives. Literature was assessed for methodological quality using appropriate quality assessment tools. Data were extracted from the included sources using a data extraction framework. A narrative synthesis approach was used to collate qualitative evidence as quantitative evidence was too sparse for a quantitative synthesis to be carried out. Results: We identified 15 sources, including 8 original research papers and 7 gray literature papers. These sources included 16 unique chatbots. This review found the following evidence on the impact and efficacy of chatbots: a large, robust randomized controlled trial suggests that chatbots have no effect on intention to use contraception; a small, uncontrolled cohort study suggests increased uptake of contraception among adolescent girls; and a development report, using poor-quality methods, suggests no impact on improved access to services. There is also poor-quality evidence to suggest increased contraceptive knowledge from interacting with chatbot content. User engagement was mixed, with some chatbots reaching wide audiences and others reaching very small audiences. User feedback suggests that chatbots may be experienced as acceptable, convenient, anonymous, and private, but also as incompetent, inconvenient, and unsympathetic. The best practice guidance on the development of chatbots to improve contraceptive knowledge, attitudes, and behaviors is consistent with that in the literature on chatbots in other health care fields. Conclusions: We found limited and conflicting evidence on chatbots to improve contraceptive knowledge, attitudes, and behaviors. Further research that examines the impact of chatbot interventions in comparison with alternative technologies, acknowledges the varied and changing nature of chatbot interventions, and seeks to identify key features associated with improved contraceptive outcomes is needed. The limitations of this review include the limited evidence available on this topic, the lack of formal evaluation of chatbots in this field, and the lack of standardized definition of what a chatbot is. © 2024 Elsevier B.V., All rights reserved."
128,5,0.469560012385962,"Background: Artificial intelligence (AI)–based chatbots could help address some of the challenges patients face in acquiring information essential to their self-health management, including unreliable sources and overburdened health care professionals. Research to ensure the proper design, implementation, and uptake of chatbots is imperative. Inclusive digital health research and responsible AI integration into health care require active and sustained patient and stakeholder engagement, yet corresponding activities and guidance are limited for this purpose. Objective: In response, this manuscript presents a master protocol for the development, testing, and implementation of a chatbot family in partnership with stakeholders. This protocol aims to help efficiently translate an initial chatbot intervention (MARVIN) to multiple health domains and populations. Methods: The MARVIN chatbots study has an adaptive platform trial design consisting of multiple parallel individual chatbot substudies with four common objectives: (1) co-construct a tailored AI chatbot for a specific health care setting, (2) assess its usability with a small sample of participants, (3) measure implementation outcomes (usability, acceptability, appropriateness, adoption, and fidelity) within a large sample, and (4) evaluate the impact of patient and stakeholder partnerships on chatbot development. For objective 1, a needs assessment will be conducted within the setting, involving four 2-hour focus groups with 5 participants each. Then, a co-construction design committee will be formed with patient partners, health care professionals, and researchers who will participate in 6 workshops for chatbot development, testing, and improvement. For objective 2, a total of 30 participants will interact with the prototype for 3 weeks and assess its usability through a survey and 3 focus groups. Positive usability outcomes will lead to the initiation of objective 3, whereby the public will be able to access the chatbot for a 12-month real-world implementation study using web-based questionnaires to measure usability, acceptability, and appropriateness for 150 participants and meta-use data to inform adoption and fidelity. After each objective, for objective 4, focus groups will be conducted with the design committee to better understand their perspectives on the engagement process. Results: From July 2022 to October 2023, this master protocol led to four substudies conducted at the McGill University Health Centre or the Centre hospitalier de l’Université de Montréal (both in Montreal, Quebec, Canada): (1) MARVIN for HIV (large-scale implementation expected in mid-2024), (2) MARVIN-Pharma for community pharmacists providing HIV care (usability study planned for mid-2024), (3) MARVINA for breast cancer, and (4) MARVIN-CHAMP for pediatric infectious conditions (both in preparation, with development to begin in early 2024). Conclusions: This master protocol offers an approach to chatbot development in partnership with patients and health care professionals that includes a comprehensive assessment of implementation outcomes. It also contributes to best practice recommendations for patient and stakeholder engagement in digital health research. © 2024 Elsevier B.V., All rights reserved."
129,1,1.0,"Background: Large language models (LLMs) hold potential for mental health applications. However, their opaque alignment processes may embed biases that shape problematic perspectives. Evaluating the values embedded within LLMs that guide their decision-making have ethical importance. Schwartz’s theory of basic values (STBV) provides a framework for quantifying cultural value orientations and has shown utility for examining values in mental health contexts, including cultural, diagnostic, and therapist-client dynamics. Objective: This study aimed to (1) evaluate whether the STBV can measure value-like constructs within leading LLMs and (2) determine whether LLMs exhibit distinct value-like patterns from humans and each other. Methods: In total, 4 LLMs (Bard, Claude 2, Generative Pretrained Transformer [GPT]-3.5, GPT-4) were anthropomorphized and instructed to complete the Portrait Values Questionnaire—Revised (PVQ-RR) to assess value-like constructs. Their responses over 10 trials were analyzed for reliability and validity. To benchmark the LLMs’ value profiles, their results were compared to published data from a diverse sample of 53,472 individuals across 49 nations who had completed the PVQ-RR. This allowed us to assess whether the LLMs diverged from established human value patterns across cultural groups. Value profiles were also compared between models via statistical tests. Results: The PVQ-RR showed good reliability and validity for quantifying value-like infrastructure within the LLMs. However, substantial divergence emerged between the LLMs’ value profiles and population data. The models lacked consensus and exhibited distinct motivational biases, reflecting opaque alignment processes. For example, all models prioritized universalism and self-direction, while de-emphasizing achievement, power, and security relative to humans. Successful discriminant analysis differentiated the 4 LLMs’ distinct value profiles. Further examination found the biased value profiles strongly predicted the LLMs’ responses when presented with mental health dilemmas requiring choosing between opposing values. This provided further validation for the models embedding distinct motivational value-like constructs that shape their decision-making. Conclusions: This study leveraged the STBV to map the motivational value-like infrastructure underpinning leading LLMs. Although the study demonstrated the STBV can effectively characterize value-like infrastructure within LLMs, substantial divergence from human values raises ethical concerns about aligning these models with mental health applications. The biases toward certain cultural value sets pose risks if integrated without proper safeguards. For example, prioritizing universalism could promote unconditional acceptance even when clinically unwise. Furthermore, the differences between the LLMs underscore the need to standardize alignment processes to capture true cultural diversity. Thus, any responsible integration of LLMs into mental health care must account for their embedded biases and motivation mismatches to ensure equitable delivery across diverse populations. Achieving this will require transparency and refinement of alignment techniques to instill comprehensive human values. © 2024 Elsevier B.V., All rights reserved."
130,1,1.0,"Background: It is thought that ChatGPT, an advanced language model developed by OpenAI, may in the future serve as an AI-assisted decision support tool in medicine. Objective: To evaluate the accuracy of ChatGPT’s recommendations on medical questions related to common cardiac symptoms or conditions. Methods: We tested ChatGPT’s ability to address medical questions in two ways. First, we assessed its accuracy in correctly answering cardiovascular trivia questions (n = 50), based on quizzes for medical professionals. Second, we entered 20 clinical case vignettes on the ChatGPT platform and evaluated its accuracy compared to expert opinion and clinical course. Lastly, we compared the latest research version (v3.5; 27 September 2023) with a prior version (v3.5; 30 January 2023) to evaluate improvement over time. Results: We found that ChatGPT latest version correctly answered 92% of the trivia questions, with slight variation in accuracy in the domains coronary artery disease (100%), pulmonary and venous thrombotic embolism (100%), atrial fibrillation (90%), heart failure (90%) and cardiovascular risk management (80%). In the 20 case vignettes, ChatGPT’s response matched in 17 (85%) of the cases with the actual advice given. Straightforward patient-to-physician questions were all answered correctly (10/10). In more complex cases, where physicians (general practitioners) asked other physicians (cardiologists) for assistance or decision support, ChatGPT was correct in 70% of cases, and otherwise provided incomplete, inconclusive, or inappropriate recommendations when compared with expert consultation. ChatGPT showed significant improvement over time; as the January version correctly answered 74% (vs 92%) of trivia questions (p = 0.031), and correctly answered a mere 50% of complex cases. Conclusions: Our study suggests that ChatGPT has potential as an AI-assisted decision support tool in medicine, particularly for straightforward, low-complex medical questions, but further research is needed to fully evaluate its potential. © 2024 Elsevier B.V., All rights reserved."
131,-1,0.1340216346769542,"Background: Stark disparities exist in maternal and child outcomes and there is a need to provide timely and accurate health information. Objective: In this pilot study, we assessed the feasibility and acceptability of a health chatbot for new mothers of color. Methods: Rosie, a question-and-answer chatbot, was developed as a mobile app and is available to answer questions about pregnancy, parenting, and child development. From January 9, 2023, to February 9, 2023, participants were recruited using social media posts and through engagement with community organizations. Inclusion criteria included being aged ≥14 years, being a woman of color, and either being currently pregnant or having given birth within the past 6 months. Participants were randomly assigned to the Rosie treatment group (15/29, 52% received the Rosie app) or control group (14/29, 48% received a children’s book each month) for 3 months. Those assigned to the treatment group could ask Rosie questions and receive an immediate response generated from Rosie’s knowledgebase. Upon detection of a possible health emergency, Rosie sends emergency resources and relevant hotline information. In addition, a study staff member, who is a clinical social worker, reaches out to the participant within 24 hours to follow up. Preintervention and postintervention tests were completed to qualitatively and quantitatively evaluate Rosie and describe changes across key health outcomes, including postpartum depression and the frequency of emergency room visits. These measurements were used to inform the clinical trial’s sample size calculations. Results: Of 41 individuals who were screened and eligible, 31 (76%) enrolled and 29 (71%) were retained in the study. More than 87% (13/15) of Rosie treatment group members reported using Rosie daily (5/15, 33%) or weekly (8/15, 53%) across the 3-month study period. Most users reported that Rosie was easy to use (14/15, 93%) and provided responses quickly (13/15, 87%). The remaining issues identified included crashing of the app (8/15, 53%), and users were not satisfied with some of Rosie’s answers (12/15, 80%). Mothers in both the Rosie treatment group and control group experienced a decline in depression scores from pretest to posttest periods, but the decline was statistically significant only among treatment group mothers (P=.008). In addition, a low proportion of treatment group infants had emergency room visits (1/11, 9%) compared with control group members (3/13, 23%). Nonetheless, no between-group differences reached statistical significance at P<.05. Conclusions: Rosie was found to be an acceptable, feasible, and appropriate intervention for ethnic and racial minority pregnant women and mothers of infants owing to the chatbot’s ability to provide a personalized, flexible tool to increase the timeliness and accessibility of high-quality health information to individuals during a period of elevated health risks for the mother and child. © 2024 Elsevier B.V., All rights reserved."
132,0,0.7413654792375535,"Background: Primary headaches, including migraine and tension-type headaches, are widespread and have a social, physical, mental, and economic impact. Among the key components of treatment are behavior interventions such as lifestyle modification. Scalable conversational agents (CAs) have the potential to deliver behavior interventions at a low threshold. To our knowledge, there is no evidence of behavioral interventions delivered by CAs for the treatment of headaches. Objective: This study has 2 aims. The first aim was to develop and test a smartphone-based coaching intervention (BalanceUP) for people experiencing frequent headaches, delivered by a CA and designed to improve mental well-being using various behavior change techniques. The second aim was to evaluate the effectiveness of BalanceUP by comparing the intervention and waitlist control groups and assess the engagement and acceptance of participants using BalanceUP. Methods: In an unblinded randomized controlled trial, adults with frequent headaches were recruited on the web and in collaboration with experts and allocated to either a CA intervention (BalanceUP) or a control condition. The effects of the treatment on changes in the primary outcome of the study, that is, mental well-being (as measured by the Patient Health Questionnaire Anxiety and Depression Scale), and secondary outcomes (eg, psychosomatic symptoms, stress, headache-related self-efficacy, intention to change behavior, presenteeism and absenteeism, and pain coping) were analyzed using linear mixed models and Cohen d. Primary and secondary outcomes were self-assessed before and after the intervention, and acceptance was assessed after the intervention. Engagement was measured during the intervention using self-reports and usage data. Results: A total of 198 participants (mean age 38.7, SD 12.14 y; n=172, 86.9% women) participated in the study (intervention group: n=110; waitlist control group: n=88). After the intervention, the intention-to-treat analysis revealed evidence for improved well-being (treatment: β estimate=-3.28, 95% CI -5.07 to -1.48) with moderate between-group effects (Cohen d=-0.66, 95% CI -0.99 to -0.33) in favor of the intervention group. We also found evidence of reduced somatic symptoms, perceived stress, and absenteeism and presenteeism, as well as improved headache management self-efficacy, application of behavior change techniques, and pain coping skills, with effects ranging from medium to large (Cohen d=0.43-1.05). Overall, 64.8% (118/182) of the participants used coaching as intended by engaging throughout the coaching and completing the outro. Conclusions: BalanceUP was well accepted, and the results suggest that coaching delivered by a CA can be effective in reducing the burden of people who experience headaches by improving their well-being. Trial Registration: German Clinical Tr i a l s Register DRKS00017422; https://trialsearch.who.int/Trial2.aspx?TrialID=DRKS00017422. © 2024 Elsevier B.V., All rights reserved."
133,1,0.5871564262226355,"ChatGPT is a new artificial intelligence system that revolutionizes the way how information can be sought and obtained. In this study, the trustworthiness, value, and danger of ChatGPT-generated responses on four vignettes that represented virtual patient questions were evaluated by 20 experts in the domain of congenital heart disease, atrial fibrillation, heart failure, or cholesterol. Experts generally considered ChatGPT-generated responses trustworthy and valuable, with few considering them dangerous. Forty percent of the experts found ChatGPT responses more valuable than Google. Experts appreciated the sophistication and nuances in the responses but also recognized that responses were often incomplete and sometimes misleading. © 2024 Elsevier B.V., All rights reserved."
134,0,1.0,"Background: Low-intensity cognitive behavioral therapy (LICBT) has been implemented by the Improving Access to Psychological Therapies services across England to manage excessive worry associated with generalized anxiety disorder and support emotional well-being. However, barriers to access limit scalability. A solution has been to incorporate LICBT techniques derived from an evidence-based protocol within the Iona Mind Well-being app for Worry management (IMWW) with support provided through an algorithmically driven conversational agent. Objective: This study aims to examine engagement with a mobile phone app to support worry management with specific attention directed toward interaction with specific LICBT techniques and examine the potential to reduce symptoms of anxiety. Methods: Log data were examined with respect to a sample of “engaged” users who had completed at least 1 lesson related to the Worry Time and Problem Solving in-app modules that represented the “minimum dose.” Paired sample 2-tailed t tests were undertaken to examine the potential for IMWW to reduce worry and anxiety, with multivariate linear regressions examining the extent to which completion of each of the techniques led to reductions in worry and anxiety. Results: There was good engagement with the range of specific LICBT techniques included within IMWW. The vast majority of engaged users were able to interact with the cognitive behavioral therapy model and successfully record types of worry. When working through Problem Solving, the conversational agent was successfully used to support the user with lower levels of engagement. Several users engaged with Worry Time outside of the app. Forgetting to use the app was the most common reason for lack of engagement, with features of the app such as completion of routine outcome measures and weekly reflections having lower levels of engagement. Despite difficulties in the collection of end point data, there was a significant reduction in severity for both anxiety (t<inf>53</inf>=5.5; P<.001; 95% CI 2.4-5.2) and low mood (t<inf>53</inf>=2.3; P=.03; 95% CI 0.2-3.3). A statistically significant linear model was also fitted to the Generalized Anxiety Disorder–7 (F<inf>2,51</inf>=6.73; P<.001), while the model predicting changes in the Patient Health Questionnaire–8 did not reach significance (F<inf>2,51</inf>=2.33; P=.11). This indicates that the reduction in these measures was affected by in-app engagement with Worry Time and Problem Solving. Conclusions: Engaged users were able to successfully interact with the LICBT-specific techniques informed by an evidence-based protocol although there were lower completion rates of routine outcome measures and weekly reflections. Successful interaction with the specific techniques potentially contributes to promising data, indicating that IMWW may be effective in the management of excessive worry. A relationship between dose and improvement justifies the use of log data to inform future developments. However, attention needs to be directed toward enhancing interaction with wider features of the app given that larger improvements were associated with greater engagement. © 2025 Elsevier B.V., All rights reserved."
135,-1,0.10717587352937119,"Research suggests participant engagement is a key mediator of mHealth alcohol interventions’ effectiveness in reducing alcohol consumption among users. Understanding the features that promote engagement is critical to maximizing the effectiveness of mHealth-delivered alcohol interventions. The purpose of this study was to identify facilitators and barriers to mHealth alcohol intervention utilization among hazardous-drinking participants who were randomized to use either an app (Step Away) or Artificial Intelligence (AI) chatbot-based intervention for reducing drinking (the Step Away chatbot). We conducted semi-structured interviews from December 2019 to January 2020 with 20 participants who used the app or chatbot for three months, identifying common facilitators and barriers to use. Participants of both interventions reported that tracking their drinking, receiving feedback about their drinking, feeling held accountable, notifications about high-risk drinking times, and reminders to track their drinking promoted continued engagement. Positivity, personalization, gaining insight into their drinking, and daily tips were stronger facilitator themes among bot users, indicating these may be strengths of the AI chatbot-based intervention when compared to a user-directed app. While tracking drinking was a theme among both groups, it was more salient among app users, potentially due to the option to quickly track drinks in the app that was not present with the conversational chatbot. Notification glitches, technology glitches, and difficulty with tracking drinking data were usage barriers for both groups. Lengthy setup processes were a stronger barrier for app users. Repetitiveness of the bot conversation, receipt of non-tailored daily tips, and inability to self-navigate to desired content were reported as barriers by bot users. To maximize engagement with AI interventions, future developers should include tracking to reinforce behavior change self-monitoring and be mindful of repetitive conversations, lengthy setup, and pathways that limit self-directed navigation. © 2024 Elsevier B.V., All rights reserved."
136,4,0.7130230515032642,"Chatbots increase business productivity by handling customer conversations instead of human agents. Similar rationale applies to use chatbots in the healthcare sector, especially for health coaches who converse with clients. Chatbots are nascent in healthcare. Study findings have been mixed in terms of engagement and their impact on outcomes. Questions remain as to chatbot acceptability with coaches and other providers; studies have focused on clients. To clarify perceived benefits of chatbots in HIV interventions we conducted virtual focus groups with 13 research staff, eight community advisory board members, and seven young adults who were HIV intervention trial participants (clients). Our HIV healthcare context is important. Clients represent a promising age demographic for chatbot uptake. They are a marginalized population warranting consideration to avoid technology that limits healthcare access. Focus group participants expressed the value of chatbots for HIV research staff and clients. Staff discussed how chatbot functions, such as automated appointment scheduling and service referrals, could reduce workloads while clients discussed the after-hours convenience of these functions. Participants also emphasized that chatbots should provide relatable conversation, reliable functionality, and would not be appropriate for all clients. Our findings underscore the need to further examine appropriate chatbot functionality in HIV interventions. © 2024 Elsevier B.V., All rights reserved."
137,1,0.684802110384434,"The advent of large language models (LLMs) such as ChatGPT has potential implications for psychological therapies such as cognitive behavioral therapy (CBT). We systematically investigated whether LLMs could recognize an unhelpful thought, examine its validity, and reframe it to a more helpful one. LLMs currently have the potential to offer reasonable suggestions for the identification and reframing of unhelpful thoughts but should not be relied on to lead CBT delivery. © 2025 Elsevier B.V., All rights reserved."
138,0,1.0,"Background: The COVID-19 pandemic exposed a substantial portion of society to multiple stressors, while access to mental health care was limited. To address this, we introduced a digital stepped-care program rooted in cognitive–behavioral therapy (CBT) principles, aiming to alleviate mental health distress among the general public seeking help. Methods: The program comprises a 4-week digital application using “Aury” the chatbot, followed by an optional 6-week online group session for those still symptomatic. A 4-week waiting period separated these steps. Participants entered based on self-identified mental health concerns. Interventions addressed prevalent pandemic mental health issues: sleep disturbances, anxiety, depression, worry/rumination, interpersonal issues, and resource mobilization. Outcomes focused on depressive, anxiety, and somatic symptoms, assessed by the Patient Health Questionnaire (PHQ). Results: Of the 1261 initial participants, postchatbot results (N = 142) indicated small to medium effects (d = 0.412 to d = 0.523). Those finishing the entire program (N = 41) saw substantial symptom decline with medium to large effects (d = 0.757 to d = 0.818). No shifts were seen in the waiting phase. At follow-up 6 months after baseline, both groups—those who only used the chatbot (N = 60; d = 0.284 to d = 0.416) and those who completed the entire program (N = 27; d = 0.854 to d = 0.926)—showed sustained symptom reduction. Comparing groups that received no intervention, used the chatbot only, and completed the entire program, we observed a dose–response effect. Conclusions: This resource-efficient and adaptable digital approach effectively reduced pandemic-induced mental health issues, indicating its potential in crisis periods with limited health resources. Randomized controlled trials are recommended for further validation. Trial Registration: Clinical Trial Registry identifier: DRKS00023220. © 2025 Elsevier B.V., All rights reserved."
139,-1,0.23657317684293072,"Introduction: There has been an unprecedented rise is the use of artificial intelligence (AI) amongst medical fields. Recently, a dialogue agent called ChatGPT (Generative Pre-trained Transformer) has grown in popularity through its use of large language models (LLM) to clearly and precisely generate text on demand. However, the impact of AI on the creation of scientific articles is remains unknown. A retrospective study was carried out with the aim of answering the following questions: identify the presence of text generated by LLM before and after the increased usage of ChatGPT in articles submitted in OTSR; determine if the type of article, the year of submission, and the country of origin, influenced the proportion of text generated, at least in part by AI. Material and methods: A total of 390 English articles were submitted to OTSR in January, February and March 2022 (n = 204) and over the same months of 2023 (n = 186) were analyzed. All articles were analyzed using the ZeroGPT tool, which provides an assumed rate of AI use expressed as a percentage. A comparison of the average rate of AI use was carried out between the articles submitted in 2022 and 2023. This comparison was repeated keeping only the articles with the highest percentage of suspected AI use (greater than 10 and 20%). A secondary analysis was carried out to identify risk factors for AI use. Results: The average percentage of suspected LLM use in the entire cohort was 11% ± 6, with 160 articles (41.0%) having a suspected AI rate greater than 10% and 61 (15.6%) with an assumed AI rate greater than 20%. A comparison between articles submitted in 2022 and 2023 revealed a significant increase in the use of these tools after the launch of ChatGPT 3.5 (9.4% in 2022 and 12.6% in 2023 [p = 0.004]). The number of articles with suspected AI rates of greater than 10 and 20% were significantly higher in 2023: >10%: 71 articles (34.8%) versus 89 articles (47.8%) (p = 0.008) and >20%: 21 articles (10.3%) versus 40 articles (21.5%) (p = 0.002). A risk factor analysis for LLLM use, demonstrated that authors of Asian geographic origin, and the submission year 2023 were associated with a higher rate of suspected AI use. An AI rate >20% was associated to Asian geographical origin with an odds ratio of 1.79 (95% CI: 1.03–3.11) (p = 0.029), while the year of submission being 2023 had an odds ratio of 1.7 (95% CI: 1.1–2.5) (p = 0.02). Conclusion: This study highlights a significant increase in the use of LLM in the writing of articles submitted to the OTSR journal after the launch of ChatGPT 3.5. The increasing use of these models raises questions about originality and plagiarism in scientific research. AI offers creative opportunities but also raises ethical and methodological challenges. Level of evidence: III; case control study. © 2023 Elsevier B.V., All rights reserved."
140,0,1.0,"Background: There is a lack of understanding of the potential utility of a chatbot integrated into a website to support healthy eating among young adults. Therefore, the aim was to interview key informants regarding potential utility and design of a chatbot to: (1) increase young adults’ return rates and engagement with a purpose-built healthy eating website and, (2) improve young adults’ diet quality. Methods: Eighteen qualitative, semi-structured interviews were conducted across three stakeholder groups: (i) experts in dietary behaviour change in young adults (n = 6), (ii) young adult users of a healthy eating website (n = 7), and (iii) experts in chatbot design (n = 5). Interview questions were guided by a behaviour change framework and a template analysis was conducted using NVivo. Results: Interviewees identified three potential roles of a chatbot for supporting healthy eating in young adults; R1: improving healthy eating knowledge and facilitating discovery, R2: reducing time barriers related to healthy eating, R3: providing support and social engagement. To support R1, the following features were suggested: F1: chatbot generated recommendations and F2: triage to website information or externally (e.g., another website) to address current user needs. For R2, suggested features included F3: nudge or behavioural prompts at critical moments and F4: assist users to navigate healthy eating websites. Finally, to support R3 interviewees recommended the following features: F5: enhance interactivity, F6: offer useful anonymous support, F7: facilitate user connection with content in meaningful ways and F8: outreach adjuncts to website (e.g., emails). Additional ‘general’ chatbot features included authenticity, personalisation and effective and strategic development, while the preferred chatbot style and language included tailoring (e.g., age and gender), with a positive and professional tone. Finally, the preferred chatbot message subjects included training (e.g., would you like to see a video to make this recipe?), enablement (e.g., healthy eating doesn’t need to be expensive, we’ve created a budget meal plan, want to see?) and education or informative approaches (e.g., “Did you know bananas are high in potassium which can aid in reducing blood pressure?”). Conclusion: Findings can guide chatbot designers and nutrition behaviour change researchers on potential chatbot roles, features, style and language and messaging in order to support healthy eating knowledge and behaviours in young adults. © 2024 Elsevier B.V., All rights reserved."
141,-1,0.33111832968809835,"Background: Rapid advancements in artificial intelligence (AI) have led to the adoption of AI-driven symptom checkers in primary care. This study aimed to evaluate both patients' and physicians' attitudes towards these tools in Italian general practice settings, focusing on their perceived utility, user satisfaction, and potential challenges. Methods: This feasibility study involved ten general practitioners (GPs) and patients visiting GP offices. The patients used a chatbot-based symptom checker before their medical visit and conducted anamnestic screening for COVID-19 and a medical history algorithm concerning the current medical problem. The entered data were forwarded to the GP as medical history aid. After the medical visit, both physicians and patients evaluated their respective symptoms. Additionally, physicians performed a final overall evaluation of the symptom checker after the conclusion of the practice phase. Results: Most patients did not use symptom checkers. Overall, 49% of patients and 27% of physicians reported being rather or very satisfied with the symptom checker. The most frequent patient-reported reasons for satisfaction were ease of use, precise and comprehensive questions, perceived time-saving potential, and encouragement of self-reflection. Every other patient would consider at-home use of the symptom checker for the first appraisal of health problems to save time, reduce unnecessary visits, and/or as an aid for the physician. Patients’ attitudes towards the symptom checker were not significantly associated with age, sex, or level of education. Most patients (75%) and physicians (84%) indicated that the symptom checker had no effect on the duration of the medical visit. Only a few participants found the use of the symptom checker to be disruptive to the medical visit or its quality. Conclusions: The findings suggest a positive reception of the symptom checker, albeit with differing focus between patients and physicians. With the potential to be integrated further into primary care, these tools require meticulous clinical guidance to maximize their benefits. Trial registration: The study was not registered, as it did not include direct medical intervention on human participants. © 2023 Elsevier B.V., All rights reserved."
142,1,0.5110494267777833,"Background: ChatGPT is an open-source artificial intelligence (AI) chatbot that uses deep learning to produce human-like text dialog. Its potential applications in the scientific community are vast; however, its efficacy on performing comprehensive literature searches, data analysis and report writing in aesthetic plastic surgery topics remains unknown. This study aims to evaluate both the accuracy and comprehensiveness of ChatGPT’s responses to assess its suitability for use in aesthetic plastic surgery research. Methods: Six questions were prompted to ChatGPT on post-mastectomy breast reconstruction. First two questions focused on the current evidence and options for breast reconstruction post-mastectomy, and remaining four questions focused specifically on autologous breast reconstruction. Using the Likert framework, the responses provided by ChatGPT were qualitatively assessed for accuracy and information content by two specialist plastic surgeons with extensive experience in the field. Results: ChatGPT provided relevant, accurate information; however, it lacked depth. It could provide no more than a superficial overview in response to more esoteric questions and generated incorrect references. It created non-existent references, cited wrong journal and date, which poses a significant challenge in maintaining academic integrity and caution of its use in academia. Conclusion: While ChatGPT demonstrated proficiency in summarizing existing knowledge, it created fictitious references which poses a significant concern of its use in academia and healthcare. Caution should be exercised in interpreting its responses in the aesthetic plastic surgical field and should only be used for such with sufficient oversight. Level of Evidence IV: This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266 . © 2024 Elsevier B.V., All rights reserved."
143,-1,0.2514731902567595,"Objective: To assess use of two web-based conversational agents, the Family Sharing Chatbot (FSC) and One Month Chatbot (OMC), by individuals with familial hypercholesterolemia (FH). Methods: FSC and OMC were sent using an opt-out methodology to a cohort of individuals receiving a FH genetic result. Data from 7/1/2021 through 5/12/2022 was obtained from the electronic health record and the chatbots’ HIPAA-secure web portal. Results: Of 175 subjects, 21 (12%) opted out of the chatbots. Older individuals were more likely to opt out. Most (91/154, 59%) preferred receiving chatbots via the patient EHR portal. Seventy-five individuals (49%) clicked the FSC link, 62 (40%) interacted, and 36 (23%) shared a chatbot about their FH result with at least one relative. Ninety-two of the subjects received OMC, 22 (23%) clicked the link and 20 (21%) interacted. Individuals who shared were majority female and younger on average than the overall cohort. Reminders tended to increase engagement. Conclusion: Results demonstrate characteristics relevant to chatbot engagement. Individuals may be more inclined to receive chatbots if integrated within the patient EHR portal. Frequent reminders can potentially improve chatbot utilization. Innovation: FSC and OMC employ innovative digital health technology that can facilitate family communication about hereditary conditions. © 2023 Elsevier B.V., All rights reserved."
144,4,1.0,"INTRODUCTION: Technology advancements have enhanced artificial intelligence, leading to a user shift towards virtual assistants, but a human-centered approach is needed to assess for acceptability and effectiveness. The AGILE chatbot is designed in Kenya with features to redefine the response towards gender-based violence (GBV) among vulnerable populations, including adolescents, young women and men, and sexual and gender minorities, to offer accurate and reliable information among users. METHODS: We conducted an exploratory qualitative study through focus group discussions (FGDs) targeting 150 participants sampled from vulnerable categories; adolescent girls and boys, young women, young men, and sexual and gender minorities. The FGDs included multiple inquiries to assess knowledge and prior interaction with intelligent conversational assistants to inform the user-centric development of a decision-supportive chatbot and a pilot of the chatbot prototype. Each focus group comprised 9-10 members, and the discussions lasted about two hours to gain qualitative user insights and experiences. We used thematic analysis and drew on grounded theory to analyze the data. RESULTS: The analysis resulted in 14 salient themes composed of sexual violence, physical violence, emotional violence, intimate partner violence, female genital mutilation, sexual reproductive health, mental health, help-seeking behaviors/where to seek support, who to talk to, and what information they would like, features of the chatbot, access of chatbot, abuse and HIV, family and community conflicts, and information for self-care. CONCLUSION: Adopting a human-centered approach in designing an effective chatbot with as many human features as possible is crucial in increasing utilization, addressing the gaps presented by marginalized/vulnerable populations, and reducing the current GBV epidemic by moving prevention and response services closer to people in need. This record is sourced from MEDLINE/PubMed, a database of the U.S. National Library of Medicine"
145,1,1.0,"Increased screen time may cause significant health impacts, including harmful effects on mental health. Studies on the association between technological obsessions and their influence on health have been conducted using Deep Learning (DL) and Machine Learning (ML) techniques. The deployment of chatbots in different industries has been proven as a game-changer. We study conversational Artificial Intelligence (AI) systems enabling operators to conduct conversations with machines that resemble those with humans. We design and develop two retrieval-based and generative-based chatbots, each with six designs. Among the retrieval-based chatbots, Vanilla Recurrent Neural Network (RNN) has an accuracy of 83.22%, Long Short Term Memory (LSTM) is 89.87% accurate, Bidirectional LSTM (Bi-LSTM) is 91.57% accurate, Gated Recurrent Unit (GRU) is 65.57% accurate, and Convolution Neural Network (CNN) is 82.33% accurate. In comparison, generative-based chatbots have encoder–decoder designs that are 94.45% accurate. The most significant distinction is that while generative-based chatbots can generate new text, retrieval-based chatbots are restricted to responding to inputs that match the best of the outputs they already know. © 2023 Elsevier B.V., All rights reserved."
146,0,0.51013839544893,"Background Although psychoeducation is generally recommended for the treatment of adult attention-deficit hyperactivity disorder (ADHD), participation in clinical psychoeducation groups is impeded by waiting times and the constrained number of patients who can simultaneously attend a group. Digital psychoeducation attempts are promising, but the rapidly expanding number of apps lack evidence and are mostly limited to only a few implemented interactive elements. Aims To determine the potential of digital, self-guided psychoeducation for adult ADHD, a newly developed interactive chatbot was compared with a previously validated, conventional psychoeducation app. Method Forty adults with ADHD were randomised, of whom 17 participants in each group completed self-guided psychoeducation based on either a chatbot or conventional psychoeducation app between October 2020 and July 2021. ADHD core symptoms were assessed before and after the 3-week interventions, using both the blinded observer-rated Integrated Diagnosis of ADHD in Adulthood interview and the self-rated ADHD Self-Assessment Scale (ADHS-SB). Results Observer- and patient-rated ADHD symptoms were significantly reduced from pre- to post-intervention (observer-rated: mean difference -6.18, 95% CI -8.06 to -4.29; patient-rated: mean difference -2.82, 95% CI -4.98 to -0.67). However, there were no group × intervention interaction effects that would indicate a stronger therapeutic benefit of one of the interventions. Likewise, administered psychoeducational knowledge quizzes did not show differences between the groups. No adverse events were reported. Conclusions Self-guided psychoeducation based on a chatbot or a conventional app appears similarly effective and safe for improving ADHD core symptoms. Future research should compare additional control interventions and examine patient-related outcomes and usability preferences in detail. © 2023 Elsevier B.V., All rights reserved."
147,1,0.6120117144506717,[No abstract available] Writing for Pediatric Critical Care Medicine: Engaging With Citations to References in the Chatbot Generative Pre-Trained Transformer Era Chatbot; Citations; Critical Care; Reading; Writing; Article; Generative Pretrained Transformer; Human; Intensive Care Medicine; Medical Ethics; Medical Literature; Pediatrics; Article; Chatbot; Intensive Care; Pediatric Intensive Care Nursing; Child; Critical Care; Humans; Writing
148,5,1.0,"Objectives: Health-related chatbots have demonstrated early promise for improving self-management behaviors but have seldomly been utilized for hypertension. This research focused on the design, development, and usability evaluation of a chatbot for hypertension self-management, called ""Medicagent.""Materials and Methods: A user-centered design process was used to iteratively design and develop a text-based chatbot using Google Cloud's Dialogflow natural language understanding platform. Then, usability testing sessions were conducted among patients with hypertension. Each session was comprised of: (1) background questionnaires, (2) 10 representative tasks within Medicagent, (3) System Usability Scale (SUS) questionnaire, and (4) a brief semi-structured interview. Sessions were video and audio recorded using Zoom. Qualitative and quantitative analyses were used to assess effectiveness, efficiency, and satisfaction of the chatbot. Results: Participants (n = 10) completed nearly all tasks (98%, 98/100) and spent an average of 18 min (SD = 10 min) interacting with Medicagent. Only 11 (8.6%) utterances were not successfully mapped to an intent. Medicagent achieved a mean SUS score of 78.8/100, which demonstrated acceptable usability. Several participants had difficulties navigating the conversational interface without menu and back buttons, felt additional information would be useful for redirection when utterances were not recognized, and desired a health professional persona within the chatbot. Discussion: The text-based chatbot was viewed favorably for assisting with blood pressure and medication-related tasks and had good usability. Conclusion: Flexibility of interaction styles, handling unrecognized utterances gracefully, and having a credible persona were highlighted as design components that may further enrich the user experience of chatbots for hypertension self-management. © 2023 Elsevier B.V., All rights reserved."
149,1,0.4243934583639523,"Background: ChatGPT is an open-source artificial large language model that uses deep learning to produce human-like text dialogue. This observational study evaluated the ability of ChatGPT to provide informative and accurate responses to a set of hypothetical questions designed to simulate an initial consultation about rhinoplasty. Methods: Nine questions were prompted to ChatGPT on rhinoplasty. The questions were sourced from a checklist published by the American Society of Plastic Surgeons, and the responses were assessed for accessibility, informativeness, and accuracy by Specialist Plastic Surgeons with extensive experience in rhinoplasty. Results: ChatGPT was able to provide coherent and easily comprehensible answers to the questions posed, demonstrating its understanding of natural language in a health-specific context. The responses emphasized the importance of an individualized approach, particularly in aesthetic plastic surgery. However, the study also highlighted ChatGPT’s limitations in providing more detailed or personalized advice. Conclusion: Overall, the results suggest that ChatGPT has the potential to provide valuable information to patients in a medical context, particularly in situations where patients may be hesitant to seek advice from medical professionals or where access to medical advice is limited. However, further research is needed to determine the scope and limitations of AI language models in this domain and to assess the potential benefits and risks associated with their use. Level of Evidence V: Observational study under respected authorities. This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266. © 2023 Elsevier B.V., All rights reserved."
150,-1,0.23965071604699342,"Introduction: The emergence of artificial intelligence (AI) has presented several opportunities to ease human work. AI applications are available for almost every domain of life. A new technology, Chat Generative Pre-Trained Transformer (ChatGPT), was introduced by OpenAI in November 2022, and has become a topic of discussion across the world. ChatGPT-3 has brought many opportunities, as well as ethical and privacy considerations. ChatGPT is a large language model (LLM) which has been trained on the events that happened until 2021. The use of AI and its assisted technologies in scientific writing is against research and publication ethics. Therefore, policies and guidelines need to be developed over the use of such tools in scientific writing. The main objective of the present study was to highlight the use of AI and AI assisted technologies such as the ChatGPT and other chatbots in the scientific writing and in the research domain resulting in bias, spread of inaccurate information and plagiarism. Methodology: Experiments were designed to test the accuracy of ChatGPT when used in research and academic writing. Results: The information provided by ChatGPT was inaccurate and may have far-reaching implications in the field of medical science and engineering. Critical thinking should be encouraged among researchers to raise awareness about the associated privacy and ethical risks. Conclusions: Regulations for ethical and privacy concerns related to the use of ChatGPT in academics and research need to be developed. © 2023 Elsevier B.V., All rights reserved."
151,2,0.22553752958504386,"Chatbots have become increasingly popular in the healthcare industry. In the area of preventive care, chatbots can provide personalized and timely solutions that aid individuals in maintaining their well-being and forestalling the development of chronic conditions. This paper presents GECA, a chatbot designed specifically for preventive care, that offers information, advice, and monitoring to patients who are undergoing home treatment, providing a cost-effective, personalized, and engaging solution. Moreover, its adaptable architecture enables extension to other diseases and conditions seamlessly. The chatbot’s bilingual capabilities enhance accessibility for a wider range of users, including those with reading or writing difficulties, thereby improving the overall user experience. GECA’s ability to connect with external resources offers a higher degree of personalization, which is a crucial aspect in engaging users effectively. The integration of standards and security protocols in these connections allows patient privacy, security and smooth adaptation to emerging healthcare information sources. GECA has demonstrated a remarkable level of accuracy and precision in its interactions with the diverse features, boasting an impressive 97% success rate in delivering accurate responses. Presently, preparations are underway for a pilot project at a Portuguese hospital that will conduct exhaustive testing and evaluate GECA, encompassing aspects such as its effectiveness, efficiency, quality, goal achievability, and user satisfaction. © 2023 Elsevier B.V., All rights reserved."
152,1,0.8093450391949233,"Background: Large language models (LLMs) are garnering wide interest due to their human-like and contextually relevant responses. However, LLMs’ accuracy across specific medical domains has yet been thoroughly evaluated. Myopia is a frequent topic which patients and parents commonly seek information online. Our study evaluated the performance of three LLMs namely ChatGPT-3.5, ChatGPT-4.0, and Google Bard, in delivering accurate responses to common myopia-related queries. Methods: We curated thirty-one commonly asked myopia care-related questions, which were categorised into six domains—pathogenesis, risk factors, clinical presentation, diagnosis, treatment and prevention, and prognosis. Each question was posed to the LLMs, and their responses were independently graded by three consultant-level paediatric ophthalmologists on a three-point accuracy scale (poor, borderline, good). A majority consensus approach was used to determine the final rating for each response. ‘Good’ rated responses were further evaluated for comprehensiveness on a five-point scale. Conversely, ‘poor’ rated responses were further prompted for self-correction and then re-evaluated for accuracy. Findings: ChatGPT-4.0 demonstrated superior accuracy, with 80.6% of responses rated as ‘good’, compared to 61.3% in ChatGPT-3.5 and 54.8% in Google Bard (Pearson's chi-squared test, all p ≤ 0.009). All three LLM-Chatbots showed high mean comprehensiveness scores (Google Bard: 4.35; ChatGPT-4.0: 4.23; ChatGPT-3.5: 4.11, out of a maximum score of 5). All LLM-Chatbots also demonstrated substantial self-correction capabilities: 66.7% (2 in 3) of ChatGPT-4.0's, 40% (2 in 5) of ChatGPT-3.5's, and 60% (3 in 5) of Google Bard's responses improved after self-correction. The LLM-Chatbots performed consistently across domains, except for ‘treatment and prevention’. However, ChatGPT-4.0 still performed superiorly in this domain, receiving 70% ‘good’ ratings, compared to 40% in ChatGPT-3.5 and 45% in Google Bard (Pearson's chi-squared test, all p ≤ 0.001). Interpretation: Our findings underscore the potential of LLMs, particularly ChatGPT-4.0, for delivering accurate and comprehensive responses to myopia-related queries. Continuous strategies and evaluations to improve LLMs’ accuracy remain crucial. Funding: Dr Yih-Chung Tham was supported by the National Medical Research Council of Singapore (NMRC/MOH/HCSAINV21nov-0001). © 2023 Elsevier B.V., All rights reserved."
153,1,0.5925233661279122,"There is growing interest nowadays for artificial intelligence (AI) in all medical fields. Beyond the direct medical application of AI to medical data, generative AI such as “pre-trained transformer” (GPT) could significantly change the ophthalmology landscape, opening up new avenues for enhancing precision, productivity, and patient outcomes. At present, ChatGPT-4 has been investigated in various ways in ophthalmology for research, medical education, and support for clinical decisions purposes. This article intends to demonstrate the application of ChatGPT-4 within the field of ophthalmology by employing a ‘mise en abime’ approach. While we explore its potential to enhance the future of ophthalmology care, we will also carefully outline its current limitations and potential risks. © 2023 Elsevier B.V., All rights reserved."
154,0,1.0,"Background: Obesity is increasing in the pediatric population, and it represents an important risk factor for the life-long development of several diseases. Although health promotion represents the mainstay of obesity prevention and treatment, lifestyle modification programs are often unsuccessful. Objectives: The purpose of this article is to introduce the V-care app, a mobile health platform specifically developed to offer effective interaction and support young people in a long-term obesity treatment, combining different strategies to maximize the results of the lifestyle modification program and minimize the possibility of dropouts. Methods: The V-care app is based on a conventional client–server architecture, but novelties of our approach are the involvement of families in the lifestyle modification program, and the design inspired to psychological/behavioral change theories, with the aim of raising the chance of patients’ compliance to the program. V-care implements a goal-based behavioral intervention, providing specific feedbacks according to the patient's performance. A pilot usability and acceptability study was performed on a sample of thirteen children aged 6–12 years, using a questionnaire with a 5-points Likert scale to evaluate eight system features, identified as essential requirements based on the analysis of strengths and weaknesses of similar systems in literature. Results: The pilot study highlighted very high rate of overall friendliness and perceived utility evaluation, while some critical issues emerged especially for the chatbot section, which may be due to the novelty of the technology. The positive evaluation of the design choices is confirmed by the average score greater than 3 for all the questions. Conclusions: The V-care app represents a digital innovation in the pediatric healthcare, and it could be introduced in children's primary healthcare nationwide, with the aim to offer an intervention program for controlling and preventing childhood obesity. © 2023 Elsevier B.V., All rights reserved."
155,-1,0.13969178360977244,"Communities of color experience higher maternal and infant mortality, as well as a host of other adverse outcomes, during pregnancy and postpartum. To address this, our team is developing a free, user-friendly, question-answering chatbot called Rosie. Chatbots have gained significant popularity due to their scalability and success in individualizing resources. In recent years, scientific communities and researchers have started recognizing this technology's potential to inform communities, promote health outcomes, and address health disparities. The development of Rosie is an interdisciplinary project, with teams focused on the technical build of the application (app), the development of machine learning models, and community outreach, making Rosie a chatbot built with the input from the communities it aims to serve. From June to October 2022, more than 20 demonstration sessions were conducted in Washington, District of Columbia, Maryland, and Virginia, where a total of 109 pregnant women and new mothers of color could interact with Rosie. Results from the live demonstrations showed that 75% of mothers searched for maternity and baby-related information at least once a week and more than 90% of participants expressed the likelihood to use the app. Most of the participants inquired about their baby's development, nutrition for babies, and identifying and addressing the causes of certain symptoms and conditions, accounting for about 80% of the total questions asked. Mother-related questions in the community demonstrations were mainly about pregnancy. The high level of interest in the chatbot is a clear indication of the need for more resources. Rosie aims to help close the racial gap in maternal and infant health disparities by providing new mothers with easy access to reliable health information. © 2023 Elsevier B.V., All rights reserved."
156,2,0.4953220199503693,"Objectives: The COVID-19 pandemic has been a public health hazard since 2020. Preventive measures taken in mainland China and Hong Kong to control the spread of COVID-19, including quarantine, could potentially affect people’s physical and mental health. Methods: We used a snowball sampling method to investigate the experience of people in mainland China and Hong Kong using AI chatbots during the COVID-19 pandemic to obtain information on mental health related to COVID-19, the current situation, and the multi-dimensional experience of using AI chatbots. The people who participated in the survey were residents aged 18-75 in the 2 areas. Results: The effective response rate of the questionnaire was 98%. Concerning demographics, 91.1% of the target group were 18-55 years old. The most important sources of information for the respondents were WeChat and Web pages. There was no difference between Hong Kong and mainland China in terms of access to COVID-19-related mental health information (χ2=0.59, p=.444), and no difference shown in access to information by gender (χ2=0.01, p=.942). There was no difference in age group (χ2=2.97, p=.594) and was not related to whether respondents were in the provincial capital city area (χ2=0.62, p=.429). Age groups “<18 years old” and “56-65 years old” were related to giving a higher (4 or 5) score to AI text questions answering chatbot (p=.030), and there is a positive relationship between the satisfactory of AI text question answering chatbot and that of AI voice question answering chatbot (R2=0.8074, p=.038). Conclusion: There is no significant difference in the use of all-in-one AI platforms in mainland China and Hong Kong, and both have large market potential in the field of AI services for mental health. This platform is suitable for people of all ages in both regions. The results of this study provide forward-looking guidance for our team to develop robots based on an all-in-one AI platform. © 2023 Elsevier B.V., All rights reserved."
157,0,0.727725862855752,"Objective: Physical inactivity is a leading modifiable cause of death and disease worldwide. Population-based interventions to increase physical activity are needed. Existing automated expert systems (e.g., computer-tailored interventions) have significant limitations that result in low long-term effectiveness. Therefore, innovative approaches are needed. This special communication aims to describe and discuss a novel mHealth intervention approach that proactively offers participants with hyper-personalised intervention content adjusted in real-time. Methods: Using machine learning approaches, we propose a novel physical activity intervention approach that can learn and adapt in real-time to achieve high levels of personalisation and user engagement, underpinned by a likeable digital assistant. It will consist of three major components: (1) conversations: to increase user's knowledge on a wide range of activity-related topics underpinned by Natural Language Processing; (2) nudge engine: to provide users with hyper-personalised cues to action underpinned by reinforcement learning (i.e., contextual bandit) and integrating real-time data from activity tracking, GPS, GIS, weather, and user provided data; (3) Q&A: to facilitate users asking any physical activity related questions underpinned by generative AI (e.g., ChatGPT, Bard) for content generation. Results: The detailed concept of the proposed physical activity intervention platform demonstrates the practical application of a just-in-time adaptive intervention applying various machine learning techniques to deliver a hyper-personalised physical activity intervention in an engaging way. Compared to traditional interventions, the novel platform is expected to show potential for increased user engagement and long-term effectiveness due to: (1) using new variables to personalise content (e.g., GPS, weather), (2) providing behavioural support at the right time in real-time, (3) implementing an engaging digital assistant and (4) improving the relevance of content through applying machine learning algorithms. Conclusion: The use of machine learning is on the rise in every aspect of today's society, however few attempts have been undertaken to harness its potential to achieve health behaviour change. By sharing our intervention concept, we contribute to the ongoing dialogue on creating effective methods for promoting health and well-being in the informatics research community. Future research should focus on refining these techniques and evaluating their effectiveness in controlled and real-world circumstances. © 2023 Elsevier B.V., All rights reserved."
158,-1,0.15347409268276488,"BACKGROUND: Perinatal mood disorders are common yet underdiagnosed and un- or undertreated. Barriers exist to accessing perinatal mental health services, including limited availability, time, and cost. Automated conversational agents (chatbots) can deliver evidence-based cognitive behavioral therapy content through text message-based conversations and reduce depression and anxiety symptoms in select populations. Such digital mental health technologies are poised to overcome barriers to mental health care access but need to be evaluated for efficacy, as well as for preliminary feasibility and acceptability among perinatal populations. OBJECTIVE: To evaluate the acceptability and preliminary efficacy of a mental health chatbot for mood management in a general postpartum population. STUDY DESIGN: An unblinded randomized controlled trial was conducted at a tertiary academic center. English-speaking postpartum women aged 18 years or above with a live birth and access to a smartphone were eligible for enrollment prior to discharge from delivery hospitalization. Baseline surveys were administered to all participants prior to randomization to a mental health chatbot intervention or to usual care only. The intervention group downloaded the mental health chatbot smartphone application with perinatal-specific content, in addition to continuing usual care. Usual care consisted of routine postpartum follow up and mental health care as dictated by the patient's obstetric provider. Surveys were administered during delivery hospitalization (baseline) and at 2-, 4-, and 6-weeks postpartum to assess depression and anxiety symptoms. The primary outcome was a change in depression symptoms at 6-weeks as measured using two depression screening tools: Patient Health Questionnaire-9 and Edinburgh Postnatal Depression Scale. Secondary outcomes included anxiety symptoms measured using Generalized Anxiety Disorder-7, and satisfaction and acceptability using validated scales. Based on a prior study, we estimated a sample size of 130 would have sufficient (80%) power to detect a moderate effect size (d=.4) in between group difference on the Patient Health Questionnaire-9. RESULTS: A total of 192 women were randomized equally 1:1 to the chatbot or usual care; of these, 152 women completed the 6-week survey (n=68 chatbot, n=84 usual care) and were included in the final analysis. Mean baseline mental health assessment scores were below positive screening thresholds. At 6-weeks, there was a greater decrease in Patient Health Questionnaire-9 scores among the chatbot group compared to the usual care group (mean decrease=1.32, standard deviation=3.4 vs mean decrease=0.13, standard deviation=3.01, respectively). 6-week mean Edinburgh Postnatal Depression Scale and Generalized Anxiety Disorder-7 scores did not differ between groups and were similar to baseline. 91% (n=62) of the chatbot users were satisfied or highly satisfied with the chatbot, and 74% (n=50) of the intervention group reported use of the chatbot at least once in 2 weeks prior to the 6-week survey. 80% of study participants reported being comfortable with the use of a mobile smartphone application for mood management. CONCLUSION: Use of a chatbot was acceptable to women in the early postpartum period. The sample did not screen positive for depression at baseline and thus the potential of the chatbot to reduce depressive symptoms in this population was limited. This study was conducted in a general obstetric population. Future studies of longer duration in high-risk postpartum populations who screen positive for depression are needed to further understand the utility and efficacy of such digital therapeutics for that population. © 2023 Elsevier B.V., All rights reserved."
159,-1,0.24333226874164987,"Objective: The advent of large language models has triggered a wave of technological advancements in the global AI dialogue system, which has been widely adopted in various fields including medical care. This research aims to investigate the potential of chatbots in the field of gastroenterology nursing. Methods: Two nurses compiled and categorized 20 relevant questions related to gastroenterology nursing, grouping them into four modules. Two chatbot-based AI language models were selected to answer all the questions. The satisfaction levels and satisfaction rates for each module were analyzed to evaluate the performance of the two chatbots. Results: Chatbot A received an overall satisfaction rate of 85% (with 9 very satisfied, 8 satisfied, and 3 dissatisfied responses), while chatbot B had a lower satisfaction rate of 45% (with 0 very satisfied, 9 satisfied, and 11 dissatisfied responses). The satisfaction rates for module 1 (pre-hospital care) were 60% for chatbot A and 20% for chatbot B. In module 2 (health education during hospitalization), chatbot A's satisfaction rate was 100%, while chatbot B's satisfaction was only 60%. For module 3 (continuing care after discharge), chatbot A's satisfaction rate was 100%, while chatbot B's was 40%. Finally, in module 4 (nursing management), chatbot A received an 80% satisfaction rate, compared to chatbot B's 60% satisfaction rate. Conclusion: The performance of chatbot in terms of health education and nursing management for patients during hospitalization is acceptable; Further optimization is needed in terms of pre hospitalization nursing interventions and post discharge continuity care. The performance of different chatbots varies, and intelligent large models need to be tailored to the medical or nursing fields to better apply in the field of digestive disease care. © 2024 Elsevier B.V., All rights reserved."
160,3,0.4890204490311016,"New chatbot models, built on the transformer architecture and trained on large amounts of data, have the potential to transform healthcare, including gastroenterology. In this paper, we synthesized current literature reports on the roles of chatbots, and evaluated their potential applications in various areas such as clinical diagnosis and treatment plans, patient triage, scientific research, and academic writing. We believe that chatbots can improve efficiency and patient outcomes in these fields. However, it is important to acknowledge some challenges that need to be addressed, such as privacy concerns and emotional considerations. Overall, chatbots are expected to have a significant influence on gastroenterology and require more research to comprehensively examine their capabilities. © 2024 Elsevier B.V., All rights reserved."
161,1,1.0,"OBJECTIVES: Artificial intelligence companies have been increasing their initiatives recently to improve the results of chatbots, which are software programs that can converse with a human in natural language. The role of chatbots in health care is deemed worthy of research. OpenAI's ChatGPT is a supervised and empowered machine learning-based chatbot. The aim of this study was to determine the performance of ChatGPT in emergency medicine (EM) triage prediction. METHODS: This was a preliminary, cross-sectional study conducted with case scenarios generated by the researchers based on the emergency severity index (ESI) handbook v4 cases. Two independent EM specialists who were experts in the ESI triage scale determined the triage categories for each case. A third independent EM specialist was consulted as arbiter, if necessary. Consensus results for each case scenario were assumed as the reference triage category. Subsequently, each case scenario was queried with ChatGPT and the answer was recorded as the index triage category. Inconsistent classifications between the ChatGPT and reference category were defined as over-triage (false positive) or under-triage (false negative). RESULTS: Fifty case scenarios were assessed in the study. Reliability analysis showed a fair agreement between EM specialists and ChatGPT (Cohen's Kappa: 0.341). Eleven cases (22%) were over triaged and 9 (18%) cases were under triaged by ChatGPT. In 9 cases (18%), ChatGPT reported two consecutive triage categories, one of which matched the expert consensus. It had an overall sensitivity of 57.1% (95% confidence interval [CI]: 34-78.2), specificity of 34.5% (95% CI: 17.9-54.3), positive predictive value (PPV) of 38.7% (95% CI: 21.8-57.8), negative predictive value (NPV) of 52.6 (95% CI: 28.9-75.6), and an F1 score of 0.461. In high acuity cases (ESI-1 and ESI-2), ChatGPT showed a sensitivity of 76.2% (95% CI: 52.8-91.8), specificity of 93.1% (95% CI: 77.2-99.2), PPV of 88.9% (95% CI: 65.3-98.6), NPV of 84.4 (95% CI: 67.2-94.7), and an F1 score of 0.821. The receiver operating characteristic curve showed an area under the curve of 0.846 (95% CI: 0.724-0.969, P < 0.001) for high acuity cases. CONCLUSION: The performance of ChatGPT was best when predicting high acuity cases (ESI-1 and ESI-2). It may be useful when determining the cases requiring critical care. When trained with more medical knowledge, ChatGPT may be more accurate for other triage category predictions. © 2023 Elsevier B.V., All rights reserved."
162,5,1.0,"Introduction: Gaps in the disease knowledge of People with Haemophilia (PWH) in Senegal are important barriers to the effective management of haemophilia. Digital health systems for chronic diseases in low- and middle-income countries are suggested to improve education and self-management. Artificial Intelligence (AI) chatbots could improve knowledge and support symptom monitoring. Aim: Development process and usability testing of an AI chatbot to assess its future adoption in Senegal. Methods: An AI chatbot prototype was designed based on a multilingual conversational engine using Natural Language Processing. A sequential mixed method was used including a co-creative design process with a task force made up of PWH and medical doctors. Usability was assessed through the System Usability Scale (SUS) questionnaire. Results: An AI chatbot in French and Wolof, named Saytù Hemophilie, was developed for Android and Apple iOS devices. It was assessed as a very usable system with a SUS score of 81.7, above average. 42% would prefer to use the Wolof version even if they were very satisfied with the French version. The level of Wolof in the app did not always correspond to users’ levels. Participants praised its accessibility and reliability, and its ability to enhance self-learning. Conclusions: Findings suggest that a culturally adapted digital conversational agent is likely to be used by PWH in Senegal and their families to improve education and self-management of haemophilia. Relevance and impact are foreseen for other communities in Africa and beyond. © 2023 Elsevier B.V., All rights reserved."
163,1,0.4515518313727183,"Background: In the United States, English language proficiency is widely accepted as a key social determinant of health. For patients with limited English proficiency (LEP), language barriers can make the delivery of perioperative instructions challenging. The purpose of this study was to evaluate whether a multilingual chatbot could effectively engage LEP patients and improve their outcome after total joint arthroplasty (TJA). Methods: We identified 1,282 TJA patients (705 knees, 577 hips) who enrolled in a short message service (SMS) chatbot from 2020-2022. Forty-seven patients enrolled in the chatbot received their messages in a language other than English. A historical control of 68 LEP patients not enrolled in the chatbot was identified. Chi-squared, Fisher's exact test, and t-tests were performed to measure the effect that conversational engagement had on emergency department (ED) visits, hospital readmissions, and reoperations. Results: There was no difference in the conversational engagement between LEP patients and those with English as their primary language (EPL) (12.3 versus 12.2 text responses, P =.959). The LEP cohort who enrolled in the chatbot had fewer readmissions (0% versus 8.3%, P =.013) and a near significant reduction in ED visits (0.9% versus 8.0%, P =.085) compared to those not enrolled. There was no difference in reoperations between the 2 cohorts. Conclusion: LEP and EPL patients engaged equally with the multilingual chatbot. LEP patients who enrolled in the chatbot had fewer readmissions and a near significant reduction in ED visits. Multilingual platforms such as this chatbot may provide more equitable care to our frequently encountered LEP patients. © 2023 Elsevier B.V., All rights reserved."
164,-1,0.2032056549714697,"Digital health assistants (DHAs) are conversational agents incorporated into health systems’ interfaces, exploiting an intuitive interaction format appreciated by the users. At the same time, however, their conversational format can evoke interactional practices typical of health encounters with human doctors that might misguide the users. Awareness of the similarities and differences between novel mediated encounters and more familiar ones helps designers avoid unintended expectations and leverage suitable ones. Focusing on adherence apps, we analytically discuss the structure of DHA-patient encounters against the literature on physician-patient encounters and the specific affordances of DHAs. We synthesize our discussion into a design checklist and add some considerations about DHA with unconstrained natural language interfaces. © 2023 Elsevier B.V., All rights reserved."
165,1,0.8343458903227151,"Objectives: ChatGPT, a tool based on natural language processing (NLP), is on everyone's mind, and several potential applications in healthcare have been already proposed. However, since the ability of this tool to interpret laboratory test results has not yet been tested, the EFLM Working group on Artificial Intelligence (WG-AI) has set itself the task of closing this gap with a systematic approach. Methods: WG-AI members generated 10 simulated laboratory reports of common parameters, which were then passed to ChatGPT for interpretation, according to reference intervals (RI) and units, using an optimized prompt. The results were subsequently evaluated independently by all WG-AI members with respect to relevance, correctness, helpfulness and safety. Results: ChatGPT recognized all laboratory tests, it could detect if they deviated from the RI and gave a test-by-test as well as an overall interpretation. The interpretations were rather superficial, not always correct, and, only in some cases, judged coherently. The magnitude of the deviation from the RI seldom plays a role in the interpretation of laboratory tests, and artificial intelligence (AI) did not make any meaningful suggestion regarding follow-up diagnostics or further procedures in general. Conclusions: ChatGPT in its current form, being not specifically trained on medical data or laboratory data in particular, may only be considered a tool capable of interpreting a laboratory report on a test-by-test basis at best, but not on the interpretation of an overall diagnostic picture. Future generations of similar AIs with medical ground truth training data might surely revolutionize current processes in healthcare, despite this implementation is not ready yet. © 2023 Elsevier B.V., All rights reserved."
166,-1,0.19327895771938486,"Evaluating conversational agents (CAs) that are supposed to be applied in healthcare settings and ensuring their quality is essential to avoid patient harm and ensure efficacy of the CA-delivered intervention. However, a guideline for a standardized quality assessment of health CAs is still missing. The objective of this work is to describe a framework that provides guidance for development and evaluation of health CAs. In previous work, consensus on categories for evaluating health CAs has been found. In this work, we identify concrete metrics, heuristics, and checklists for these evaluation categories to form a framework. We focus on a specific type of health CA, namely rule-based systems that are based on written input and output, have a simple personality without any kind of embodiment. First, we identified relevant metrics, heuristics, and checklists to be linked to the evaluation categories through a literature search. Second, five experts judged the metrics regarding their relevance to be considered within evaluation and development of health CAs. The final framework considers nine aspects from a general perspective, five aspects from a response understanding perspective, one aspect from a response generation perspective, and three aspects from an aesthetics perspective. Existing tools and heuristics specifically designed for evaluating CAs were linked to these evaluation aspects (e.g., Bot usability scale, design heuristics for CAs); tools related to mHealth evaluation were adapted when necessary (e.g., aspects from the ISO technical specification for mHealth Apps). The resulting framework comprises aspects to be considered not only as part of a system evaluation, but already during the development. In particular, aspects related to accessibility or security have to be addressed in the design phase (e.g., which input and output options are provided to ensure accessibility?) and have to be verified after the implementation phase. As a next step, transfer of the framework to other types of health CAs has to be studied. The framework has to be validated by applying it during health CA design and development. © 2023 Elsevier B.V., All rights reserved."
167,-1,0.16650399239138478,"Medical terminology can be challenging for healthcare students due to its unfamiliar and lengthy terms. Traditional methods such as flashcards and memorization can be ineffective and require significant effort. To address this, an online chatbot-based learning model called Termbot was designed to provide an engaging and convenient method for enhancing medical terminology learning. Termbot, accessible through the LINE platform, offers crossword puzzles that turn boring medical terms into a fun learning experience. An experimental study was conducted, which showed that students who trained with Termbot made significant progress in learning medical terms, demonstrating the potential of chatbots to improve learning outcomes. Termbot’s gamified approach to learning can also be applied to other fields, making it a useful tool for students to learn medical terminology conveniently and enjoyably. © 2023 Elsevier B.V., All rights reserved."
168,-1,0.18998110966160045,[No abstract available] Artificial Intelligence Discusses the Role of Artificial Intelligence in Translational Medicine: A JACC: Basic to Translational Science Interview With ChatGPT Artificial Intelligence; Chatbot; Translational Medicine; Article; Artificial Intelligence; Basic Research; Basic Science; Clinical Practice; Electronic Health Record; Futurology; Health Care Delivery; Human; Medical Literature; Natural Language Processing; Patient Care; Personalized Medicine; Translating (language); Translational Medicine; Translational Science; Treatment Outcome
169,-1,0.14422544378499214,"Background: The use of chatbots to address mental health conditions have become increasingly popular in recent years. However, few studies aimed to teach parenting skills through chatbots, and there are no reports on parental user experience. Aim: This study aimed to assess the user experience of a parenting chatbot micro intervention to teach how to praise children in a Spanish-speaking country. Methods: A sample of 89 parents were assigned to the chatbot micro intervention as part of a randomized controlled trial study. Completion rates, engagement, satisfaction, net promoter score, and acceptability were analyzed. Results: 66.3% of the participants completed the intervention. Participants exchanged an average of 49.8 messages (SD = 1.53), provided an average satisfaction score of 4.19 (SD =.79), and reported that they would recommend the chatbot to other parents (net promoter score = 4.63/5; SD =.66). Acceptability level was high (ease of use = 4.66 [SD =.73]; comfortability = 4.76 [SD =.46]; lack of technical problems = 4.69 [SD =.59]; interactivity = 4.51 [SD =.77]; usefulness for everyday life = 4.75 [SD =.54]). Conclusions: Overall, users completed the intervention at a high rate, engaged with the chatbot, were satisfied, would recommend it to others, and reported a high level of acceptability. Chatbots have the potential to teach parenting skills however research on the efficacy of parenting chatbot interventions is needed. © 2023 Elsevier B.V., All rights reserved."
170,-1,0.31147346163158235,"Background: Chatbots enable users to have humanlike conversations on various topics and can vary widely in complexity and functionality. An area of research priority in chatbots is democratizing chatbots to all, removing barriers to entry, such as financial ones, to help make chatbots a possibility for the wider global population to improve access to information, help reduce the digital divide between nations, and improve areas of public good (eg, health communication). Chatbots in this space may help create the potential for improved health outcomes, potentially alleviating some of the burdens on health care providers and systems to be the sole voices of outreach to public health. Objective: This study explored the feasibility of developing a chatbot using approaches that are accessible in low- and middle-resource settings, such as using technology that is low cost, can be developed by nonprogrammers, and can be deployed over social media platforms to reach the broadest-possible audience without the need for a specialized technical team. Methods: This study is presented in 2 parts. First, we detailed the design and development of a chatbot, VWise, including the resources used and development considerations for the conversational model. Next, we conducted a case study of 33 participants who engaged in a pilot with our chatbot. We explored the following 3 research questions: (1) Is it feasible to develop and implement a chatbot addressing a public health issue with only minimal resources? (2) What is the participants' experience with using the chatbot? (3) What kinds of measures of engagement are observed from using the chatbot? Results: A high level of engagement with the chatbot was demonstrated by the large number of participants who stayed with the conversation to its natural end (n=17, 52%), requested to see the free online resource, selected to view all information about a given concern, and returned to have a dialogue about a second concern (n=12, 36%). Conclusions: This study explored the feasibility of and the design and development considerations for a chatbot, VWise. Our early findings from this initial pilot suggest that developing a functioning and low-cost chatbot is feasible, even in low-resource environments. Our results show that low-resource environments can enter the health communication chatbot space using readily available human and technical resources. However, despite these early indicators, many limitations exist in this study and further work with a larger sample size and greater diversity of participants is needed. This study represents early work on a chatbot in its virtual infancy. We hope this study will help provide those who feel chatbot access may be out of reach with a useful guide to enter this space, enabling more democratized access to chatbots for all. © 2024 Elsevier B.V., All rights reserved."
171,-1,0.21955781063286794,"Background: The COVID-19 pandemic influenced many to consider methods to reduce human contact and ease the burden placed on health care workers. Conversational agents or chatbots are a set of technologies that may aid with these challenges. They may provide useful interactions for users, potentially reducing the health care worker burden while increasing user satisfaction. Research aims to understand these potential impacts of chatbots and conversational recommender systems and their associated design features. Objective: The objective of this study was to evaluate user perceptions of the helpfulness of an artificial intelligence chatbot that was offered free to the public in response to COVID-19. The chatbot engaged patients and provided educational information and the opportunity to report symptoms, understand personal risks, and receive referrals for care. Methods: A cross-sectional study design was used to analyze 82,222 chats collected from patients in South Carolina seeking services from the Prisma Health system. Chi-square tests and multinomial logistic regression analyses were conducted to assess the relationship between reported risk factors and perceived chat helpfulness using chats started between April 24, 2020, and April 21, 2022. Results: A total of 82,222 chat series were started with at least one question or response on record; 53,805 symptom checker questions with at least one COVID-19–related activity series were completed, with 5191 individuals clicking further to receive a virtual video visit and 2215 clicking further to make an appointment with a local physician. Patients who were aged >65 years (P<.001), reported comorbidities (P<.001), had been in contact with a person with COVID-19 in the last 14 days (P<.001), and responded to symptom checker questions that placed them at a higher risk of COVID-19 (P<.001) were 1.8 times more likely to report the chat as helpful than those who reported lower risk factors. Users who engaged with the chatbot to conduct a series of activities were more likely to find the chat helpful (P<.001), including seeking COVID-19 information (3.97-4.07 times), in-person appointments (2.46-1.99 times), telehealth appointments with a nearby provider (2.48-1.9 times), or vaccination (2.9-3.85 times) compared with those who did not perform any of these activities. Conclusions: Chatbots that are designed to target high-risk user groups and provide relevant actionable items may be perceived as a helpful approach to early contact with the health system for assessing communicable disease symptoms and follow-up care options at home before virtual or in-person contact with health care providers. The results identified and validated significant design factors for conversational recommender systems, including triangulating a high-risk target user population and providing relevant actionable items for users to choose from as part of user engagement. © 2025 Elsevier B.V., All rights reserved."
172,1,0.40354297498854524,"Background and objective: Chat Generative Pre-trained Transformer (ChatGPT) is an artificial intelligence (AI)-based language processing model using deep learning to create human-like text dialogue. It has been a popular source of information covering vast number of topics including medicine. Patient education in head and neck cancer (HNC) is crucial to enhance the understanding of patients about their medical condition, diagnosis, and treatment options. Therefore, this study aims to examine the accuracy and reliability of ChatGPT in answering questions regarding HNC. Methods: 154 head and neck cancer-related questions were compiled from sources including professional societies, institutions, patient support groups, and social media. These questions were categorized into topics like basic knowledge, diagnosis, treatment, recovery, operative risks, complications, follow-up, and cancer prevention. ChatGPT was queried with each question, and two experienced head and neck surgeons assessed each response independently for accuracy and reproducibility. Responses were rated on a scale: (1) comprehensive/correct, (2) incomplete/partially correct, (3) a mix of accurate and inaccurate/misleading, and (4) completely inaccurate/irrelevant. Discrepancies in grading were resolved by a third reviewer. Reproducibility was evaluated by repeating questions and analyzing grading consistency. Results: ChatGPT yielded “comprehensive/correct” responses to 133/154 (86.4%) of the questions whereas, rates of “incomplete/partially correct” and “mixed with accurate and inaccurate data/misleading” responses were 11% and 2.6%, respectively. There were no “completely inaccurate/irrelevant” responses. According to category, the model provided “comprehensive/correct” answers to 80.6% of questions regarding “basic knowledge”, 92.6% related to “diagnosis”, 88.9% related to “treatment”, 80% related to “recovery – operative risks – complications – follow-up”, 100% related to “cancer prevention” and 92.9% related to “other”. There was not any significant difference between the categories regarding the grades of ChatGPT responses (p=0.88). The rate of reproducibility was 94.1% (145 of 154 questions). Conclusion: ChatGPT generated substantially accurate and reproducible information to diverse medical queries related to HNC. Despite its limitations, it can be a useful source of information for both patients and medical professionals. With further developments in the model, ChatGPT can also play a crucial role in clinical decision support to provide the clinicians with up-to-date information. © 2023 Elsevier B.V., All rights reserved."
173,-1,0.3198595086251784,"Background: Chatbots have the potential to enhance health care interaction, satisfaction, and service delivery. However, data regarding their acceptance across diverse patient populations are limited. In-depth studies on the reception of chatbots by patients with chronic autoimmune inflammatory diseases are lacking, although such studies are vital for facilitating the effective integration of chatbots in rheumatology care. Objective: We aim to assess patient perceptions and acceptance of a chatbot designed for autoimmune inflammatory rheumatic diseases (AIIRDs). Methods: We administered a comprehensive survey in an outpatient setting at a top-tier rheumatology referral center. The target cohort included patients who interacted with a chatbot explicitly tailored to facilitate diagnosis and obtain information on AIIRDs. Following the RE-AIM (Reach, Effectiveness, Adoption, Implementation and Maintenance) framework, the survey was designed to gauge the effectiveness, user acceptability, and implementation of the chatbot. Results: Between June and October 2022, we received survey responses from 200 patients, with an equal number of 100 initial consultations and 100 follow-up (FU) visits. The mean scores on a 5-point acceptability scale ranged from 4.01 (SD 0.63) to 4.41 (SD 0.54), indicating consistently high ratings across the different aspects of chatbot performance. Multivariate regression analysis indicated that having a FU visit was significantly associated with a greater willingness to reuse the chatbot for symptom determination (P=.01). Further, patients’ comfort with chatbot diagnosis increased significantly after meeting physicians (P<.001). We observed no significant differences in chatbot acceptance according to sex, education level, or diagnosis category. Conclusions: This study underscores that chatbots tailored to AIIRDs have a favorable reception. The inclination of FU patients to engage with the chatbot signifies the possible influence of past clinical encounters and physician affirmation on its use. Although further exploration is required to refine their integration, the prevalent positive perceptions suggest that chatbots have the potential to strengthen the bridge between patients and health care providers, thus enhancing the delivery of rheumatology care to various cohorts. © 2024 Elsevier B.V., All rights reserved."
174,4,0.1921654124162567,"Background: Reproductive health conditions such as endometriosis, uterine fibroids, and polycystic ovary syndrome (PCOS) affect a large proportion of women and people who menstruate worldwide. Prevalence estimates for these conditions range from 5% to 40% of women of reproductive age. Long diagnostic delays, up to 12 years, are common and contribute to health complications and increased health care costs. Symptom checker apps provide users with information and tools to better understand their symptoms and thus have the potential to reduce the time to diagnosis for reproductive health conditions. Objective: This study aimed to evaluate the agreement between clinicians and 3 symptom checkers (developed by Flo Health UK Limited) in assessing symptoms of endometriosis, uterine fibroids, and PCOS using vignettes. We also aimed to present a robust example of vignette case creation, review, and classification in the context of predeployment testing and validation of digital health symptom checker tools. Methods: Independent general practitioners were recruited to create clinical case vignettes of simulated users for the purpose of testing each condition symptom checker; vignettes created for each condition contained a mixture of condition-positive and condition-negative outcomes. A second panel of general practitioners then reviewed, approved, and modified (if necessary) each vignette. A third group of general practitioners reviewed each vignette case and designated a final classification. Vignettes were then entered into the symptom checkers by a fourth, different group of general practitioners. The outcomes of each symptom checker were then compared with the final classification of each vignette to produce accuracy metrics including percent agreement, sensitivity, specificity, positive predictive value, and negative predictive value. Results: A total of 24 cases were created per condition. Overall, exact matches between the vignette general practitioner classification and the symptom checker outcome were 83% (n=20) for endometriosis, 83% (n=20) for uterine fibroids, and 88% (n=21) for PCOS. For each symptom checker, sensitivity was reported as 81.8% for endometriosis, 84.6% for uterine fibroids, and 100% for PCOS; specificity was reported as 84.6% for endometriosis, 81.8% for uterine fibroids, and 75% for PCOS; positive predictive value was reported as 81.8% for endometriosis, 84.6% for uterine fibroids, 80% for PCOS; and negative predictive value was reported as 84.6% for endometriosis, 81.8% for uterine fibroids, and 100% for PCOS. Conclusions: The single-condition symptom checkers have high levels of agreement with general practitioner classification for endometriosis, uterine fibroids, and PCOS. Given long delays in diagnosis for many reproductive health conditions, which lead to increased medical costs and potential health complications for individuals and health care providers, innovative health apps and symptom checkers hold the potential to improve care pathways. © 2023 Elsevier B.V., All rights reserved."
175,-1,0.19880869706726784,"Background: Patient-generated health data are important in the management of several diseases. Although there are limitations, information can be obtained using a wearable device and time-related information such as exercise time or sleep time can also be obtained. Fitbits can be used to acquire sleep onset, sleep offset, total sleep time (TST), and wakefulness after sleep onset (WASO) data, although there are limitations regarding the depth of sleep and satisfaction; therefore, the patient’s subjective response is still important information that cannot be replaced by wearable devices. Objective: To effectively use patient-generated health data related to time such as sleep, it is first necessary to understand the characteristics of the time response recorded by the user. Therefore, the aim of this study was to analyze the characteristics of individuals’ time perception in comparison with wearable data. Methods: Sleep data were acquired for 2 weeks using a Fitbit. Participants’ sleep records were collected daily through chatbot conversations while wearing the Fitbit, and the two sets of data were statistically compared. Results: In total, 736 people aged 30-59 years were recruited for this study, and the sleep data of 543 people who wore a Fitbit and responded to the chatbot for more than 7 days on the same day were analyzed. Research participants tended to respond to sleep-related times on the hour or in 30-minute increments, and each participant responded within the range of 60-90 minutes from the value measured by the Fitbit. On average for all participants, the chat responses and the Fitbit data were similar within a difference of approximately 15 minutes. Regarding sleep onset, the participant response was 8 minutes and 39 seconds (SD 58 minutes) later than that of the Fitbit data, whereas with respect to sleep offset, the response was 5 minutes and 38 seconds (SD 57 minutes) earlier. The participants’ actual sleep time (AST) indicated in the chat was similar to that obtained by subtracting the WASO from the TST measured by the Fitbit. The AST was 13 minutes and 39 seconds (SD 87 minutes) longer than the time WASO was subtracted from the Fitbit TST. On days when the participants reported good sleep, they responded 19 (SD 90) minutes longer on the AST than the Fitbit data. However, for each sleep event, the probability that the participant’s AST was within ±30 and ±60 minutes of the Fitbit TST-WASO was 50.7% and 74.3%, respectively. Conclusions: The chatbot sleep response and Fitbit measured time were similar on average and the study participants had a slight tendency to perceive a relatively long sleep time if the quality of sleep was self-reported as good. However, on a participant-by-participant basis, it was difficult to predict participants’ sleep duration responses with Fitbit data. Individual variations in sleep time perception significantly affect patient responses related to sleep, revealing the limitations of objective measures obtained through wearable devices. © 2023 Elsevier B.V., All rights reserved."
176,0,1.0,"Background: Globally, the high prevalence of mental disorders among university students is a growing public health problem, yet a small minority of students with mental health problems receive treatment. Digital mental health solutions could bridge treatment gaps and overcome many barriers students face accessing treatment. However, there is scant evidence, especially in South Africa (SA), relating to university students’ use of and intention to use digital mental health solutions or their attitudes towards these technologies. We aim to explore university 2students attitudes towards and perceptions of digital mental health solutions, and the factors associated with their intention to use them. Methods: University students from four SA universities (n = 17 838) completed an online survey to assess experience with, attitudes and perceptions of, and intentions to use, digital mental health solutions. We conducted an exploratory factor analysis to identify factors underlying attitudes and perceptions, and then used multivariate ordinal regression analysis was used to investigate the factors’ association with students’ intention to use digital mental health solutions. Results: Intention to use digital mental health solutions was high, and attitudes towards and perceptions of digital mental health solutions were largely positive. Importantly, our analysis also shows that 12.6% of users were willing to utilise some form of digital mental health solutions but were unwilling to utilise traditional face-to-face therapies. The greatest proportion of variance was explained by the factor ‘Attitudes towards digital technologies’ utility to improve student counselling services, provided they are safe’. Conclusion: SA university students are already engaging with digital mental health solutions, and their intention to do so is high. Certain attitudes and perceptions, particularly concerning the utility, effectiveness, and safety, underlie willingness to engage with these solutions, providing potential targets for interventions to increase uptake. © 2023 Elsevier B.V., All rights reserved."
177,3,1.0,"Background: Outpatient chemotherapy often leaves patients to grapple with a range of complex side effects at home. Leveraging tailored evidence-based content to monitor and manage these symptoms remains an untapped potential among patients with gastrointestinal (GI) cancer. Objective: This study aims to bridge the gap in outpatient chemotherapy care by integrating a cutting-edge text messaging system with a chatbot interface. This approach seeks to enable real-time monitoring and proactive management of side effects in patients with GI cancer undergoing intravenous chemotherapy. Methods: Real-Time Chemotherapy-Associated Side Effects Monitoring Supportive System (RT-CAMSS) was developed iteratively, incorporating patient-centered inputs and evidence-based information. It synthesizes chemotherapy knowledge, self-care symptom management skills, emotional support, and healthy lifestyle recommendations. In a single-arm 2-month pilot study, patients with GI cancer undergoing chemotherapy received tailored intervention messages thrice a week and a weekly Patient-Reported Outcomes Version of the Common Terminology Criteria for Adverse Events–based symptom assessment via a chatbot interface. Baseline and postintervention patient surveys and interviews were conducted. Results: Out of 45 eligible patients, 34 were enrolled (76% consent rate). The mean age was 61 (SD 12) years, with 19 (56%) being females and 21 (62%) non-Hispanic White. The most common cancer type was pancreatic (n=18, 53%), followed by colon (n=12, 35%) and stomach (n=4, 12%). In total, 27 (79% retention rate) participants completed the postintervention follow-up. In total, 20 patients texted back at least once to seek additional information, with the keyword “chemo” or “support” texted the most. Among those who used the chatbot system checker, fatigue emerged as the most frequently reported symptom (n=15), followed by neuropathy (n=7). Adjusted for multiple comparisons, patients engaging with the platform exhibited significantly improved Patient Activation Measure (3.70, 95% CI –6.919 to –0.499; P=.02). Postintervention interviews and satisfaction surveys revealed that participants found the intervention was user-friendly and were provided with valuable information. Conclusions: Capitalizing on mobile technology communication holds tremendous scalability for enhancing health care services. This study presents initial evidence of the engagement and acceptability of RT-CAMSS, warranting further evaluation in a controlled clinical trial setting. © 2023 Elsevier B.V., All rights reserved."
178,1,1.0,"Background: ChatGPT has gained global attention recently owing to its high performance in generating a wide range of information and retrieving any kind of data instantaneously. ChatGPT has also been tested for the United States Medical Licensing Examination (USMLE) and has successfully cleared it. Thus, its usability in medical education is now one of the key discussions worldwide. Objective: The objective of this study is to evaluate the performance of ChatGPT in medical biochemistry using clinical case vignettes. Methods: The performance of ChatGPT was evaluated in medical biochemistry using 10 clinical case vignettes. Clinical case vignettes were randomly selected and inputted in ChatGPT along with the response options. We tested the responses for each clinical case twice. The answers generated by ChatGPT were saved and checked using our reference material. Results: ChatGPT generated correct answers for 4 questions on the first attempt. For the other cases, there were differences in responses generated by ChatGPT in the first and second attempts. In the second attempt, ChatGPT provided correct answers for 6 questions and incorrect answers for 4 questions out of the 10 cases that were used. But, to our surprise, for case 3, different answers were obtained with multiple attempts. We believe this to have happened owing to the complexity of the case, which involved addressing various critical medical aspects related to amino acid metabolism in a balanced approach. Conclusions: According to the findings of our study, ChatGPT may not be considered an accurate information provider for application in medical education to improve learning and assessment. However, our study was limited by a small sample size (10 clinical case vignettes) and the use of the publicly available version of ChatGPT (version 3.5). Although artificial intelligence (AI) has the capability to transform medical education, we emphasize the validation of such data produced by such AI systems for correctness and dependability before it could be implemented in practice. © 2023 Elsevier B.V., All rights reserved."
179,3,1.0,"Artificial intelligence (AI)-powered chatbots have the potential to substantially increase access to affordable and effective mental health services by supplementing the work of clinicians. Their 24/7 availability and accessibility through a mobile phone allow individuals to obtain help whenever and wherever needed, overcoming financial and logistical barriers. Although psychological AI chatbots have the ability to make significant improvements in providing mental health care services, they do not come without ethical and technical challenges. Some major concerns include providing inadequate or harmful support, exploiting vulnerable populations, and potentially producing discriminatory advice due to algorithmic bias. However, it is not always obvious for users to fully understand the nature of the relationship they have with chatbots. There can be significant misunderstandings about the exact purpose of the chatbot, particularly in terms of care expectations, ability to adapt to the particularities of users and responsiveness in terms of the needs and resources/treatments that can be offered. Hence, it is imperative that users are aware of the limited therapeutic relationship they can enjoy when interacting with mental health chatbots. Ignorance or misunderstanding of such limitations or of the role of psychological AI chatbots may lead to a therapeutic misconception (TM) where the user would underestimate the restrictions of such technologies and overestimate their ability to provide actual therapeutic support and guidance. TM raises major ethical concerns that can exacerbate one's mental health contributing to the global mental health crisis. This paper will explore the various ways in which TM can occur particularly through inaccurate marketing of these chatbots, forming a digital therapeutic alliance with them, receiving harmful advice due to bias in the design and algorithm, and the chatbots inability to foster autonomy with patients. © 2023 Elsevier B.V., All rights reserved."
180,4,1.0,"Integrating pleasure may be a successful strategy for reaching young people with sexual and reproductive health and rights (SRHR) interventions. However, sexual pleasure-related programming and research remains sparse. We aimed to assess chatbot acceptability and describe changes in SRHR attitudes and behaviours among Kenyan young adults engaging with a pleasure-oriented SRHR chatbot. We used an exploratory mixed-methods study design. Between November 2021 and January 2022, participants completed a self-administered online questionnaire before and after chatbot engagement. In-depth phone interviews were conducted among a select group of participants after their initial chatbot engagement. Quantitative data were analysed using paired analyses and interviews were analysed using thematic content analysis. Of 301 baseline participants, 38% (115/301) completed the endline survey, with no measured baseline differences between participants who did and did not complete the endline survey. In-depth interviews were conducted among 41 participants. We observed higher satisfaction at endline vs. baseline on reported ability to exercise sexual rights (P ≤ 0.01), confidence discussing contraception (P ≤ 0.02) and sexual feelings/needs (P ≤ 0.001) with their sexual partner(s). Qualitative interviews indicated that most participants valued the chatbot as a confidential and free-of-judgment source of trustworthy “on-demand” SRHR information. Participants reported improvements in sex-positive communication with partners and safer sex practices due to new learnings from the chatbot. We observed increases in SRHR empowerment among young Kenyans after engagement with the chatbot. Integrating sexual pleasure into traditional SRHR content delivered through digital tools is a promising strategy to advance positive SRHR attitudes and practices among youth. © 2023 Elsevier B.V., All rights reserved."
181,3,1.0,[No abstract available] AI chatbots and (mis)information in public health: impact on vulnerable communities Artificial Intelligence; Chatbot; Chatgpt; Global South; Llm; Public Health; Vulnerable Communities; Public Health; Public Health
182,0,0.49568148402404644,"Background: The delivery of education on pain neuroscience and the evidence for different treatment approaches has become a key component of contemporary persistent pain management. Chatbots, or more formally conversation agents, are increasingly being used in health care settings due to their versatility in providing interactive and individualized approaches to both capture and deliver information. Research focused on the acceptability of diverse chatbot formats can assist in developing a better understanding of the educational needs of target populations. Objective: This study aims to detail the development and initial pilot testing of a multimodality pain education chatbot (Dolores) that can be used across different age groups and investigate whether acceptability and feedback were comparable across age groups following pilot testing. Methods: Following an initial design phase involving software engineers (n=2) and expert clinicians (n=6), a total of 60 individuals with chronic pain who attended an outpatient clinic at 1 of 2 pain centers in Australia were recruited for pilot testing. The 60 individuals consisted of 20 (33%) adolescents (aged 10-18 years), 20 (33%) young adults (aged 19-35 years), and 20 (33%) adults (aged >35 years) with persistent pain. Participants spent 20 to 30 minutes completing interactive chatbot activities that enabled the Dolores app to gather a pain history and provide education about pain and pain treatments. After the chatbot activities, participants completed a custom-made feedback questionnaire measuring the acceptability constructs pertaining to health education chatbots. To determine the effect of age group on the acceptability ratings and feedback provided, a series of binomial logistic regression models and cumulative odds ordinal logistic regression models with proportional odds were generated. Results: Overall, acceptability was high for the following constructs: engagement, perceived value, usability, accuracy, responsiveness, adoption intention, esthetics, and overall quality. The effect of age group on all acceptability ratings was small and not statistically significant. An analysis of open-ended question responses revealed that major frustrations with the app were related to Dolores’ speech, which was explored further through a comparative analysis. With respect to providing negative feedback about Dolores’ speech, a logistic regression model showed that the effect of age group was statistically significant (χ2<inf>2</inf>=11.7; P=.003) and explained 27.1% of the variance (Nagelkerke R2). Adults and young adults were less likely to comment on Dolores’ speech compared with adolescent participants (odds ratio 0.20, 95% CI 0.05-0.84 and odds ratio 0.05, 95% CI 0.01-0.43, respectively). Comments were related to both speech rate (too slow) and quality (unpleasant and robotic). Conclusions: This study provides support for the acceptability of pain history and education chatbots across different age groups. Chatbot acceptability for adolescent cohorts may be improved by enabling the self-selection of speech characteristics such as rate and personable tone. © 2023 Elsevier B.V., All rights reserved."
183,-1,0.19958124645627454,"Background: Conversational agents (CAs), or chatbots, are computer programs that simulate conversations with humans. The use of CAs in health care settings is recent and rapidly increasing, which often translates to poor reporting of the CA development and evaluation processes and unreliable research findings. We developed and published a conceptual framework, designing, developing, evaluating, and implementing a smartphone-delivered, rule-based conversational agent (DISCOVER), consisting of 3 iterative stages of CA design, development, and evaluation and implementation, complemented by 2 cross-cutting themes (user-centered design and data privacy and security). Objective: This study aims to perform in-depth, semistructured interviews with multidisciplinary experts in health care CAs to share their views on the definition and classification of health care CAs and evaluate and validate the DISCOVER conceptual framework. Methods: We conducted one-on-one semistructured interviews via Zoom (Zoom Video Communications) with 12 multidisciplinary CA experts using an interview guide based on our framework. The interviews were audio recorded, transcribed by the research team, and analyzed using thematic analysis. Results: Following participants’ input, we defined CAs as digital interfaces that use natural language to engage in a synchronous dialogue using ≥1 communication modality, such as text, voice, images, or video. CAs were classified by 13 categories: response generation method, input and output modalities, CA purpose, deployment platform, CA development modality, appearance, length of interaction, type of CA-user interaction, dialogue initiation, communication style, CA personality, human support, and type of health care intervention. Experts considered that the conceptual framework could be adapted for artificial intelligence–based CAs. However, despite recent advances in artificial intelligence, including large language models, the technology is not able to ensure safety and reliability in health care settings. Finally, aligned with participants’ feedback, we present an updated iteration of the conceptual framework for health care conversational agents (CHAT) with key considerations for CA design, development, and evaluation and implementation, complemented by 3 cross-cutting themes: ethics, user involvement, and data privacy and security. Conclusions: We present an expanded, validated CHAT and aim at guiding researchers from a variety of backgrounds and with different levels of expertise in the design, development, and evaluation and implementation of rule-based CAs in health care settings. © 2023 Elsevier B.V., All rights reserved."
184,1,0.7389272970435872,"Background: As advancements in artificial intelligence (AI) continue, large language models (LLMs) have emerged as promising tools for generating medical information. Their rapid adaptation and potential benefits in health care require rigorous assessment in terms of the quality, accuracy, and safety of the generated information across diverse medical specialties. Objective: This study aimed to evaluate the performance of 4 prominent LLMs, namely, Claude-instant-v1.0, GPT-3.5-Turbo, Command-xlarge-nightly, and Bloomz, in generating medical content spanning the clinical specialties of ophthalmology, orthopedics, and dermatology. Methods: Three domain-specific physicians evaluated the AI-generated therapeutic recommendations for a diverse set of 60 diseases. The evaluation criteria involved the mDISCERN score, correctness, and potential harmfulness of the recommendations. ANOVA and pairwise t tests were used to explore discrepancies in content quality and safety across models and specialties. Additionally, using the capabilities of OpenAI’s most advanced model, GPT-4, an automated evaluation of each model’s responses to the diseases was performed using the same criteria and compared to the physicians’ assessments through Pearson correlation analysis. Results: Claude-instant-v1.0 emerged with the highest mean mDISCERN score (3.35, 95% CI 3.23-3.46). In contrast, Bloomz lagged with the lowest score (1.07, 95% CI 1.03-1.10). Our analysis revealed significant differences among the models in terms of quality (P<.001). Evaluating their reliability, the models displayed strong contrasts in their falseness ratings, with variations both across models (P<.001) and specialties (P<.001). Distinct error patterns emerged, such as confusing diagnoses; providing vague, ambiguous advice; or omitting critical treatments, such as antibiotics for infectious diseases. Regarding potential harm, GPT-3.5-Turbo was found to be the safest, with the lowest harmfulness rating. All models lagged in detailing the risks associated with treatment procedures, explaining the effects of therapies on quality of life, and offering additional sources of information. Pearson correlation analysis underscored a substantial alignment between physician assessments and GPT-4’s evaluations across all established criteria (P<.01). Conclusions: This study, while comprehensive, was limited by the involvement of a select number of specialties and physician evaluators. The straightforward prompting strategy (“How to treat…”) and the assessment benchmarks, initially conceptualized for human-authored content, might have potential gaps in capturing the nuances of AI-driven information. The LLMs evaluated showed a notable capability in generating valuable medical content; however, evident lapses in content quality and potential harm signal the need for further refinements. Given the dynamic landscape of LLMs, this study’s findings emphasize the need for regular and methodical assessments, oversight, and fine-tuning of these AI tools to ensure they produce consistently trustworthy and clinically safe medical advice. Notably, the introduction of an auto-evaluation mechanism using GPT-4, as detailed in this study, provides a scalable, transferable method for domain-agnostic evaluations, extending beyond therapy recommendation assessments. © 2023 Elsevier B.V., All rights reserved."
185,0,0.32296575740468864,"Background: Artificial intelligence chatbot research has focused on technical advances in natural language processing and validating the effectiveness of human-machine conversations in specific settings. However, real-world chat data remain proprietary and unexplored despite their growing popularity, and new analyses of chatbot uses and their effects on mitigating negative moods are urgently needed. Objective: In this study, we investigated whether and how artificial intelligence chatbots facilitate the expression of user emotions, specifically sadness and depression. We also examined cultural differences in the expression of depressive moods among users in Western and Eastern countries. Methods: This study used SimSimi, a global open-domain social chatbot, to analyze 152,783 conversation utterances containing the terms “depress” and “sad” in 3 Western countries (Canada, the United Kingdom, and the United States) and 5 Eastern countries (Indonesia, India, Malaysia, the Philippines, and Thailand). Study 1 reports new findings on the cultural differences in how people talk about depression and sadness to chatbots based on Linguistic Inquiry and Word Count and n-gram analyses. In study 2, we classified chat conversations into predefined topics using semisupervised classification techniques to better understand the types of depressive moods prevalent in chats. We then identified the distinguishing features of chat-based depressive discourse data and the disparity between Eastern and Western users. Results: Our data revealed intriguing cultural differences. Chatbot users in Eastern countries indicated stronger emotions about depression than users in Western countries (positive: P<.001; negative: P=.01); for example, Eastern users used more words associated with sadness (P=.01). However, Western users were more likely to share vulnerable topics such as mental health (P<.001), and this group also had a greater tendency to discuss sensitive topics such as swear words (P<.001) and death (P<.001). In addition, when talking to chatbots, people expressed their depressive moods differently than on other platforms. Users were more open to expressing emotional vulnerability related to depressive or sad moods to chatbots (74,045/148,590, 49.83%) than on social media (149/1978, 7.53%). Chatbot conversations tended not to broach topics that require social support from others, such as seeking advice on daily life difficulties, unlike on social media. However, chatbot users acted in anticipation of conversational agents that exhibit active listening skills and foster a safe space where they can openly share emotional states such as sadness or depression. Conclusions: The findings highlight the potential of chatbot-assisted mental health support, emphasizing the importance of continued technical and policy-wise efforts to improve chatbot interactions for those in need of emotional assistance. Our data indicate the possibility of chatbots providing helpful information about depressive moods, especially for users who have difficulty communicating emotions to other humans. © 2024 Elsevier B.V., All rights reserved."
186,0,1.0,"Background: Mental illness is a pervasive worldwide public health issue. Residentially vulnerable populations, such as those living in rural medically underserved areas (MUAs) or mental health provider shortage areas (MHPSAs), face unique access barriers to mental health care. Despite the growth of digital mental health interventions using relational agent technology, little is known about their use patterns, efficacy, and favorability among residentially vulnerable populations. Objective: This study aimed to explore differences in app use, therapeutic alliance, mental health outcomes, and satisfaction across residential subgroups (metropolitan, nonmetropolitan, or rural), MUAs (yes or no), and MHPSAs (yes or no) among users of a smartphone-based, digital mental health intervention, Woebot LIFE (WB-LIFE). WB-LIFE was designed to help users better understand and manage their moods and features a relational agent, Woebot, that converses through text-based messages. Methods: We used an exploratory study that examined data from 255 adults enrolled in an 8-week, single-arm trial of WB-LIFE. Analyses compared levels of app use and therapeutic alliance total scores as well as subscales (goal, task, and bond), mental health outcomes (depressive and anxiety symptoms, stress, resilience, and burnout), and program satisfaction across residential subgroups. Results: Few study participants resided in nonmetropolitan (25/255, 10%) or rural (3/255, 1%) areas, precluding estimates across this variable. Despite a largely metropolitan sample, nearly 39% (99/255) resided in an MUA and 55% (141/255) in an MHPSA. There were no significant differences in app use or satisfaction by MUA or MHPSA status. There also were no differences in depressive symptoms, anxiety, stress, resilience, or burnout, with the exception of MUA participants having higher baseline depressive symptoms among those starting in the moderate range or higher (Patient Health Questionnaire-8 item scale≥10) than non-MUA participants (mean 16.50 vs 14.41, respectively; P=.01). Although working alliance scores did not differ by MHPSA status, those who resided in an MUA had higher goal (2-tailed t<inf>203.47</inf>=2.21; P=.03), and bond (t<inf>203.47</inf>=1.94; P=.05) scores at day 3 (t<inf>192.98</inf>=2.15; P=.03), and higher goal scores at week 8 (t<inf>186.19</inf>=2.28; P=.02) as compared with those not living in an MUA. Conclusions: Despite the study not recruiting many participants from rural or nonmetropolitan populations, sizable proportions resided in an MUA or an MHPSA. Analyses revealed few differences in app use, therapeutic alliance, mental health outcomes (including baseline levels), or satisfaction across MUA or MHPSA status over the 8-week study. Findings suggest that vulnerable residential populations may benefit from using digital agent–guided cognitive behavioral therapy. © 2023 Elsevier B.V., All rights reserved."
187,0,0.3167979062556479,"Background: Type 2 diabetes (T2D) is a growing global health concern, including in Singapore. Diabetes education programs have been shown to be effective in improving health outcomes and diabetes self-management skills. Mobile health apps have emerged as useful tools for diabetes education; however, their use and acceptance by the target population remain inconsistent. Therefore, end-user participation in the design and development of a mobile health app is crucial for designing an acceptable app that can improve outcomes for populations with a chronic disease. Objective: The objective of this study was to apply an end-user participatory approach to co-design a diabetes education app prototype for people living with T2D by exploring their perceptions, acceptance, and usability of an app prototype, as well as their diabetes experience and perspectives on digital diabetes education. Methods: A total of 8 people with T2D, who were recruited from diabetes management Facebook groups, participated in 4 web-based surveys via Qualtrics and 2 structured interviews via Zoom (Zoom Video Communications, Inc) between August 20, 2021, and January 28, 2022. Descriptive statistics and thematic analyses of the discussion and iterative feedback on the app prototype were used to assess the participants’ perceptions of living with T2D, attitudes toward digital diabetes education, and acceptance of the prototype. Results: Analyses of the surveys and interview data revealed 3 themes: challenges of living with T2D; validation, acceptability, and usability of the diabetes education app prototype; and perspectives on digital diabetes education. In the first theme, participants highlighted the importance of solitary accountability, translating knowledge into practice, and developing pragmatic self-consciousness. The second theme indicated that the diabetes education app prototype was acceptable, with information and appearance being key; revealed ambivalent and polarized opinions toward the chatbot; and confirmed potential impact of the app on diabetes self-management skills and practice. The third theme comprised the necessity of using a variety of information-seeking strategies and recommendations for desired content and app qualities, including accessibility, adaptability, autonomy, evidence-based design and content, gamification, guidance, integration, personalization, and up-to-date content. The findings were used to reiterate the app design. Conclusions: Despite a small sample size, the study demonstrated the feasibility of engaging and empowering people living with T2D to consider digital therapeutics for diabetes self-management skills and practice. Participants gave rather positive feedback on the design and content of the app prototype, with some recommendations for improvements. The findings suggest that incorporating end-user feedback into app design can lead to the creation of feasible and acceptable tools for diabetes education, potentially improving outcomes for populations with a chronic disease. Further research is needed to test the impact of the refined diabetes education app prototype on diabetes self-management skills and practice and quality of life. © 2023 Elsevier B.V., All rights reserved."
188,5,1.0,"Background: Artificial intelligence–driven chatbots are increasingly being used in health care, but few chat-based instant messaging support health education programs are designed for patients with chronic kidney disease (CKD) to evaluate their effectiveness. In addition, limited research exists on the usage of chat-based programs among patients with CKD, particularly those that integrate a chatbot aimed at enhancing the communication ability and disease-specific knowledge of patients. Objective: The objective of this formative study is to gather the data necessary to develop an intervention program of chat-based instant messaging support health education for patients with CKD. Participants’ user experiences will form the basis for program design improvements. Methods: Data were collected from April to November 2020 using a structured questionnaire. A pre-post design was used, and a total of 60 patients consented to join the 3-month program. Among them, 55 successfully completed the study measurements. The System Usability Scale was used for participant evaluations of the usability of the chat-based program. Results: Paired t tests revealed significant differences before and after intervention for communicative literacy (t<inf>54</inf>=3.99; P<.001) and CKD-specific disease knowledge (t<inf>54</inf>=7.54; P<.001). Within disease knowledge, significant differences were observed in the aspects of CKD basic knowledge (t<inf>5</inf><inf>4</inf>=3.46; P=.001), lifestyle (t<inf>54</inf>=3.83; P=.001), dietary intake (t<inf>54</inf>=5.51; P<.001), and medication (t<inf>54</inf>=4.17; P=.001). However, no significant difference was found in the aspect of disease prevention. Subgroup analysis revealed that while the findings among male participants were similar to those of the main sample, this was not the case among female participants. Conclusions: The findings reveal that a chat-based instant messaging support health education program may be effective for middle-aged and older patients with CKD. The use of a chat-based program with multiple promoting approaches is promising, and users’ evaluation is satisfactory. © 2023 Elsevier B.V., All rights reserved."
189,1,1.0,"Prompt engineering is a relatively new field of research that refers to the practice of designing, refining, and implementing prompts or instructions that guide the output of large language models (LLMs) to help in various tasks. With the emergence of LLMs, the most popular one being ChatGPT that has attracted the attention of over a 100 million users in only 2 months, artificial intelligence (AI), especially generative AI, has become accessible for the masses. This is an unprecedented paradigm shift not only because of the use of AI becoming more widespread but also due to the possible implications of LLMs in health care. As more patients and medical professionals use AI-based tools, LLMs being the most popular representatives of that group, it seems inevitable to address the challenge to improve this skill. This paper summarizes the current state of research about prompt engineering and, at the same time, aims at providing practical recommendations for the wide range of health care professionals to improve their interactions with LLMs. © 2023 Elsevier B.V., All rights reserved."
190,-1,0.3545441088797069,"Background: The ongoing COVID-19 pandemic has highlighted the potential of digital health solutions to adapt the organization of care in a crisis context. Objective: Our aim was to describe the relationship between the MyRISK score, derived from self-reported data collected by a chatbot before the preanesthetic consultation, and the occurrence of postoperative complications. Methods: This was a single-center prospective observational study that included 401 patients. The 16 items composing the MyRISK score were selected using the Delphi method. An algorithm was used to stratify patients with low (green), intermediate (orange), and high (red) risk. The primary end point concerned postoperative complications occurring in the first 6 months after surgery (composite criterion), collected by telephone and by consulting the electronic medical database. A logistic regression analysis was carried out to identify the explanatory variables associated with the complications. A machine learning model was trained to predict the MyRISK score using a larger data set of 1823 patients classified as green or red to reclassify individuals classified as orange as either modified green or modified red. User satisfaction and usability were assessed. Results: Of the 389 patients analyzed for the primary end point, 16 (4.1%) experienced a postoperative complication. A red score was independently associated with postoperative complications (odds ratio 5.9, 95% CI 1.5-22.3; P=.009). A modified red score was strongly correlated with postoperative complications (odds ratio 21.8, 95% CI 2.8-171.5; P=.003) and predicted postoperative complications with high sensitivity (94%) and high negative predictive value (99%) but with low specificity (49%) and very low positive predictive value (7%; area under the receiver operating characteristic curve=0.71). Patient satisfaction numeric rating scale and system usability scale median scores were 8.0 (IQR 7.0-9.0) out of 10 and 90.0 (IQR 82.5-95.0) out of 100, respectively. Conclusions: The MyRISK digital perioperative risk score established before the preanesthetic consultation was independently associated with the occurrence of postoperative complications. Its negative predictive strength was increased using a machine learning model to reclassify patients identified as being at intermediate risk. This reliable numerical categorization could be used to objectively refer patients with low risk to teleconsultation. © 2023 Elsevier B.V., All rights reserved."
191,1,0.7966886115196484,"Background: Artificial intelligence (AI) has gained tremendous popularity recently, especially the use of natural language processing (NLP). ChatGPT is a state-of-the-art chatbot capable of creating natural conversations using NLP. The use of AI in medicine can have a tremendous impact on health care delivery. Although some studies have evaluated ChatGPT’s accuracy in self-diagnosis, there is no research regarding its precision and the degree to which it recommends medical consultations. Objective: The aim of this study was to evaluate ChatGPT’s ability to accurately and precisely self-diagnose common orthopedic diseases, as well as the degree of recommendation it provides for medical consultations. Methods: Over a 5-day course, each of the study authors submitted the same questions to ChatGPT. The conditions evaluated were carpal tunnel syndrome (CTS), cervical myelopathy (CM), lumbar spinal stenosis (LSS), knee osteoarthritis (KOA), and hip osteoarthritis (HOA). Answers were categorized as either correct, partially correct, incorrect, or a differential diagnosis. The percentage of correct answers and reproducibility were calculated. The reproducibility between days and raters were calculated using the Fleiss κ coefficient. Answers that recommended that the patient seek medical attention were recategorized according to the strength of the recommendation as defined by the study. Results: The ratios of correct answers were 25/25, 1/25, 24/25, 16/25, and 17/25 for CTS, CM, LSS, KOA, and HOA, respectively. The ratios of incorrect answers were 23/25 for CM and 0/25 for all other conditions. The reproducibility between days was 1.0, 0.15, 0.7, 0.6, and 0.6 for CTS, CM, LSS, KOA, and HOA, respectively. The reproducibility between raters was 1.0, 0.1, 0.64, –0.12, and 0.04 for CTS, CM, LSS, KOA, and HOA, respectively. Among the answers recommending medical attention, the phrases “essential,” “recommended,” “best,” and “important” were used. Specifically, “essential” occurred in 4 out of 125, “recommended” in 12 out of 125, “best” in 6 out of 125, and “important” in 94 out of 125 answers. Additionally, 7 out of the 125 answers did not include a recommendation to seek medical attention. Conclusions: The accuracy and reproducibility of ChatGPT to self-diagnose five common orthopedic conditions were inconsistent. The accuracy could potentially be improved by adding symptoms that could easily identify a specific location. Only a few answers were accompanied by a strong recommendation to seek medical attention according to our study standards. Although ChatGPT could serve as a potential first step in accessing care, we found variability in accurate self-diagnosis. Given the risk of harm with self-diagnosis without medical follow-up, it would be prudent for an NLP to include clear language alerting patients to seek expert medical opinions. We hope to shed further light on the use of AI in a future clinical study. © 2023 Elsevier B.V., All rights reserved."
192,0,0.4228344881362147,"Background: The current paper details findings from Elena+: Care for COVID-19, an app developed to tackle the collateral damage of lockdowns and social distancing, by offering pandemic lifestyle coaching across seven health areas: anxiety, loneliness, mental resources, sleep, diet and nutrition, physical activity, and COVID-19 information. Methods: The Elena+ app functions as a single-arm interventional study, with participants recruited predominantly via social media. We used paired samples T-tests and within subjects ANOVA to examine changes in health outcome assessments and user experience evaluations over time. To investigate the mediating role of behavioral activation (i.e., users setting behavioral intentions and reporting actual behaviors) we use mixed-effect regression models. Free-text entries were analyzed qualitatively. Results: Results show strong demand for publicly available lifestyle coaching during the pandemic, with total downloads (N = 7′135) and 55.8% of downloaders opening the app (n = 3,928) with 9.8% completing at least one subtopic (n = 698). Greatest areas of health vulnerability as assessed with screening measures were physical activity with 62% (n = 1,000) and anxiety with 46.5% (n = 760). The app was effective in the treatment of mental health; with a significant decrease in depression between first (14 days), second (28 days), and third (42 days) assessments: F<inf>2,38</inf> = 7.01, p = 0.003, with a large effect size (η2G = 0.14), and anxiety between first and second assessments: t<inf>54</inf> = 3.7, p = <0.001 with a medium effect size (Cohen d = 0.499). Those that followed the coaching program increased in net promoter score between the first and second assessment: t<inf>36</inf> = 2.08, p = 0.045 with a small to medium effect size (Cohen d = 0.342). Mediation analyses showed that while increasing number of subtopics completed increased behavioral activation (i.e., match between behavioral intentions and self-reported actual behaviors), behavioral activation did not mediate the relationship to improvements in health outcome assessments. Conclusions: Findings show that: (i) there is public demand for chatbot led digital coaching, (ii) such tools can be effective in delivering treatment success, and (iii) they are highly valued by their long-term user base. As the current intervention was developed at rapid speed to meet the emergency pandemic context, the future looks bright for other public health focused chatbot-led digital health interventions. © 2023 Elsevier B.V., All rights reserved."
193,3,0.3485161449131233,[No abstract available] Brave (in a) new world: an ethical perspective on chatbots for medical advice Chatbot; Chatgpt; Confidentiality And Privacy; Ethics; Hallucination; Medical Advice; Risks
194,0,0.4093673457131379,"Background: Mental health status assessment is mostly limited to clinical or research settings, but recent technological advances provide new opportunities for measurement using more ecological approaches. Leveraging apps already in use by individuals on their smartphones, such as chatbots, could be a useful approach to capture subjective reports of mood in the moment. Objective: This study aimed to describe the development and implementation of the Identifying Depression Early in Adolescence Chatbot (IDEABot), a WhatsApp-based tool designed for collecting intensive longitudinal data on adolescents’ mood. Methods: The IDEABot was developed to collect data from Brazilian adolescents via WhatsApp as part of the Identifying Depression Early in Adolescence Risk Stratified Cohort (IDEA-RiSCo) study. It supports the administration and collection of self-reported structured items or questionnaires and audio responses. The development explored WhatsApp’s default features, such as emojis and recorded audio messages, and focused on scripting relevant and acceptable conversations. The IDEABot supports 5 types of interactions: textual and audio questions, administration of a version of the Short Mood and Feelings Questionnaire, unprompted interactions, and a snooze function. Six adolescents (n=4, 67% male participants and n=2, 33% female participants) aged 16 to 18 years tested the initial version of the IDEABot and were engaged to codevelop the final version of the app. The IDEABot was subsequently used for data collection in the second- and third-year follow-ups of the IDEA-RiSCo study. Results: The adolescents assessed the initial version of the IDEABot as enjoyable and made suggestions for improvements that were subsequently implemented. The IDEABot’s final version follows a structured script with the choice of answer based on exact text matches throughout 15 days. The implementation of the IDEABot in 2 waves of the IDEA-RiSCo sample (140 and 132 eligible adolescents in the second- and third-year follow-ups, respectively) evidenced adequate engagement indicators, with good acceptance for using the tool (113/140, 80.7% and 122/132, 92.4% for second- and third-year follow-up use, respectively), low attrition (only 1/113, 0.9% and 1/122, 0.8%, respectively, failed to engage in the protocol after initial interaction), and high compliance in terms of the proportion of responses in relation to the total number of elicited prompts (12.8, SD 3.5; 91% out of 14 possible interactions and 10.57, SD 3.4; 76% out of 14 possible interactions, respectively). Conclusions: The IDEABot is a frugal app that leverages an existing app already in daily use by our target population. It follows a simple rule-based approach that can be easily tested and implemented in diverse settings and possibly diminishes the burden of intensive data collection for participants by repurposing WhatsApp. In this context, the IDEABot appears as an acceptable and potentially scalable tool for gathering momentary information that can enhance our understanding of mood fluctuations and development. © 2023 Elsevier B.V., All rights reserved."
195,3,1.0,"Background: Genetic testing has become an integrated part of health care for patients with breast or ovarian cancer, and the increasing demand for genetic testing is accompanied by an increasing need for easy access to reliable genetic information for patients. Therefore, we developed a chatbot app (Rosa) that is able to perform humanlike digital conversations about genetic BRCA testing. Objective: Before implementing this new information service in daily clinical practice, we wanted to explore 2 aspects of chatbot use: the perceived utility and trust in chatbot technology among healthy patients at risk of hereditary cancer and how interaction with a chatbot regarding sensitive information about hereditary cancer influences patients. Methods: Overall, 175 healthy individuals at risk of hereditary breast and ovarian cancer were invited to test the chatbot, Rosa, before and after genetic counseling. To secure a varied sample, participants were recruited from all cancer genetic clinics in Norway, and the selection was based on age, gender, and risk of having a BRCA pathogenic variant. Among the 34.9% (61/175) of participants who consented for individual interview, a selected subgroup (16/61, 26%) shared their experience through in-depth interviews via video. The semistructured interviews covered the following topics: usability, perceived usefulness, trust in the information received via the chatbot, how Rosa influenced the user, and thoughts about future use of digital tools in health care. The transcripts were analyzed using the stepwise-deductive inductive approach. Results: The overall finding was that the chatbot was very welcomed by the participants. They appreciated the 24/7 availability wherever they were and the possibility to use it to prepare for genetic counseling and to repeat and ask questions about what had been said afterward. As Rosa was created by health care professionals, they also valued the information they received as being medically correct. Rosa was referred to as being better than Google because it provided specific and reliable answers to their questions. The findings were summed up in 3 concepts: “Anytime, anywhere”; “In addition, not instead”; and “Trustworthy and true.” All participants (16/16) denied increased worry after reading about genetic testing and hereditary breast and ovarian cancer in Rosa. Conclusions: Our results indicate that a genetic information chatbot has the potential to contribute to easy access to uniform information for patients at risk of hereditary breast and ovarian cancer, regardless of geographical location. The 24/7 availability of quality-assured information, tailored to the specific situation, had a reassuring effect on our participants. It was consistent across concepts that Rosa was a tool for preparation and repetition; however, none of the participants (0/16) supported that Rosa could replace genetic counseling if hereditary cancer was confirmed. This indicates that a chatbot can be a well-suited digital companion to genetic counseling. © 2023 Elsevier B.V., All rights reserved."
196,5,0.48813583393008203,"Background: Health literacy is low among patients with chronic liver disease (CLD) and associated with poor health outcomes and increased health care use. Lucy LiverBot, an artificial intelligence chatbot was created by a multidisciplinary team at Monash Health, Australia, to improve health literacy and self-efficacy in patients with decompensated CLD. Objective: The aim of this study was to explore users’ experience with Lucy LiverBot using an unmoderated, in-person, qualitative test. Methods: Lucy LiverBot is a simple, low cost, and scalable digital intervention, which was at the beta prototype development phase at the time of usability testing. The concept and prototype development was realized in 2 phases: concept development and usability testing. We conducted a mixed methods study to assess usability of Lucy LiverBot as a tool for health literacy education among ambulatory and hospitalized patients with decompensated CLD at Monash Health. Patients were provided with free reign to interact with Lucy LiverBot on an iPad device under moderator observation. A 3-part survey (preuser, user, and postuser) was developed using the Unified Acceptance Theory Framework to capture the user experience. Results: There were 20 participants with a median age of 55.5 (IQR 46.0-60.5) years, 55% (n=11) of them were female, and 85% (n=17) of them were White. In total, 35% (n=7) of them reported having difficulty reading and understanding written medical information. Alcohol was the predominant etiology in 70% (n=14) of users. Participants actively engaged with Lucy LiverBot and identified it as a potential educational tool and device that could act as a social companion to improve well-being. In total, 25% (n=5) of them reported finding it difficult to learn about their health problems and 20% (n=4) of them found it difficult to find medical information they could trust. Qualitative interviews revealed the conversational nature of Lucy LiverBot was considered highly appealing with improvement in mental health and well-being reported as an unintended benefit of Lucy LiverBot. Patients who had been managing their liver cirrhosis for several years identified that they would be less likely to use Lucy LiverBot, but that it would have been more useful at the time of their diagnosis. Overall, Lucy LiverBot was perceived as a reliable and trustworthy source of information. Conclusions: Lucy LiverBot was well received and may be used to improve health literacy and address barriers to health care provision in patients with decompensated CLD. The study revealed important feedback that has been used to further optimize Lucy LiverBot. Further acceptability and validation studies are being undertaken to investigate whether Lucy LiverBot can improve clinical outcomes and health related quality of life in patients with decompensated CLD. © 2023 Elsevier B.V., All rights reserved."
197,1,0.7288606534810319,"Background: Large language model (LLM)–based artificial intelligence chatbots direct the power of large training data sets toward successive, related tasks as opposed to single-ask tasks, for which artificial intelligence already achieves impressive performance. The capacity of LLMs to assist in the full scope of iterative clinical reasoning via successive prompting, in effect acting as artificial physicians, has not yet been evaluated. Objective: This study aimed to evaluate ChatGPT’s capacity for ongoing clinical decision support via its performance on standardized clinical vignettes. Methods: We inputted all 36 published clinical vignettes from the Merck Sharpe & Dohme (MSD) Clinical Manual into ChatGPT and compared its accuracy on differential diagnoses, diagnostic testing, final diagnosis, and management based on patient age, gender, and case acuity. Accuracy was measured by the proportion of correct responses to the questions posed within the clinical vignettes tested, as calculated by human scorers. We further conducted linear regression to assess the contributing factors toward ChatGPT’s performance on clinical tasks. Results: ChatGPT achieved an overall accuracy of 71.7% (95% CI 69.3%-74.1%) across all 36 clinical vignettes. The LLM demonstrated the highest performance in making a final diagnosis with an accuracy of 76.9% (95% CI 67.8%-86.1%) and the lowest performance in generating an initial differential diagnosis with an accuracy of 60.3% (95% CI 54.2%-66.6%). Compared to answering questions about general medical knowledge, ChatGPT demonstrated inferior performance on differential diagnosis (β=–15.8%; P<.001) and clinical management (β=–7.4%; P=.02) question types. Conclusions: ChatGPT achieves impressive accuracy in clinical decision-making, with increasing strength as it gains more clinical information at its disposal. In particular, ChatGPT demonstrates the greatest accuracy in tasks of final diagnosis as compared to initial diagnosis. Limitations include possible model hallucinations and the unclear composition of ChatGPT’s training data set. © 2023 Elsevier B.V., All rights reserved."
198,0,0.3935215021563685,"Background: The prevalence of child and adolescent mental health issues is increasing faster than the number of services available, leading to a shortfall. Mental health chatbots are a highly scalable method to address this gap. Manage Your Life Online (MYLO) is an artificially intelligent chatbot that emulates the method of levels therapy. Method of levels is a therapy that uses curious questioning to support the sustained awareness and exploration of current problems. Objective: This study aimed to assess the feasibility and acceptability of a co-designed interface for MYLO in young people aged 16 to 24 years with mental health problems. Methods: An iterative co-design phase occurred over 4 months, in which feedback was elicited from a group of young people (n=7) with lived experiences of mental health issues. This resulted in the development of a progressive web application version of MYLO that could be used on mobile phones. We conducted a case series to assess the feasibility and acceptability of MYLO in 13 young people over 2 weeks. During this time, the participants tested MYLO and completed surveys including clinical outcomes and acceptability measures. We then conducted focus groups and interviews and used thematic analysis to obtain feedback on MYLO and identify recommendations for further improvements. Results: Most participants were positive about their experience of using MYLO and would recommend MYLO to others. The participants enjoyed the simplicity of the interface, found it easy to use, and rated it as acceptable using the System Usability Scale. Inspection of the use data found evidence that MYLO can learn and adapt its questioning in response to user input. We found a large effect size for the decrease in participants’ problem-related distress and a medium effect size for the increase in their self-reported tendency to resolve goal conflicts (the proposed mechanism of change) in the testing phase. Some patients also experienced a reliable change in their clinical outcome measures over the 2 weeks. Conclusions: We established the feasibility and acceptability of MYLO. The initial outcomes suggest that MYLO has the potential to support the mental health of young people and help them resolve their own problems. We aim to establish whether the use of MYLO leads to a meaningful reduction in participants’ symptoms of depression and anxiety and whether these are maintained over time by conducting a randomized controlled evaluation trial. © 2024 Elsevier B.V., All rights reserved."
199,-1,0.20325916258434384,"The launch of OpenAI’s GPT-3 model in June 2020 began a new era for conversational chatbots. While there are chatbots that do not use artificial intelligence (AI), conversational chatbots integrate AI language models that allow for back-and-forth conversation between an AI system and a human user. GPT-3, since upgraded to GPT-4, harnesses a natural language processing technique called sentence embedding and allows for conversations with users that are more nuanced and realistic than before. The launch of this model came in the first few months of the COVID-19 pandemic, where increases in health care needs globally combined with social distancing measures made virtual medicine more relevant than ever. GPT-3 and other conversational models have been used for a wide variety of medical purposes, from providing basic COVID-19–related guidelines to personalized medical advice and even prescriptions. The line between medical professionals and conversational chatbots is somewhat blurred, notably in hard-to-reach communities where the chatbot replaced face-to-face health care. Considering these blurred lines and the circumstances accelerating the adoption of conversational chatbots globally, we analyze the use of these tools from an ethical perspective. Notably, we map out the many types of risks in the use of conversational chatbots in medicine to the principles of medical ethics. In doing so, we propose a framework for better understanding the effects of these chatbots on both patients and the medical field more broadly, with the hope of informing safe and appropriate future developments. © 2023 Elsevier B.V., All rights reserved."
200,0,0.8720551644241978,"Background: Mental disorders cause substantial health-related burden worldwide. Mobile health interventions are increasingly being used to promote mental health and well-being, as they could improve access to treatment and reduce associated costs. Behavior change is an important feature of interventions aimed at improving mental health and well-being. There is a need to discern the active components that can promote behavior change in such interventions and ultimately improve users’ mental health. Objective: This study systematically identified mental health conversational agents (CAs) currently available in app stores and assessed the behavior change techniques (BCTs) used. We further described their main features, technical aspects, and quality in terms of engagement, functionality, esthetics, and information using the Mobile Application Rating Scale. Methods: The search, selection, and assessment of apps were adapted from a systematic review methodology and included a search, 2 rounds of selection, and an evaluation following predefined criteria. We conducted a systematic app search of Apple’s App Store and Google Play using 42matters. Apps with CAs in English that uploaded or updated from January 2020 and provided interventions aimed at improving mental health and well-being and the assessment or management of mental disorders were tested by at least 2 reviewers. The BCT taxonomy v1, a comprehensive list of 93 BCTs, was used to identify the specific behavior change components in CAs. Results: We found 18 app-based mental health CAs. Most CAs had <1000 user ratings on both app stores (12/18, 67%) and targeted several conditions such as stress, anxiety, and depression (13/18, 72%). All CAs addressed >1 mental disorder. Most CAs (14/18, 78%) used cognitive behavioral therapy (CBT). Half (9/18, 50%) of the CAs identified were rule based (ie, only offered predetermined answers) and the other half (9/18, 50%) were artificial intelligence enhanced (ie, included open-ended questions). CAs used 48 different BCTs and included on average 15 (SD 8.77; range 4-30) BCTs. The most common BCTs were 3.3 “Social support (emotional),” 4.1 “Instructions for how to perform a behavior,” 11.2 “Reduce negative emotions,” and 6.1 “Demonstration of the behavior.” One-third (5/14, 36%) of the CAs claiming to be CBT based did not include core CBT concepts. Conclusions: Mental health CAs mostly targeted various mental health issues such as stress, anxiety, and depression, reflecting a broad intervention focus. The most common BCTs identified serve to promote the self-management of mental disorders with few therapeutic elements. CA developers should consider the quality of information, user confidentiality, access, and emergency management when designing mental health CAs. Future research should assess the role of artificial intelligence in promoting behavior change within CAs and determine the choice of BCTs in evidence-based psychotherapies to enable systematic, consistent, and transparent development and evaluation of effective digital mental health interventions. © 2023 Elsevier B.V., All rights reserved."
201,0,0.5584651545476689,"Background: Methamphetamine (MA) use disorder is associated with a large public health burden. Despite the therapeutic effects of psychosocial interventions based on current evidence, finding an approach to retain patients in treatment remains a real-world challenge. The rapid development of mobile health (mHealth) systems suggests the potential to provide real-time personalized care at any time and from any location, minimize barriers to treatment, maximize use, and promote the dissemination of accessible therapeutic tools in at-risk populations. Our study aimed to investigate the feasibility and effectiveness of chatbots for the treatment of MA use disorder. Method: The inclusion criteria were (a) a diagnosis of MA use disorder as defined by the DSM-5, (b) age between 18 and 65 years, (c) no acute exacerbation of severe mental illness during the initial assessment, such as schizophrenia or bipolar I disorder, (d) willingness to participate in standard outpatient treatment for ≥ 6 months, and (e) an Android phone. Participants were randomly allocated to either a chatbot-assisted therapy via smartphone (CAT) group or a control group following simple randomization procedures (computerized random numbers) without blinding. All participants were followed up for 6 months. Treatment retention and monthly urine test results were analyzed as outcome measures. Participants' satisfaction with CAT was also assessed. Results: In total, 50 and 49 participants were allocated to the CAT and control groups, respectively. There were no significant differences in retention time between the two treatment groups (df = 1, p = 0.099). The CAT group had fewer MA-positive urine samples than the control group (19.5% vs. 29.6%, F = 9.116, p = 0.003). The proportion of MA-positive urine samples was positively correlated with the frequency of MA use (r = 0.323, p = 0.001), severity of MA use disorder (r = 0.364, p < 0.001), and polysubstance use (r = 0.212, p = 0.035), and negatively correlated with readiness to change (r = −0.330, p = 0.001). Totally 55 participants completed the study at the 6-month follow-up and 60% reported relative satisfaction. Conclusion: Participants in this study had favorable acceptance and generally positive outcomes, which indicates that chatbot is feasible for treating people who use MA. © 2023 Elsevier B.V., All rights reserved."
202,2,1.0,"Background: Relational agents (RAs) have shown effectiveness in various health interventions with and without doctors and hospital facilities. In situations such as a pandemic like the COVID-19 pandemic when health care professionals (HCPs) and facilities are unable to cope with increased demands, RAs may play a major role in ameliorating the situation. However, they have not been well explored in this domain. Objective: This study aimed to design a prototypical RA in collaboration with COVID-19 patients and HCPs and test it with the potential users, for its ability to deliver services during a pandemic. Methods: The RA was designed and developed in collaboration with people with COVID-19 (n=21) and 2 groups of HCPs (n=19 and n=16, respectively) to aid COVID-19 patients at various stages by performing 4 main tasks: testing guidance, support during self-isolation, handling emergency situations, and promoting postrecovery mental well-being. A design validation survey was conducted with 98 individuals to evaluate the usability of the prototype using the System Usability Scale (SUS), and the participants provided feedback on the design. In addition, the RA’s usefulness and acceptability were rated by the participants using Likert scales. Results: In the design validation survey, the prototypical RA received an average SUS score of 58.82. Moreover, 90% (88/98) of participants perceived it to be helpful, and 69% (68/98) of participants accepted it as a viable alternative to HCPs. The prototypical RA received favorable feedback from the participants, and they were inclined to accept it as an alternative to HCPs in non-life-threatening scenarios despite the usability rating falling below the acceptable threshold. Conclusions: Based on participants’ feedback, we recommend further development of the RA with improved automation and emotional support, ability to provide information, tracking, and specific recommendations. © 2023 Elsevier B.V., All rights reserved."
203,1,0.4781036102602717,"Background: ChatGPT-4 is the latest release of a novel artificial intelligence (AI) chatbot able to answer freely formulated and complex questions. In the near future, ChatGPT could become the new standard for health care professionals and patients to access medical information. However, little is known about the quality of medical information provided by the AI. Objective: We aimed to assess the reliability of medical information provided by ChatGPT. Methods: Medical information provided by ChatGPT-4 on the 5 hepato-pancreatico-biliary (HPB) conditions with the highest global disease burden was measured with the Ensuring Quality Information for Patients (EQIP) tool. The EQIP tool is used to measure the quality of internet-available information and consists of 36 items that are divided into 3 subsections. In addition, 5 guideline recommendations per analyzed condition were rephrased as questions and input to ChatGPT, and agreement between the guidelines and the AI answer was measured by 2 authors independently. All queries were repeated 3 times to measure the internal consistency of ChatGPT. Results: Five conditions were identified (gallstone disease, pancreatitis, liver cirrhosis, pancreatic cancer, and hepatocellular carcinoma). The median EQIP score across all conditions was 16 (IQR 14.5-18) for the total of 36 items. Divided by subsection, median scores for content, identification, and structure data were 10 (IQR 9.5-12.5), 1 (IQR 1-1), and 4 (IQR 4-5), respectively. Agreement between guideline recommendations and answers provided by ChatGPT was 60% (15/25). Interrater agreement as measured by the Fleiss κ was 0.78 (P<.001), indicating substantial agreement. Internal consistency of the answers provided by ChatGPT was 100%. Conclusions: ChatGPT provides medical information of comparable quality to available static internet information. Although currently of limited quality, large language models could become the future standard for patients and health care professionals to gather medical information. © 2023 Elsevier B.V., All rights reserved."
204,-1,0.27642947222676356,"Purpose: A comprehensive health history contributes to identifying the most appropriate interventions and care priorities. However, history-taking is challenging to learn and develop for most nursing students. Chatbot was suggested by students to be used in history-taking training. Still, there is a lack of clarity regarding the needs of nursing students in these programs. This study aimed to explore nursing students’ needs and essential components of chatbot-based history-taking instruction program. Methods: This was a qualitative study. Four focus groups, with a total of 22 nursing students, were recruited. Colaizzi's phenomenological methodology was used to analyze the qualitative data generated from the focus group discussions. Results: Three main themes and 12 subthemes emerged. The main themes included limitations of clinical practice for history-taking, perceptions of chatbot used in history-taking instruction programs, and the need for history-taking instruction programs using chatbot. Students had limitations in clinical practice for history-taking. When developing chatbot-based history-taking instruction programs, the development should reflect students’ needs, including feedback from the chatbot system, diverse clinical situations, chances to practice nontechnical skills, a form of chatbot (i.e., humanoid robots or cyborgs), the role of teachers (i.e., sharing experience and providing advice) and training before the clinical practice. Conclusion: Nursing students had limitations in clinical practice for history-taking and high expectations for chatbot-based history-taking instruction programs. © 2023 Elsevier B.V., All rights reserved."
205,4,1.0,"Background: HIV incidence rates have increased in adolescent men who have sex with men (AMSM) and adolescent transgender women (ATGW). Thus, it is essential to promote access to HIV prevention, including pre-exposure prophylaxis (PrEP), among these groups. Moreover, using artificial intelligence and online social platforms to create demand and access to health care services are essential tools for adolescents and youth. Objective: This study aims to describe the participative process of developing a chatbot using artificial intelligence to create demand for PrEP use among AMSM and ATGW in Brazil. Furthermore, it analyzes the chatbot’s acceptability, functionality, and usability and its results on the demand creation for PrEP. Methods: The chatbot Amanda Selfie integrates the demand creation strategies based on social networks (DCSSNs) of the PrEP1519 study. She was conceived as a Black transgender woman and to function as a virtual peer educator. The development process occurred in 3 phases (conception, trial, and final version) and lasted 21 months. A mixed methodology was used for the evaluations. Qualitative approaches, such as in-depth adolescent interviews, were used to analyze acceptability and usability, while quantitative methods were used to analyze the functionality and result of the demand creation for PrEP based on interactions with Amanda and information from health care services about using PrEP. To evaluate Amanda’s result on the demand creation for PrEP, we analyzed sociodemographic profiles of adolescents who interacted at least once with her and developed a cascade model containing the number of people at various stages between the first interaction and initiation of PrEP (PrEP uptake). These indicators were compared with other DCSs developed in the PrEP1519 study using chi-square tests and residual analysis (P=.05). Results: Amanda Selfie was well accepted as a peer educator, clearly and objectively communicating on topics such as gender identity, sexual experiences, HIV, and PrEP. The chatbot proved appropriate for answering questions in an agile and confidential manner, using the language used by AMSM and ATGW and with a greater sense of security and less judgment. The interactions with Amanda Selfie combined with a health professional were well evaluated and improved the appointment scheduling. The chatbot interacted with most people (757/1239, 61.1%) reached by the DCSSNs. However, when compared with the other DCSSNs, Amanda was not efficient in identifying AMSM/ATGW (359/482, 74.5% vs 130/757, 17.2% of total interactions, respectively) and in PrEP uptake (90/359, 25.1% vs 19/130, 14.6%). The following profiles were associated (P<.001) with Amanda Selfie’s demand creation, when compared with other DCS: ATGW and adolescents with higher levels of schooling and White skin color. Conclusions: Using a chatbot to create PrEP demand among AMSM and ATGW was well accepted, especially for ATGW with higher levels of schooling. A complimentary dialog with a health professional increased PrEP uptake, although it remained lower than the results of the other DCSSNs. © 2023 Elsevier B.V., All rights reserved."
206,0,0.7406186799878408,"Background: Accessible, cost-effective, and scalable mental health interventions are limited, particularly in low- and middle-income countries, where disparities between mental health needs and services are greatest. Microinterventions (ie, brief, stand-alone, or digital approaches) aim to provide immediate reprieve and enhancements in mental health states and offer a novel and scalable framework for embedding evidence-based mental health promotion techniques into digital environments. Body image is a global public health issue that increases young peoples’ risk of developing more severe mental and physical health issues. Embedding body image microinterventions into digital environments is one avenue for providing young people with immediate and short-term reprieve and protection from the negative exposure effects associated with social media. Objective: This 2-armed, fully remote, and preregistered randomized controlled trial assessed the impact of a body image chatbot containing microinterventions on Brazilian adolescents’ state and trait body image and associated well-being outcomes. Methods: Geographically diverse Brazilian adolescents aged 13-18 years (901/1715, 52.54% girls) were randomized into the chatbot or an assessment-only control condition and completed web-based self-assessments at baseline, immediately after the intervention time frame, and at 1-week and 1-month follow-ups. The primary outcomes were mean change in state (at chatbot entry and at the completion of a microintervention technique) and trait body image (before and after the intervention), with the secondary outcomes being mean change in affect (state and trait) and body image self-efficacy between the assessment time points. Results: Most participants who entered the chatbot (258/327, 78.9%) completed ≥1 microintervention technique, with participants completing an average of 5 techniques over the 72-hour intervention period. Chatbot users experienced small significant improvements in primary (state: P<.001, Cohen d=0.30, 95% CI 0.25-0.34; and trait body image: P=.02, Cohen d range=0.10, 95% CI 0.01-0.18, to 0.26, 95% CI 0.13-0.32) and secondary outcomes across various time points (state: P<.001, Cohen d=0.28, 95% CI 0.22-0.33; trait positive affect: P=.02, Cohen d range=0.15, 95% CI 0.03-0.27, to 0.23, 95% CI 0.08-0.37; negative affect: P=.03, Cohen d range=−0.16, 95% CI −0.30 to −0.02, to −0.18, 95% CI −0.33 to −0.03; and self-efficacy: P=.02, Cohen d range=0.14, 95% CI 0.03-0.25, to 0.19, 95% CI 0.08-0.32) relative to the control condition. Intervention benefits were moderated by baseline levels of concerns but not by gender. Conclusions: This is the first large-scale randomized controlled trial assessing a body image chatbot among Brazilian adolescents. Intervention attrition was high (531/858, 61.9%) and reflected the broader digital intervention literature; barriers to engagement were discussed. Meanwhile, the findings support the emerging literature that indicates microinterventions and chatbot technology are acceptable and effective web-based service provisions. This study also offers a blueprint for accessible, cost-effective, and scalable digital approaches that address disparities between health care needs and provisions in low- and middle-income countries. © 2023 Elsevier B.V., All rights reserved."
207,0,0.45974766964419905,"Background: Maternal mental health care is variable and with limited accessibility. Artificial intelligence (AI) conversational agents (CAs) could potentially play an important role in supporting maternal mental health and wellbeing. Our study examined data from real-world users who self-reported a maternal event while engaging with a digital mental health and wellbeing AI-enabled CA app (Wysa) for emotional support. The study evaluated app effectiveness by comparing changes in self-reported depressive symptoms between a higher engaged group of users and a lower engaged group of users and derived qualitative insights into the behaviors exhibited among higher engaged maternal event users based on their conversations with the AI CA. Methods: Real-world anonymised data from users who reported going through a maternal event during their conversation with the app was analyzed. For the first objective, users who completed two PHQ-9 self-reported assessments (n = 51) were grouped as either higher engaged users (n = 28) or lower engaged users (n = 23) based on their number of active session-days with the CA between two screenings. A non-parametric Mann–Whitney test (M–W) and non-parametric Common Language effect size was used to evaluate group differences in self-reported depressive symptoms. For the second objective, a Braun and Clarke thematic analysis was used to identify engagement behavior with the CA for the top quartile of higher engaged users (n = 10 of 51). Feedback on the app and demographic information was also explored. Results: Results revealed a significant reduction in self-reported depressive symptoms among the higher engaged user group compared to lower engaged user group (M–W p =.004) with a high effect size (CL = 0.736). Furthermore, the top themes that emerged from the qualitative analysis revealed users expressed concerns, hopes, need for support, reframing their thoughts and expressing their victories and gratitude. Conclusion: These findings provide preliminary evidence of the effectiveness and engagement and comfort of using this AI-based emotionally intelligent mobile app to support mental health and wellbeing across a range of maternal events and experiences. © 2023 Elsevier B.V., All rights reserved."
208,4,1.0,"Background: Sexual and gender minority (SGM) adolescents and young adults (AYAs) are at increased risk of HIV infection, particularly in the Southern United States. Despite the availability of effective biomedical prevention strategies, such as pre-exposure prophylaxis (PrEP), access and uptake remain low among SGM AYAs. In response, the Louisiana Department of Health initiated the LA TelePrEP Program, which leverages the power of telemedicine to connect Louisiana residents to PrEP. A virtual TelePrEP Navigator guides users through the enrollment process, answers questions, schedules appointments, and facilitates lab testing and medication delivery. To increase the participation of SGM AYAs in the program, the TelePrEP program partnered with researchers to develop a chatbot that would facilitate access to the program and support navigator functions. Chatbots are capable of carrying out many functions that reduce employee workload, and despite their successful use in health care and public health, they are relatively new to HIV prevention. Objective: In this paper, we describe the iterative and community-engaged process that we used to develop an SMS text messaging-based chatbot tailored to SGM AYAs that would support navigator functions and disseminate PrEP-related information. Methods: Our process was comprised of 2 phases: conceptualization and development. In the conceptualization phase, aspects of navigator responsibilities, program logistics, and user interactions to prioritize in chatbot programming (eg, scheduling appointments and answering questions) were identified. We also selected a commercially available chatbot platform that could execute these functions and could be programmed with minimal coding experience. In the development phase, we engaged Department of Health staff and SGM AYAs within our professional and personal networks. Five different rounds of testing were conducted with various groups to evaluate each iteration of the chatbot. After each iteration of the testing process, the research team met to discuss feedback, guide the programmer on incorporating modifications, and re-evaluate the chatbot's functionality. Results: Through our highly collaborative and community-engaged process, a rule-based chatbot with artificial intelligence components was successfully created. We gained important knowledge that could advance future chatbot development efforts for HIV prevention. Key to the PrEPBot's success was resolving issues that hampered the user experience, like asking unnecessary questions, responding too quickly, and misunderstanding user input. Conclusions: HIV prevention researchers can feasibly and efficiently program a rule-based chatbot with the assistance of commercially available tools. Our iterative process of engaging researchers, program personnel, and different subgroups of SGM AYAs to obtain input was key to successful chatbot development. If the results of this pilot trial show that the chatbot is feasible and acceptable to SGM AYAs, future HIV researchers and practitioners could consider incorporating chatbots as part of their programs. © 2023 Elsevier B.V., All rights reserved."
209,2,1.0,"Background: Post-COVID-19, or long COVID, has now affected millions of individuals, resulting in fatigue, neurocognitive symptoms, and an impact on daily life. The uncertainty of knowledge around this condition, including its overall prevalence, pathophysiology, and management, along with the growing numbers of affected individuals, has created an essential need for information and disease management. This has become even more critical in a time of abundant online misinformation and potential misleading of patients and health care professionals. Objective: The RAFAEL platform is an ecosystem created to address the information about and management of post-COVID-19, integrating online information, webinars, and chatbot technology to answer a large number of individuals in a time- and resource-limited setting. This paper describes the development and deployment of the RAFAEL platform and chatbot in addressing post-COVID-19 in children and adults. Methods: The RAFAEL study took place in Geneva, Switzerland. The RAFAEL platform and chatbot were made available online, and all users were considered participants of this study. The development phase started in December 2020 and included developing the concept, the backend, and the frontend, as well as beta testing. The specific strategy behind the RAFAEL chatbot balanced an accessible interactive approach with medical safety, aiming to relay correct and verified information for the management of post-COVID-19. Development was followed by deployment with the establishment of partnerships and communication strategies in the French-speaking world. The use of the chatbot and the answers provided were continuously monitored by community moderators and health care professionals, creating a safe fallback for users. Results: To date, the RAFAEL chatbot has had 30,488 interactions, with an 79.6% (6417/8061) matching rate and a 73.2% (n=1795) positive feedback rate out of the 2451 users who provided feedback. Overall, 5807 unique users interacted with the chatbot, with 5.1 interactions per user, on average, and 8061 stories triggered. The use of the RAFAEL chatbot and platform was additionally driven by the monthly thematic webinars as well as communication campaigns, with an average of 250 participants at each webinar. User queries included questions about post-COVID-19 symptoms (n=5612, 69.2%), of which fatigue was the most predominant query (n=1255, 22.4%) in symptoms-related stories. Additional queries included questions about consultations (n=598, 7.4%), treatment (n=527, 6.5%), and general information (n=510, 6.3%). Conclusions: The RAFAEL chatbot is, to the best of our knowledge, the first chatbot developed to address post-COVID-19 in children and adults. Its innovation lies in the use of a scalable tool to disseminate verified information in a time- and resource-limited environment. Additionally, the use of machine learning could help professionals gain knowledge about a new condition, while concomitantly addressing patients' concerns. Lessons learned from the RAFAEL chatbot will further encourage a participative approach to learning and could potentially be applied to other chronic conditions. © 2023 Elsevier B.V., All rights reserved."
210,-1,0.29412622033034996,"Introduction: Artificial intelligence (AI) is increasingly used in healthcare. AI-based chatbots can act as automated conversational agents, capable of promoting health and providing education at any time. The objective of this study was to develop and evaluate a user-friendly medical chatbot (prostate cancer communication assistant (PROSCA)) for provisioning patient information about early detection of prostate cancer (PC). Methods: The chatbot was developed to provide information on prostate diseases, diagnostic tests for PC detection, stages, and treatment options. Ten men aged 49 to 81 years with suspicion of PC were enrolled in this study. Nine of ten patients used the chatbot during the evaluation period and filled out the questionnaires on usage and usability, perceived benefits, and potential for improvement. Results: The chatbot was straightforward to use, with 78% of users not needing any assistance during usage. In total, 89% of the chatbot users in the study experienced a clear to moderate increase in knowledge about PC through the chatbot. All study participants who tested the chatbot would like to re-use a medical chatbot in the future and support the use of chatbots in the clinical routine. Conclusions: Through the introduction of the chatbot PROSCA, we created and evaluated an innovative evidence-based health information tool in the field of PC, allowing targeted support for doctor–patient communication and offering great potential in raising awareness, patient education, and support. Our study revealed that a medical chatbot in the field of early PC detection is readily accepted and benefits patients as an additional informative tool. © 2023 Elsevier B.V., All rights reserved."
211,0,0.32180124205188587,"Background: Non-communicable diseases (NCDs) and common mental disorders (CMDs) are the leading causes of death and disability worldwide. Lifestyle interventions via mobile apps and conversational agents present themselves as low-cost, scalable solutions to prevent these conditions. This paper describes the rationale for, and development of, “LvL UP 1.0″, a smartphone-based lifestyle intervention aimed at preventing NCDs and CMDs. Materials and Methods: A multidisciplinary team led the intervention design process of LvL UP 1.0, involving four phases: (i) preliminary research (stakeholder consultations, systematic market reviews), (ii) selecting intervention components and developing the conceptual model, (iii) whiteboarding and prototype design, and (iv) testing and refinement. The Multiphase Optimization Strategy and the UK Medical Research Council framework for developing and evaluating complex interventions were used to guide the intervention development. Results: Preliminary research highlighted the importance of targeting holistic wellbeing (i.e., both physical and mental health). Accordingly, the first version of LvL UP features a scalable, smartphone-based, and conversational agent-delivered holistic lifestyle intervention built around three pillars: Move More (physical activity), Eat Well (nutrition and healthy eating), and Stress Less (emotional regulation and wellbeing). Intervention components include health literacy and psychoeducational coaching sessions, daily “Life Hacks” (healthy activity suggestions), breathing exercises, and journaling. In addition to the intervention components, formative research also stressed the need to introduce engagement-specific components to maximise uptake and long-term use. LvL UP includes a motivational interviewing and storytelling approach to deliver the coaching sessions, as well as progress feedback and gamification. Offline materials are also offered to allow users access to essential intervention content without needing a mobile device. Conclusions: The development process of LvL UP 1.0 led to an evidence-based and user-informed smartphone-based intervention aimed at preventing NCDs and CMDs. LvL UP is designed to be a scalable, engaging, prevention-oriented, holistic intervention for adults at risk of NCDs and CMDs. A feasibility study, and subsequent optimisation and randomised-controlled trials are planned to further refine the intervention and establish effectiveness. The development process described here may prove helpful to other intervention developers. © 2023 Elsevier B.V., All rights reserved."
212,-1,0.09724193567507455,"Background: ChatGPT (Chat Generative Pre-trained Transformer) has gained popularity for its ability to generate human-like responses. It is essential to note that overreliance or blind trust in ChatGPT, especially in high-stakes decision-making contexts, can have severe consequences. Similarly, lacking trust in the technology can lead to underuse, resulting in missed opportunities. Objective: This study investigated the impact of users’ trust in ChatGPT on their intent and actual use of the technology. Four hypotheses were tested: (1) users’ intent to use ChatGPT increases with their trust in the technology; (2) the actual use of ChatGPT increases with users’ intent to use the technology; (3) the actual use of ChatGPT increases with users’ trust in the technology; and (4) users’ intent to use ChatGPT can partially mediate the effect of trust in the technology on its actual use. Methods: This study distributed a web-based survey to adults in the United States who actively use ChatGPT (version 3.5) at least once a month between February 2023 through March 2023. The survey responses were used to develop 2 latent constructs: Trust and Intent to Use, with Actual Use being the outcome variable. The study used partial least squares structural equation modeling to evaluate and test the structural model and hypotheses. Results: In the study, 607 respondents completed the survey. The primary uses of ChatGPT were for information gathering (n=219, 36.1%), entertainment (n=203, 33.4%), and problem-solving (n=135, 22.2%), with a smaller number using it for health-related queries (n=44, 7.2%) and other activities (n=6, 1%). Our model explained 50.5% and 9.8% of the variance in Intent to Use and Actual Use, respectively, with path coefficients of 0.711 and 0.221 for Trust on Intent to Use and Actual Use, respectively. The bootstrapped results failed to reject all 4 null hypotheses, with Trust having a significant direct effect on both Intent to Use (β=0.711, 95% CI 0.656-0.764) and Actual Use (β=0.302, 95% CI 0.229-0.374). The indirect effect of Trust on Actual Use, partially mediated by Intent to Use, was also significant (β=0.113, 95% CI 0.001-0.227). Conclusions: Our results suggest that trust is critical to users’ adoption of ChatGPT. It remains crucial to highlight that ChatGPT was not initially designed for health care applications. Therefore, an overreliance on it for health-related advice could potentially lead to misinformation and subsequent health risks. Efforts must be focused on improving the ChatGPT’s ability to distinguish between queries that it can safely handle and those that should be redirected to human experts (health care professionals). Although risks are associated with excessive trust in artificial intelligence–driven chatbots such as ChatGPT, the potential risks can be reduced by advocating for shared accountability and fostering collaboration between developers, subject matter experts, and human factors researchers. © 2023 Elsevier B.V., All rights reserved."
213,2,0.615637577602368,"Background: Chatbots are increasingly used to support COVID-19 vaccination programs. Their persuasiveness may depend on the conversation-related context. Objective: This study aims to investigate the moderating role of the conversation quality and chatbot expertise cues in the effects of expressing empathy/autonomy support using COVID-19 vaccination chatbots. Methods: This experiment with 196 Dutch-speaking adults living in Belgium, who engaged in a conversation with a chatbot providing vaccination information, used a 2 (empathy/autonomy support expression: present vs absent) × 2 (chatbot expertise cues: expert endorser vs layperson endorser) between-subject design. Chatbot conversation quality was assessed through actual conversation logs. Perceived user autonomy (PUA), chatbot patronage intention (CPI), and vaccination intention shift (VIS) were measured after the conversation, coded from 1 to 5 (PUA, CPI) and from –5 to 5 (VIS). Results: There was a negative interaction effect of chatbot empathy/autonomy support expression and conversation fallback (CF; the percentage of chatbot answers “I do not understand” in a conversation) on PUA (PROCESS macro, model 1, B=–3.358, SE 1.235, t<inf>186</inf>=2.718, P=.007). Specifically, empathy/autonomy support expression had a more negative effect on PUA when the CF was higher (conditional effect of empathy/autonomy support expression at the CF level of +1SD: B=–.405, SE 0.158, t<inf>186</inf>=2.564, P=.011; conditional effects nonsignificant for the mean level: B=–0.103, SE 0.113, t<inf>186</inf>=0.914, P=.36; conditional effects nonsignificant for the –1SD level: B=0.031, SE=0.123, t<inf>186</inf>=0.252, P=.80). Moreover, an indirect effect of empathy/autonomy support expression on CPI via PUA was more negative when CF was higher (PROCESS macro, model 7, 5000 bootstrap samples, moderated mediation index=–3.676, BootSE 1.614, 95% CI –6.697 to –0.102; conditional indirect effect at the CF level of +1SD: B=–0.443, BootSE 0.202, 95% CI –0.809 to –0.005; conditional indirect effects nonsignificant for the mean level: B=–0.113, BootSE 0.124, 95% CI –0.346 to 0.137; conditional indirect effects nonsignificant for the –1SD level: B=0.034, BootSE 0.132, 95% CI –0.224 to 0.305). Indirect effects of empathy/autonomy support expression on VIS via PUA were marginally more negative when CF was higher. No effects of chatbot expertise cues were found. Conclusions: The findings suggest that expressing empathy/autonomy support using a chatbot may harm its evaluation and persuasiveness when the chatbot fails to answer its users’ questions. The paper adds to the literature on vaccination chatbots by exploring the conditional effects of chatbot empathy/autonomy support expression. The results will guide policy makers and chatbot developers dealing with vaccination promotion in designing the way chatbots express their empathy and support for user autonomy. © 2023 Elsevier B.V., All rights reserved."
214,0,0.4447517082252048,"Background: Chatbots are an emerging technology that show potential for mental health care apps to enable effective and practical evidence-based therapies. As this technology is still relatively new, little is known about recently developed apps and their characteristics and effectiveness. Objective: In this study, we aimed to provide an overview of the commercially available popular mental health chatbots and how they are perceived by users. Methods: We conducted an exploratory observation of 10 apps that offer support and treatment for a variety of mental health concerns with a built-in chatbot feature and qualitatively analyzed 3621 consumer reviews from the Google Play Store and 2624 consumer reviews from the Apple App Store. Results: We found that although chatbots’ personalized, humanlike interactions were positively received by users, improper responses and assumptions about the personalities of users led to a loss of interest. As chatbots are always accessible and convenient, users can become overly attached to them and prefer them over interacting with friends and family. Furthermore, a chatbot may offer crisis care whenever the user needs it because of its 24/7 availability, but even recently developed chatbots lack the understanding of properly identifying a crisis. Chatbots considered in this study fostered a judgment-free environment and helped users feel more comfortable sharing sensitive information. Conclusions: Our findings suggest that chatbots have great potential to offer social and psychological support in situations where real-world human interaction, such as connecting to friends or family members or seeking professional support, is not preferred or possible to achieve. However, there are several restrictions and limitations that these chatbots must establish according to the level of service they offer. Too much reliance on technology can pose risks, such as isolation and insufficient assistance during times of crisis. Recommendations for customization and balanced persuasion to inform the design of effective chatbots for mental health support have been outlined based on the insights of our findings. © 2023 Elsevier B.V., All rights reserved."
215,0,0.2599661063192685,"Background: Before the COVID-19 pandemic, adolescents with type 1 diabetes (T1D) had already experienced far greater rates of psychological distress than their peers. With the pandemic further challenging mental health and increasing the barriers to maintaining optimal diabetes self-management, it is vital that this population has access to remotely deliverable, evidence-based interventions to improve psychological and diabetes outcomes. Chatbots, defined as digital conversational agents, offer these unique advantages, as well as the ability to engage in empathetic and personalized conversations 24-7. Building on previous work developing a self-compassion program for adolescents with T1D, a self-compassion chatbot (COMPASS) was developed for adolescents with T1D to address these concerns. However, the acceptability and potential clinical usability of a chatbot to deliver self-compassion coping tools to adolescents with T1D remained unknown. Objective: This qualitative study was designed to evaluate the acceptability and potential clinical utility of COMPASS among adolescents aged 12 to 16 years with T1D and diabetes health care professionals. Methods: Potential adolescent participants were recruited from previous participant lists, and on the web and in-clinic study flyers, whereas health care professionals were recruited via clinic emails and from diabetes research special interest groups. Qualitative Zoom (Zoom Video Communications, Inc) interviews exploring views on COMPASS were conducted with 19 adolescents (in 4 focus groups) and 11 diabetes health care professionals (in 2 focus groups and 6 individual interviews) from March 2022 to April 2022. Transcripts were analyzed using directed content analysis to examine the features and content of greatest importance to both groups. Results: Adolescents were broadly representative of the youth population living with T1D in Aotearoa (11/19, 58% female; 13/19, 68% Aotearoa New Zealand European; and 2/19, 11% Maori). Health care professionals represented a range of disciplines, including diabetes nurse specialists (3/11, 27%), health psychologists (3/11, 27%), dieticians (3/11, 27%), and endocrinologists (2/11, 18%). The findings offer insight into what adolescents with T1D and their health care professionals see as the shared advantages of COMPASS and desired future additions, such as personalization (mentioned by all 19 adolescents), self-management support (mentioned by 13/19, 68% of adolescents), clinical utility (mentioned by all 11 health care professionals), and breadth and flexibility of tools (mentioned by 10/11, 91% of health care professionals). Conclusions: Early data suggest that COMPASS is acceptable, is relevant to common difficulties, and has clinical utility during the COVID-19 pandemic. However, shared desired features among both groups, including problem-solving and integration with diabetes technology to support self-management; creating a safe peer-to-peer sense of community; and broadening the representation of cultures, lived experience stories, and diabetes challenges, could further improve the potential of the chatbot. On the basis of these findings, COMPASS is currently being improved to be tested in a feasibility study. © 2023 Elsevier B.V., All rights reserved."
216,-1,0.22140903380195157,"Background: There is widespread misinformation about the effects of alcohol consumption on health, which was amplified during the COVID-19 pandemic through social media and internet channels. Chatbots and conversational agents became an important piece of the World Health Organization (WHO) response during the COVID-19 pandemic to quickly disseminate evidence-based information related to COVID-19 and tobacco to the public. The Pan American Health Organization (PAHO) seized the opportunity to develop a conversational agent to talk about alcohol-related topics and therefore complement traditional forms of health education that have been promoted in the past. Objective: This study aimed to develop and deploy a digital conversational agent to interact with an unlimited number of users anonymously, 24 hours a day, about alcohol topics, including ways to reduce risks from drinking, that is accessible in several languages, at no cost, and through various devices. Methods: The content development was based on the latest scientific evidence on the impacts of alcohol on health, social norms about drinking, and data from the WHO and PAHO. The agent itself was developed through a nonexclusive license agreement with a private company (Soul Machines) and included Google Digital Flow ES as the natural language processing software and Amazon Web Services for cloud services. Another company was contracted to program all the conversations, following the technical advice of PAHO staff. Results: The conversational agent was named Pahola, and it was deployed on November 19, 2021, through the PAHO website after a launch event with high publicity. No identifiable data were used and all interactions were anonymous, and therefore, this was not considered research with human subjects. Pahola speaks in English, Spanish, and Portuguese and interacts anonymously with a potentially infinite number of users through various digital devices. Users were required to accept the terms and conditions to enable access to their camera and microphone to interact with Pahola. Pahola attracted good attention from the media and reached 1.6 million people, leading to 236,000 clicks on its landing page, mostly through mobile devices. Only 1532 users had a conversation after clicking to talk to Pahola. The average time users spent talking to Pahola was 5 minutes. Major dropouts were observed in different steps of the conversation flow. Some questions asked by users were not anticipated during programming and could not be answered. Conclusions: Our findings showed several limitations to using a conversational agent for alcohol education to the general public. Improvements are needed to expand the content to make it more meaningful and engaging to the public. The potential of chatbots to educate the public on alcohol-related topics seems enormous but requires a long-term investment of resources and research to be useful and reach many more people. © 2023 Elsevier B.V., All rights reserved."
217,1,1.0,"As large language models (LLMs) expand and become more advanced, so do the natural language processing capabilities of conversational AI, or “chatbots”. OpenAI's recent release, ChatGPT, uses a transformer-based model to enable human-like text generation and question-answering on general domain knowledge, while a healthcare-specific Large Language Model (LLM) such as GatorTron has focused on the real-world healthcare domain knowledge. As LLMs advance to achieve near human-level performances on medical question and answering benchmarks, it is probable that Conversational AI will soon be developed for use in healthcare. In this article we discuss the potential and compare the performance of two different approaches to generative pretrained transformers—ChatGPT, the most widely used general conversational LLM, and Foresight, a GPT (generative pretrained transformer) based model focused on modelling patients and disorders. The comparison is conducted on the task of forecasting relevant diagnoses based on clinical vignettes. We also discuss important considerations and limitations of transformer-based chatbots for clinical use. © 2023 Elsevier B.V., All rights reserved."
218,0,1.0,"Background: Many people attending primary care (PC) have anxiety-depressive symptoms and work-related burnout compounded by a lack of resources to meet their needs. The COVID-19 pandemic has exacerbated this problem, and digital tools have been proposed as a solution. Objective: We aimed to present the development, feasibility, and potential effectiveness of Vickybot, a chatbot aimed at screening, monitoring, and reducing anxiety-depressive symptoms and work-related burnout, and detecting suicide risk in patients from PC and health care workers. Methods: Healthy controls (HCs) tested Vickybot for reliability. For the simulation study, HCs used Vickybot for 2 weeks to simulate different clinical situations. For feasibility and effectiveness study, people consulting PC or health care workers with mental health problems used Vickybot for 1 month. Self-assessments for anxiety (Generalized Anxiety Disorder 7-item) and depression (Patient Health Questionnaire-9) symptoms and work-related burnout (based on the Maslach Burnout Inventory) were administered at baseline and every 2 weeks. Feasibility was determined from both subjective and objective user-engagement indicators (UEIs). Potential effectiveness was measured using paired 2-tailed t tests or Wilcoxon signed-rank test for changes in self-assessment scores. Results: Overall, 40 HCs tested Vickybot simultaneously, and the data were reliably transmitted and registered. For simulation, 17 HCs (n=13, 76% female; mean age 36.5, SD 9.7 years) received 98.8% of the expected modules. Suicidal alerts were received correctly. For the feasibility and potential effectiveness study, 34 patients (15 from PC and 19 health care workers; 76% [26/34] female; mean age 35.3, SD 10.1 years) completed the first self-assessments, with 100% (34/34) presenting anxiety symptoms, 94% (32/34) depressive symptoms, and 65% (22/34) work-related burnout. In addition, 27% (9/34) of patients completed the second self-assessment after 2 weeks of use. No significant differences were found between the first and second self-assessments for anxiety (t<inf>8</inf>=1.000; P=.34) or depressive (t<inf>8</inf>=0.40; P=.70) symptoms. However, work-related burnout scores were moderately reduced (z=−2.07, P=.04, r=0.32). There was a nonsignificant trend toward a greater reduction in anxiety-depressive symptoms and work-related burnout with greater use of the chatbot. Furthermore, 9% (3/34) of patients activated the suicide alert, and the research team promptly intervened with successful outcomes. Vickybot showed high subjective UEI (acceptability, usability, and satisfaction), but low objective UEI (completion, adherence, compliance, and engagement). Vickybot was moderately feasible. Conclusions: The chatbot was useful in screening for the presence and severity of anxiety and depressive symptoms, and for detecting suicidal risk. Potential effectiveness was shown to reduce work-related burnout but not anxiety or depressive symptoms. Subjective perceptions of use contrasted with low objective-use metrics. Our results are promising but suggest the need to adapt and enhance the smartphone-based solution to improve engagement. A consensus on how to report UEIs and validate digital solutions, particularly for chatbots, is required. © 2023 Elsevier B.V., All rights reserved."
219,0,1.0,"Background: Unmet pediatric mental health (MH) needs are growing as rates of pediatric depression and anxiety dramatically increase. Access to care is limited by multiple factors, including a shortage of clinicians trained in developmentally specific, evidence-based services. Novel approaches to MH care delivery, including technology-leveraged and readily accessible options, need to be evaluated in service of expanding evidence-based services to youths and their families. Preliminary evidence supports the use of Woebot, a relational agent that digitally delivers guided cognitive behavioral therapy (CBT) through a mobile app, for adults with MH concerns. However, no studies have evaluated the feasibility and acceptability of such app-delivered relational agents specifically for adolescents with depression and/or anxiety within an outpatient MH clinic, nor compared them to other MH support services. Objective: This paper describes the protocol for a randomized controlled trial evaluating the feasibility and acceptability of an investigational device, Woebot for Adolescents (W-GenZD), within an outpatient MH clinic for youths presenting with depression and/or anxiety. The study’s secondary aim will compare the clinical outcomes of self-reported depressive symptoms with W-GenZD and a telehealth-delivered CBT-based skills group (CBT-group). Tertiary aims will evaluate additional clinical outcomes and therapeutic alliance between adolescents in W-GenZD and the CBT-group. Methods: Participants include youths aged 13-17 years with depression and/or anxiety seeking care from an outpatient MH clinic at a children’s hospital. Eligible youths will have no recent safety concerns or complex comorbid clinical diagnoses; have no concurrent individual therapy; and, if on medications, are on stable doses, based on clinical screening and as well as study-specific criteria. Results: Recruitment began in May 2022. As of December 8, 2022, we have randomized 133 participants. Conclusions: Establishing the feasibility and acceptability of W-GenZD within an outpatient MH clinical setting will add to the field’s current understanding of the utility and implementation considerations of this MH care service modality. The study will also evaluate the noninferiority of W-GenZD against the CBT-group. Findings may also have implications for patients, families, and providers looking for additional MH support options for adolescents seeking help for their depression and/or anxiety. Such options expand the menu of supports for youths with lower-intensity needs as well as possibly reduce waitlists and optimize clinician deployment toward more severe cases. © 2023 Elsevier B.V., All rights reserved."
220,5,1.0,"Introduction: Virtual conversational agents (i.e., chatbots) are an intuitive form of data collection. Understanding older adults' experiences with chatbots could help identify their usability needs. This quality improvement study evaluated older adults' experiences with a chatbot for health data collection. A secondary goal was to understand how perceptions differed based on length of chatbot forms. Methods: After a demographic survey, participants (≥60 years) completed either a short (21 questions), moderate (30 questions), or long (66 questions) chatbot form. Perceived ease-of-use, usefulness, usability, likelihood to recommend, and cognitive load were measured post-test. Qualitative and quantitative analyses were used. Results: A total of 260 participants reported on usability and satisfaction metrics including perceived ease-of-use (5.8/7), usefulness (4.7/7), usability (5.4/7), and likelihood to recommend (Net Promoter Score = 0). Cognitive load (12.3/100) was low. There was a statistically significant difference in perceived usefulness between groups, with a significantly higher mean perceived usefulness for Group 1 than Group 3. No other group differences were observed. The chatbot was perceived as quick, easy, and pleasant with concerns about technical issues, privacy, and security. Participants provided suggestions to enhance progress tracking, edit responses, improve readability, and have options to ask questions. Discussion: Older adults found the chatbot to be easy, useful, and usable. The chatbot required low cognitive load demonstrating it could be an enjoyable health data collection tool for older adults. These results will inform the development of a health data collection chatbot technology. © 2023 Elsevier B.V., All rights reserved."
221,2,1.0,"Objective: Our goal is to establish the feasibility of using an artificially intelligent chatbot in diverse healthcare settings to promote COVID-19 vaccination. Methods: We designed an artificially intelligent chatbot deployed via short message services and web-based platforms. Guided by communication theories, we developed persuasive messages to respond to users’ COVID-19-related questions and encourage vaccination. We implemented the system in healthcare settings in the U.S. between April 2021 and March 2022 and logged the number of users, topics discussed, and information on system accuracy in matching responses to user intents. We regularly reviewed queries and reclassified responses to better match responses to query intents as COVID-19 events evolved. Results: A total of 2479 users engaged with the system, exchanging 3994 COVID-19 relevant messages. The most popular queries to the system were about boosters and where to get a vaccine. The system's accuracy rate in matching responses to user queries ranged from 54% to 91.1%. Accuracy lagged when new information related to COVID emerged, such as that related to the Delta variant. Accuracy increased when we added new content to the system. Conclusions: It is feasible and potentially valuable to create chatbot systems using AI to facilitate access to current, accurate, complete, and persuasive information on infectious diseases. Such a system can be adapted to use with patients and populations needing detailed information and motivation to act in support of their health. © 2023 Elsevier B.V., All rights reserved."
222,0,0.1737680153280373,"Good mental health is imperative for one’s wellbeing. While clinical mental disorder treatments exist, self-care is an essential aspect of mental health. This paper explores the use and perceived trust of conversational agents, chatbots, in the context of crowdsourced self-care through a between-subjects study (N = 80). One group used a standalone system with a conventional web interface to discover self-care methods. The other group used the same system wrapped in a chatbot interface, facilitating utterances and turn-taking between the user and a chatbot. We identify the security and integrity of the systems as critical factors that affect users’ trust. The chatbot interface scored lower on both these factors, and we contemplate the potential underlying reasons for this. We complement the quantitative data with qualitative analysis and synthesize our findings to identify suggestions for using chatbots in mental health contexts. © 2023 Elsevier B.V., All rights reserved."
223,0,1.0,"Background: Stress levels in the general population had already been increasing in recent years, and have subsequently been exacerbated by the global pandemic. One approach for innovative online-based interventions are “chatbots” – computer programs that can simulate a text-based interaction with human users via a conversational interface. Research on the efficacy of chatbot-based interventions in the context of mental health is sparse. The present study is designed to investigate the effects of a three-week chatbot-based intervention with the chatbot ELME, aiming to reduce stress and to improve various health-related parameters in a stressed sample. Methods: In this multicenter, two-armed randomised controlled trial with a parallel design, a three-week chatbot-based intervention group including two daily interactive intervention sessions via smartphone (á 10–20 min.) is compared to a treatment-as-usual control group. A total of 130 adult participants with a medium to high stress levels will be recruited in Germany. Assessments will take place pre-intervention, post-intervention (after three weeks), and follow-up (after six weeks). The primary outcome is perceived stress. Secondary outcomes include self-reported interoceptive accuracy, mindfulness, anxiety, depression, personality, emotion regulation, psychological well-being, stress mindset, intervention credibility and expectancies, affinity for technology, and attitudes towards artificial intelligence. During the intervention, participants undergo ecological momentary assessments. Furthermore, satisfaction with the intervention, the usability of the chatbot, potential negative effects of the intervention, adherence, potential dropout reasons, and open feedback questions regarding the chatbot are assessed post-intervention. Discussion: To the best of our knowledge, this is the first chatbot-based intervention addressing interoception, as well as in the context with the target variables stress and mindfulness. The design of the present study and the usability of the chatbot were successfully tested in a previous feasibility study. To counteract a low adherence of the chatbot-based intervention, a high guidance by the chatbot, short sessions, individual and flexible time points of the intervention units and the ecological momentary assessments, reminder messages, and the opportunity to postpone single units were implemented. Trial registration: The trial is registered at the WHO International Clinical Trials Registry Platform via the German Clinical Trials Register (DRKS00027560; date of registration: 06 January 2022). This is protocol version No. 1. In case of important protocol modifications, trial registration will be updated. © 2023 Elsevier B.V., All rights reserved."
224,2,1.0,"Background: The COVID-19 pandemic raised novel challenges in communicating reliable, continually changing health information to a broad and sometimes skeptical public, particularly around COVID-19 vaccines, which, despite being comprehensively studied, were the subject of viral misinformation. Chatbots are a promising technology to reach and engage populations during the pandemic. To inform and communicate effectively with users, chatbots must be highly usable and credible. Objective: We sought to understand how young adults and health workers in the United States assessed the usability and credibility of a web-based chatbot called Vira, created by the Johns Hopkins Bloomberg School of Public Health and IBM Research using natural language processing technology. Using a mixed method approach, we sought to rapidly improve Vira’s user experience to support vaccine decision-making during the peak of the COVID-19 pandemic. Methods: We recruited racially and ethnically diverse young people and health workers, with both groups from urban areas of the United States. We used the validated Chatbot Usability Questionnaire to understand the tool’s navigation, precision, and persona. We also conducted 11 interviews with health workers and young people to understand the user experience, whether they perceived the chatbot as confidential and trustworthy, and how they would use the chatbot. We coded and categorized emerging themes to understand the determining factors for participants’ assessment of chatbot usability and credibility. Results: In all, 58 participants completed a web-based usability questionnaire and 11 completed in-depth interviews. Most questionnaire respondents said the chatbot was “easy to navigate” (51/58, 88%) and “very easy to use” (50/58, 86%), and many (45/58, 78%) said its responses were relevant. The mean Chatbot Usability Questionnaire score was 70.2 (SD 12.1) and scores ranged from 40.6 to 95.3. Interview participants felt the chatbot achieved high usability due to its strong functionality, performance, and perceived confidentiality and that the chatbot could attain high credibility with a redesign of its cartoonish visual persona. Young people said they would use the chatbot to discuss vaccination with hesitant friends or family members, whereas health workers used or anticipated using the chatbot to support community outreach, save time, and stay up to date. Conclusions: This formative study conducted during the pandemic’s peak provided user feedback for an iterative redesign of Vira. Using a mixed method approach provided multidimensional feedback, identifying how the chatbot worked well—being easy to use, answering questions appropriately, and using credible branding—while offering tangible steps to improve the product’s visual design. Future studies should evaluate how chatbots support personal health decision-making, particularly in the context of a public health emergency, and whether such outreach tools can reduce staff burnout. Randomized studies should also be conducted to measure how chatbots countering health misinformation affect user knowledge, attitudes, and behavior. © 2023 Elsevier B.V., All rights reserved."
225,5,1.0,"Background: The rising adoption of telehealth provides new opportunities for more effective and equitable health care information mediums. The ability of chatbots to provide a conversational, personal, and comprehendible avenue for learning about health care information make them a promising tool for addressing health care inequity as health care trends continue toward web-based and remote processes. Although chatbots have been studied in the health care domain for their efficacy for smoking cessation, diet recommendation, and other assistive applications, few studies have examined how specific design characteristics influence the effectiveness of chatbots in providing health information. Objective: Our objective was to investigate the influence of different design considerations on the effectiveness of an educational health care chatbot. Methods: A 2×3 between-subjects study was performed with 2 independent variables: a chatbot’s complexity of responses (eg, technical or nontechnical language) and the presented qualifications of the chatbot’s persona (eg, doctor, nurse, or nursing student). Regression models were used to evaluate the impact of these variables on 3 outcome measures: effectiveness, usability, and trust. A qualitative transcript review was also done to review how participants engaged with the chatbot. Results: Analysis of 71 participants found that participants who received technical language responses were significantly more likely to be in the high effectiveness group, which had higher improvements in test scores (odds ratio [OR] 2.73, 95% CI 1.05-7.41; P=.04). Participants with higher health literacy (OR 2.04, 95% CI 1.11-4.00, P=.03) were significantly more likely to trust the chatbot. The participants engaged with the chatbot in a variety of ways, with some taking a conversational approach and others treating the chatbot more like a search engine. Conclusions: Given their increasing popularity, it is vital that we consider how chatbots are designed and implemented. This study showed that factors such as chatbots’ persona and language complexity are two design considerations that influence the ability of chatbots to successfully provide health care information. © 2023 Elsevier B.V., All rights reserved."
226,-1,0.13731522151707756,"Background: Despite efforts, the UK death rate from asthma is the highest in Europe, and 65% of people with asthma in the United Kingdom do not receive the professional care they are entitled to. Experts have recommended the use of digital innovations to help address the issues of poor outcomes and lack of care access. An automated SMS text messaging–based conversational agent (ie, chatbot) created to provide access to asthma support in a familiar format via a mobile phone has the potential to help people with asthma across demographics and at scale. Such a chatbot could help improve the accuracy of self-assessed risk, improve asthma self-management, increase access to professional care, and ultimately reduce asthma attacks and emergencies. Objective: The aims of this study are to determine the feasibility and usability of a text-based conversational agent that processes a patient’s text responses and short sample voice recordings to calculate an estimate of their risk for an asthma exacerbation and then offers follow-up information for lowering risk and improving asthma control; assess the levels of engagement for different groups of users, particularly those who do not access professional services and those with poor asthma control; and assess the extent to which users of the chatbot perceive it as helpful for improving their understanding and self-management of their condition. Methods: We will recruit 300 adults through four channels for broad reach: Facebook, YouGov, Asthma + Lung UK social media, and the website Healthily (a health self-management app). Participants will be screened, and those who meet inclusion criteria (adults diagnosed with asthma and who use WhatsApp) will be provided with a link to access the conversational agent through WhatsApp on their mobile phones. Participants will be sent scheduled and randomly timed messages to invite them to engage in dialogue about their asthma risk during the period of study. After a data collection period (28 days), participants will respond to questionnaire items related to the quality of the interaction. A pre- and postquestionnaire will measure asthma control before and after the intervention. Results: This study was funded in March 2021 and started in January 2022. We developed a prototype conversational agent, which was iteratively improved with feedback from people with asthma, asthma nurses, and specialist doctors. Fortnightly reviews of iterations by the clinical team began in September 2022 and are ongoing. This feasibility study will start recruitment in January 2023. The anticipated completion of the study is July 2023. A future randomized controlled trial will depend on the outcomes of this study and funding. Conclusions: This feasibility study will inform a follow-up pilot and larger randomized controlled trial to assess the impact of a conversational agent on asthma outcomes, self-management, behavior change, and access to care. © 2023 Elsevier B.V., All rights reserved."
227,5,1.0,"Background: RamaCovid is a mobile health (mHealth) education system that provides the Thai population with information about COVID-19 and self-risk assessment. RamaCovid has a chatbot system that provides automatic conversations (available 24 hours per day) and a live chat function that allows users to directly communicate with health professionals (available 4 hours per day in the evening). The system consists of (1) COVID-19 vaccine information, (2) self-care after vaccination, (3) frequently asked questions, (4) self-risk assessment, (5) hospital finding, (6) contact number finding, and (7) live chat with a health professional. Objective: This study investigates the use of and satisfaction with the RamaCovid system. Methods: Overall, 400 people were recruited via RamaCovid by broadcasting an infographic about the study. Questionnaires collected demographic data, users' experiences of RamaCovid, and the use of and satisfaction with the system. The questions were answered using a 5-point Likert scale. Descriptive statistics were used to describe the participant characteristics and their use of and satisfaction with the RamaCovid system. The Mann-Whitney U test was performed to examine the difference in use and satisfaction between the adult and older adult groups. Results: The participants showed high use of and satisfaction with the RamaCovid system. They used the information to take care of themselves and their family, and they gained information about their COVID-19 risk. The users were satisfied with the system because the information was easy to understand, trustworthy, and up to date. However, the older adult group had lower use of and satisfaction with the system compared to the adult group. Conclusions: RamaCovid is an example of the successful implementation of mHealth education. It was an alternative way to work with the call center during the COVID-19 pandemic and increased access to health information and health care services. Providing ongoing updated information, improving the attractiveness of the media information, and the age group difference are important issues for further system development. © 2023 Elsevier B.V., All rights reserved."
228,2,1.0,"Background: Disparities in COVID-19 information and vaccine access have emerged during the pandemic. Individuals from historically excluded communities (eg, Black and Latin American) experience disproportionately negative health outcomes related to COVID-19. Community gaps in COVID-19 education, social, and health care services (including vaccines) should be prioritized as a critical effort to end the pandemic. Misinformation created by the politicization of COVID-19 and related public health measures has magnified the pandemic's challenges, including access to health care, vaccination and testing efforts, as well as personal protective equipment. Information and Communication Technology (ICT) has been demonstrated to reduce the gaps of marginalization in education and access among communities. Chatbots are an increasingly present example of ICTs, particularly in health care and in relation to the COVID-19 pandemic. Objective: This project aimed to (1) follow an inclusive and theoretically driven design process to develop and test a COVID-19 information ICT bilingual (English and Spanish) chatbot tool named ""Ana"" and (2) characterize and evaluate user experiences of these innovative technologies. Methods: Ana was developed following a multitheoretical framework, and the project team was comprised of public health experts, behavioral scientists, community members, and medical team. A total of 7 iterations of ß chatbots were tested, and a total of 22 ß testers participated in this process. Content was curated primarily to provide users with factual answers to common questions about COVID-19. To ensure relevance of the content, topics were driven by community concerns and questions, as ascertained through research. Ana's repository of educational content was based on national and international organizations as well as interdisciplinary experts. In the context of this development and pilot project, we identified an evaluation framework to explore reach, engagement, and satisfaction. Results: A total of 626 community members used Ana from August 2021 to March 2022. Among those participants, 346 used the English version, with an average of 43 users per month; and 280 participants used the Spanish version, with an average of 40 users monthly. Across all users, 63.87% (n=221) of English users and 22.14% (n=62) of Spanish users returned to use Ana at least once; 18.49% (n=64) among the English version users and 18.57% (n=52) among the Spanish version users reported their ranking. Positive ranking comprised the ""smiley"" and ""loved"" emojis, and negative ranking comprised the ""neutral,"" ""sad,"" and ""mad"" emojis. When comparing negative and positive experiences, the latter was higher across Ana's platforms (English: n=41, 64.06%; Spanish: n=41, 77.35%) versus the former (English: n=23, 35.93%; Spanish: n=12, 22.64%). Conclusions: This pilot project demonstrated the feasibility and capacity of an innovative ICT to share COVID-19 information within diverse communities. Creating a chatbot like Ana with bilingual content contributed to an equitable approach to address the lack of accessible COVID-19-related information. © 2023 Elsevier B.V., All rights reserved."
229,0,0.8328180497956692,"Background: There has been a surge in mental health concerns during the COVID-19 pandemic, which has prompted the increased use of digital platforms. However, there is little known about the mental health needs and behaviors of the global population during the pandemic. This study aims to fill this knowledge gap through the analysis of real-world data collected from users of a digital mental health app (Wysa) regarding their engagement patterns and behaviors, as shown by their usage of the service. Objective: This study aims to (1) examine the relationship between mental health distress, digital health uptake, and COVID-19 case numbers; (2) evaluate engagement patterns with the app during the study period; and (3) examine the efficacy of the app in improving mental health outcomes for its users during the pandemic. Methods: This study used a retrospective observational design. During the COVID-19 pandemic, the app’s installations and emotional utterances were measured from March 2020 to October 2021 for the United Kingdom, the United States of America, and India and were mapped against COVID-19 case numbers and their peaks. The engagement of the users from this period (N=4541) with the Wysa app was compared to that of equivalent samples of users from a pre–COVID-19 period (1000 iterations). The efficacy was assessed for users who completed pre-post assessments for symptoms of depression (n=2061) and anxiety (n=1995) on the Patient Health Questionnaire-9 (PHQ-9) and Generalized Anxiety Disorder-7 (GAD-7) test measures, respectively. Results: Our findings demonstrate a significant positive correlation between the increase in the number of installs of the Wysa mental health app and the peaks of COVID-19 case numbers in the United Kingdom (P=.02) and India (P<.001). Findings indicate that users (N=4541) during the COVID period had a significantly higher engagement than the samples from the pre-COVID period, with a medium to large effect size for 80% of these 1000 iterative samples, as observed on the Mann-Whitney test. The PHQ-9 and GAD-7 pre-post assessments indicated statistically significant improvement with a medium effect size (PHQ-9: P=.57; GAD-7: P=.56). Conclusions: This study demonstrates that emotional distress increased substantially during the pandemic, prompting the increased uptake of an artificial intelligence–led mental health app (Wysa), and also offers evidence that the Wysa app could support its users and its usage could result in a significant reduction in symptoms of anxiety and depression. This study also highlights the importance of contextualizing interventions and suggests that digital health interventions can provide large populations with scalable and evidence-based support for mental health care. © 2023 Elsevier B.V., All rights reserved."
230,1,1.0,"Background: Chat Generative Pre-trained Transformer (ChatGPT) is a 175-billion-parameter natural language processing model that can generate conversation-style responses to user input. Objective: This study aimed to evaluate the performance of ChatGPT on questions within the scope of the United States Medical Licensing Examination Step 1 and Step 2 exams, as well as to analyze responses for user interpretability. Methods: We used 2 sets of multiple-choice questions to evaluate ChatGPT’s performance, each with questions pertaining to Step 1 and Step 2. The first set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The second set was the National Board of Medical Examiners (NBME) free 120 questions. ChatGPT’s performance was compared to 2 other large language models, GPT-3 and InstructGPT. The text output of each ChatGPT response was evaluated across 3 qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: Of the 4 data sets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free-Step2, ChatGPT achieved accuracies of 44% (44/100), 42% (42/100), 64.4% (56/87), and 57.8% (59/102), respectively. ChatGPT outperformed InstructGPT by 8.15% on average across all data sets, and GPT-3 performed similarly to random chance. The model demonstrated a significant decrease in performance as question difficulty increased (P=.01) within the AMBOSS-Step1 data set. We found that logical justification for ChatGPT’s answer selection was present in 100% of outputs of the NBME data sets. Internal information to the question was present in 96.8% (183/189) of all questions. The presence of information external to the question was 44.5% and 27% lower for incorrect answers relative to correct answers on the NBME-Free-Step1 (P<.001) and NBME-Free-Step2 (P=.001) data sets, respectively. Conclusions: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at a greater than 60% threshold on the NBME-Free-Step-1 data set, we show that the model achieves the equivalent of a passing score for a third-year medical student. Additionally, we highlight ChatGPT’s capacity to provide logic and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as an interactive medical education tool to support learning. © 2023 Elsevier B.V., All rights reserved."
231,1,0.7713214282563766,"Introduction: Knee pain is caused by various pathologies, making evaluation in primary-care challenging. Subsequently, an over-reliance on imaging, such as radiographs and MRI exists. Electronic-triage tools represent an innovative solution to this problem. The aims of this study were to establish the magnitude of unnecessary knee imaging prior to orthopaedic surgeon referral, and ascertain whether an e-triage tool outperforms existing clinical pathways to recommend correct imaging. Methods: Patients ≥18 years presenting with knee pain treated with arthroscopy or arthroplasty at a single academic hospital between 2015 and 2020 were retrospectively identified. The timing and appropriateness of imaging were assessed according to national guidelines, and classified as ‘necessary’, ‘unnecessary’ or ‘required MRI’. Based on an eDelphi consensus study, a symptom-based e-triage tool was developed and piloted to preliminarily diagnose five common knee pathologies and suggest appropriate imaging. Results: 1462 patients were identified. 17.2% (n = 132) of arthroplasty patients received an ‘unnecessary MRI’, 27.6% (n = 192) of arthroscopy patients did not have a ‘necessary MRI’, requiring follow-up. Forty-one patients trialled the e-triage pilot (mean age: 58.4 years, 58.5% female). Preliminary diagnoses were available for 33 patients. The e-triage tool correctly identified three of the four knee pathologies (one pathology did not present). 79.2% (n = 19) of participants would use the tool again. Conclusion: A substantial number of knee pain patients receive incorrect imaging, incurring delays and unnecessary costs. A symptom-based e-triage tool was developed, with promising performance and user feedback. With refinement using larger datasets, this tool has the potential to improve wait-times, referral quality and reduce cost. © 2023 Elsevier B.V., All rights reserved."
232,2,0.4705841565031365,"Background: Chatbots have become a promising tool to support public health initiatives. Despite their potential, little research has examined how individuals interacted with chatbots during the COVID-19 pandemic. Understanding user-chatbot interactions is crucial for developing services that can respond to people’s needs during a global health emergency. Objective: This study examined the COVID-19 pandemic–related topics online users discussed with a commercially available social chatbot and compared the sentiment expressed by users from 5 culturally different countries. Methods: We analyzed 19,782 conversation utterances related to COVID-19 covering 5 countries (the United States, the United Kingdom, Canada, Malaysia, and the Philippines) between 2020 and 2021, from SimSimi, one of the world’s largest open-domain social chatbots. We identified chat topics using natural language processing methods and analyzed their emotional sentiments. Additionally, we compared the topic and sentiment variations in the COVID-19–related chats across countries. Results: Our analysis identified 18 emerging topics, which could be categorized into the following 5 overarching themes: “Questions on COVID-19 asked to the chatbot” (30.6%), “Preventive behaviors” (25.3%), “Outbreak of COVID-19” (16.4%), “Physical and psychological impact of COVID-19” (16.0%), and “People and life in the pandemic” (11.7%). Our data indicated that people considered chatbots as a source of information about the pandemic, for example, by asking health-related questions. Users turned to SimSimi for conversation and emotional messages when offline social interactions became limited during the lockdown period. Users were more likely to express negative sentiments when conversing about topics related to masks, lockdowns, case counts, and their worries about the pandemic. In contrast, small talk with the chatbot was largely accompanied by positive sentiment. We also found cultural differences, with negative words being used more often by users in the United States than by those in Asia when talking about COVID-19. Conclusions: Based on the analysis of user-chatbot interactions on a live platform, this work provides insights into people’s informational and emotional needs during a global health crisis. Users sought health-related information and shared emotional messages with the chatbot, indicating the potential use of chatbots to provide accurate health information and emotional support. Future research can look into different support strategies that align with the direction of public health policy. © 2023 Elsevier B.V., All rights reserved."
233,3,0.4034391514260314,"Background: Most mental health care providers face the challenge of increased demand for psychotherapy in the absence of increased funding or staffing. To overcome this supply-demand imbalance, care providers must increase the efficiency of service delivery. Objective: In this study, we examined whether artificial intelligence (AI)–enabled digital solutions can help mental health care practitioners to use their time more efficiently, and thus reduce strain on services and improve patient outcomes. Methods: In this study, we focused on the use of an AI solution (Limbic Access) to support initial patient referral and clinical assessment within the UK’s National Health Service. Data were collected from 9 Talking Therapies services across England, comprising 64,862 patients. Results: We showed that the use of this AI solution improves clinical efficiency by reducing the time clinicians spend on mental health assessments. Furthermore, we found improved outcomes for patients using the AI solution in several key metrics, such as reduced wait times, reduced dropout rates, improved allocation to appropriate treatment pathways, and, most importantly, improved recovery rates. When investigating the mechanism by which the AI solution achieved these improvements, we found that the provision of clinically relevant information ahead of clinical assessment was critical for these observed effects. Conclusions: Our results emphasize the utility of using AI solutions to support the mental health workforce, further highlighting the potential of AI solutions to increase the efficiency of care delivery and improve clinical outcomes for patients. © 2025 Elsevier B.V., All rights reserved."
234,0,0.5435579479163479,"Background: Conversational agents (CAs) or chatbots are increasingly used for depression, anxiety, and wellbeing management. CAs are considered acceptable and helpful. However, little is known about the adequacy of CA responses. This study assessed the structure, content, and user-customization of mental health CA dialogues with users with depression or at risk of suicide. Methods: We used content analysis to examine the dialogues of CAs previously included in three assessments of mental health apps (depression education, self-guided cognitive behavioural therapy, and suicide prevention) performed between 2019 and 2020. Two standardized user personas with depression were developed to interact with the CA. All conversations were saved as screenshots, transcribed verbatim, and coded inductively. Results: Nine CAs were included. Seven CAs (78%) had Android and iOS versions; five CAs (56%) had at least 500,000 downloads. The analysis generated eight categories: self-introduction, personalization, appropriateness of CA responses, conveying empathy, guiding users through mood-boosting activities, mood monitoring, suicide risk management, and others. CAs could engage in empathic, non-judgemental conversations with users, offer support, and guide psychotherapeutic exercises. Limitations: CA evaluations were performed using standardized personas, not real-world users. CAs were included for evaluation only if retrieved in the search strategies associated with the previous assessment studies. Conclusion: Assessed CAs offered anonymous, empathic, non-judgemental interactions that align with evidence for face-to-face psychotherapy. CAs from app stores are not suited to provide comprehensive suicide risk management. Further research should evaluate the effectiveness of CA-led interventions in mental health care and in enhancing suicide risk management strategies. © 2022 Elsevier B.V., All rights reserved."
235,1,1.0,"Objectives: Owing to the rapid progress of natural language processing (NLP), the role of NLP in the medical field has radically gained considerable attention from both NLP and medical informatics. Although numerous medical NLP papers are published annually, there is still a gap between basic NLP research and practical product development. This gap raises questions, such as what has medical NLP achieved in each medical field, and what is the burden for the practical use of NLP? This paper aims to clarify the above questions. Methods: We explore the literature on potential NLP products/services applied to various medical/clinical/healthcare areas. Results: This paper introduces clinical applications (bedside applications), in which we introduce the use of NLP for each clinical department, internal medicine, pre-surgery, post-surgery, oncology, radiology, pathology, psychiatry, rehabilitation, obstetrics, and gynecology. Also, we clarify technical problems to be addressed for encouraging bedside applications based on NLP. Conclusions: These results contribute to discussions regarding potentially feasible NLP applications and highlight research gaps for future studies. © 2023 Elsevier B.V., All rights reserved."
236,3,0.476010701552155,"Background: In knowledge transfer for educational purposes, most cancer hospital or center websites have existing information on cancer health. However, such information is usually a list of topics that are neither interactive nor customized to offer any personal touches to people facing dire health crisis and to attempt to understand the concerns of the users. Patients with cancer, their families, and the general public accessing the information are often in challenging, stressful situations, wanting to access accurate information as efficiently as possible. In addition, there is seldom any comprehensive information specifically on radiotherapy, despite the large number of older patients with cancer, to go through the treatment process. Therefore, having someone with professional knowledge who can listen to them and provide the medical information with good will and encouragement would help patients and families struggling with critical illness, particularly during the lingering pandemic. Objective: This study created a novel virtual assistant, a chatbot that can explain the radiation treatment process to stakeholders comprehensively and accurately, in the absence of any similar software. This chatbot was created using the IBM Watson Assistant with artificial intelligence and machine learning features. The chatbot or bot was incorporated into a resource that can be easily accessed by the general public. Methods: The radiation treatment process in a cancer hospital or center was described by the radiotherapy process: patient diagnosis, consultation, and prescription; patient positioning, immobilization, and simulation; 3D-imaging for treatment planning; target and organ contouring; radiation treatment planning; patient setup and plan verification; and treatment delivery. The bot was created using IBM Watson (IBM Corp) assistant. The natural language processing feature in the Watson platform allowed the bot to flow through a given conversation structure and recognize how the user responds based on recognition of similar given examples, referred to as intents during development. Therefore, the bot can be trained using the responses received, by recognizing similar responses from the user and analyzing using Watson natural language processing. Results: The bot is hosted on a website by the Watson application programming interface. It is capable of guiding the user through the conversation structure and can respond to simple questions and provide resources for requests for information that was not directly programmed into the bot. The bot was tested by potential users, and the overall averages of the identified metrics are excellent. The bot can also acquire users’ feedback for further improvements in the routine update. Conclusions: An artificial intelligence–assisted chatbot was created for knowledge transfer regarding radiation treatment process to the patients with cancer, their families, and the general public. The bot that is supported by machine learning was tested, and it was found that the bot can provide information about radiotherapy effectively. © 2023 Elsevier B.V., All rights reserved."
237,4,1.0,"Background: HIV testing rates in sub-Saharan Africa remain below the targeted threshold, and primary care facilities struggle to provide adequate services. Innovative approaches that leverage digital technologies could improve HIV testing and access to treatment. Objective: This study aimed to examine the feasibility and acceptability of Nolwazi_bot. It is an isiZulu-speaking conversational agent designed to support HIV self-testing (HIVST) in KwaZulu-Natal, South Africa. Methods: Nolwazi_bot was designed with 4 different personalities that users could choose when selecting a counselor for their HIVST session. We recruited a convenience sample of 120 consenting adults and invited them to undertake an HIV self-test facilitated by the Nolwazi_bot. After testing, participants completed an interviewer-led posttest structured survey to assess their experience with the chatbot-supported HIVST. Results: Participants (N=120) ranged in age from 18 to 47 years, with half of them being men (61/120, 50.8%). Of the 120 participants, 111 (92.5%) had tested with a human counselor more than once. Of the 120 participants, 45 (37.5%) chose to be counseled by the female Nolwazi_bot personality aged between 18 and 25 years. Approximately one-fifth (21/120, 17.5%) of the participants who underwent an HIV self-test guided by the chatbot tested positive. Most participants (95/120, 79.2%) indicated that their HIV testing experience with a chatbot was much better than that with a human counselor. Many participants (93/120, 77.5%) reported that they felt as if they were talking to a real person, stating that the response tone and word choice of Nolwazi_bot reminded them of how they speak in daily conversations. Conclusions: The study provides insights into the potential of digital technology interventions to support HIVST in low-income and middle-income countries. Although we wait to see the full benefits of mobile health, technological interventions including conversational agents or chatbots provide us with an excellent opportunity to improve HIVST by addressing the barriers associated with clinic-based HIV testing. © 2023 Elsevier B.V., All rights reserved."
238,-1,0.2103161182377718,[No abstract available] Designing Emotions for Health Care Chatbots: Text-Based or Icon-Based Approach Behavioral Intention; Chatbot; Design; Emotion; Emotional Intensity; Health Care; Human Behavior; Icon-based; Perception; Predict; Psychological Distance; Text-based; Adult; Article; Behavior; Emotion; Female; Health Care; Human; Male; Perception; Psychological Distance; Health Care Delivery; Text Messaging; Delivery Of Health Care; Emotions; Humans; Text Messaging
239,0,0.20973883322303122,"Mental health disorders increasingly affect people worldwide. As a consequence, more families and relatives find themselves acting as caregivers. Most often, these are untrained people who experience loneliness, abandonment, and often develop signs of depression (i.e., caregiver burden syndrome). In this work, we present HIGEA, a digital system based on a conversational agent to help to detect caregiver burden. The conversational agent naturally embeds psychological test questions into informal conversations, which aim at increasing the adherence of use and avoiding user bias. A proof-of-concept is developed based on the popular Zarit Test, which is widely used to assess caregiver burden. Preliminary results show the system is useful and effective. © 2023 Elsevier B.V., All rights reserved."
240,-1,0.19725550837128009,"Background: Cigarette smoking poses a major threat to public health. While cessation support provided by healthcare professionals is effective, its use remains low. Chatbots have the potential to serve as a useful addition. The objective of this study is to explore the possibility of using a motivational interviewing style chatbot to enhance engagement, therapeutic alliance, and perceived empathy in the context of smoking cessation. Methods: A preregistered web-based experiment was conducted in which smokers (n = 153) were randomly assigned to either the motivational interviewing (MI)-style chatbot condition (n = 78) or the neutral chatbot condition (n = 75) and interacted with the chatbot in two sessions. In the assessment session, typical intake questions in smoking cessation interventions were administered by the chatbot, such as smoking history, nicotine dependence level, and intention to quit. In the feedback session, the chatbot provided personalized normative feedback and discussed with participants potential reasons to quit. Engagement with the chatbot, therapeutic alliance, and perceived empathy were the primary outcomes and were assessed after both sessions. Secondary outcomes were motivation to quit and perceived communication competence and were assessed after the two sessions. Results: No significant effects of the experimental manipulation (MI-style or neutral chatbot) were found on engagement, therapeutic alliance, or perceived empathy. A significant increase in therapeutic alliance over two sessions emerged in both conditions, with participants reporting significantly increased motivation to quit. The chatbot was perceived as highly competent, and communication competence was positively associated with engagement, therapeutic alliance, and perceived empathy. Conclusion: The results of this preregistered study suggest that talking with a chatbot about smoking cessation can help to motivate smokers to quit and that the effect of conversation has the potential to build up over time. We did not find support for an extra motivating effect of the MI-style chatbot, for which we discuss possible reasons. These findings highlight the promise of using chatbots to motivate smoking cessation. Implications for future research are discussed. © 2022 Elsevier B.V., All rights reserved."
241,-1,0.13057585992823983,"Reduced anxiety is critical for the baby's health during the thousand days of pregnancy. In this age of false information, unreliable data can be harmful to pregnant women during prenatal and postnatal periods. This work presents the findings of a pilot study that investigated the use of chatbots to assist pregnant women during the prenatal and postnatal periods in Brazil. We conducted experiments with healthcare professionals and pregnant women, using the parallel convergent mixed method design to compare the perceptions of the two groups. We applied a quantitative/qualitative study using data collection tools available via the internet. Before responding to the survey instrument, both groups spent seven days interacting with the chatbot. Two doctors validated the questionnaires, and we used a previously validated questionnaire for pregnant women. Seven physicians’ and thirteen pregnant women who met the search criteria participated in the study. Pregnant women believe that interacting with the chatbot educated them and, their physicians will approve of their use. The most significant and positive construct was related to the chatbot's performance expectation ([Mean 4.61][SD 0.74]). The construct that had the least positive influence on pregnant women was Facilitating Conditions ([Mean 3.30],[SD 1.24]). Pregnant women, according to physicians, benefit from clear language and comprehensive information in a variety of ways. Finally, it was established that the presented agent is viable and beneficial for pregnant women and healthcare providers. We intend to focus more on Natural Language Processing (NLP) techniques to improve the chatbot conversation aspects in future studies. © 2023 Elsevier B.V., All rights reserved."
242,0,0.5970211331267697,"Background: Symptoms of depression and anxiety, suicidal ideation, and self-harm have escalated among adolescents to crisis levels during the COVID-19 pandemic. As a result, primary care providers (PCPs) are often called on to provide first-line care for these youth. Digital health interventions can extend mental health specialty care, but few are evidence based. We evaluated the feasibility of delivering an evidence-based mobile health (mHealth) app with an embedded conversational agent to deliver cognitive behavioral therapy (CBT) to symptomatic adolescents presenting in primary care settings during the pandemic. Objective: In this 12-week pilot study, we evaluated the feasibility of delivering the app-based intervention to adolescents aged 13 to 17 years with moderate depressive symptoms who were treated in a practice-based research network (PBRN) of academically affiliated primary care clinics. We also obtained preliminary estimates of app acceptability, effectiveness, and usability. Methods: This small, pilot randomized controlled trial (RCT) evaluated depressive symptom severity in adolescents randomized to the app or to a wait list control condition. The primary end point was depression severity at 4-weeks, measured by the 9-item Patient Health Questionnaire (PHQ-9). Data on acceptability, feasibility, and usability were collected from adolescents and their parent or legal guardian. Qualitative interviews were conducted with 13 PCPs from 11 PBRN clinics to identify facilitators and barriers to incorporating mental health apps in treatment planning for adolescents with depression and anxiety. Results: The pilot randomized 18 participants to the app (n=10, 56%) or to a wait list control condition (n=8, 44%); 17 participants were included in the analysis, and 1 became ineligible upon chart review due to lack of eligibility based on documented diagnosis. The overall sample was predominantly female (15/17, 88%), White (15/17, 88%), and privately insured (15/17, 88%). Mean PHQ-9 scores at 4 weeks decreased by 3.3 points in the active treatment group (representing a shift in mean depression score from moderate to mild symptom severity categories) and 2 points in the wait list control group (no shift in symptom severity category). Teen- and parent-reported usability, feasibility, and acceptability of the app was high. PCPs reported preference for introducing mHealth interventions like the one in this study early in the course of care for individuals presenting with mild or moderate symptoms. Conclusions: In this small study, we demonstrated the feasibility, acceptability, usability, and safety of using a CBT-based chatbot for adolescents presenting with moderate depressive symptoms in a network of PBRN-based primary care clinics. This pilot study could not establish effectiveness, but our results suggest that further study in a larger pediatric population is warranted. Future study inclusive of rural, socioeconomically disadvantaged, and underrepresented communities is needed to establish generalizability of effectiveness and identify implementation-related adaptations needed to promote broader uptake in pediatric primary care. © 2022 Elsevier B.V., All rights reserved."
243,0,1.0,"Background: Depression has a high prevalence among young adults, especially during the COVID-19 pandemic. However, mental health services remain scarce and underutilized worldwide. Mental health chatbots are a novel digital technology to provide fully automated interventions for depressive symptoms. Objective: The purpose of this study was to test the clinical effectiveness and nonclinical performance of a cognitive behavioral therapy (CBT)-based mental health chatbot (XiaoE) for young adults with depressive symptoms during the COVID-19 pandemic. Methods: In a single-blind, 3-arm randomized controlled trial, participants manifesting depressive symptoms recruited from a Chinese university were randomly assigned to a mental health chatbot (XiaoE; n=49), an e-book (n=49), or a general chatbot (Xiaoai; n=50) group in a ratio of 1:1:1. Participants received a 1-week intervention. The primary outcome was the reduction of depressive symptoms according to the 9-item Patient Health Questionnaire (PHQ-9) at 1 week later (T1) and 1 month later (T2). Both intention-to-treat and per-protocol analyses were conducted under analysis of covariance models adjusting for baseline data. Controlled multiple imputation and δ-based sensitivity analysis were performed for missing data. The secondary outcomes were the level of working alliance measured using the Working Alliance Questionnaire (WAQ), usability measured using the Usability Metric for User Experience-LITE (UMUX-LITE), and acceptability measured using the Acceptability Scale (AS). Results: Participants were on average 18.78 years old, and 37.2% (55/148) were female. The mean baseline PHQ-9 score was 10.02 (SD 3.18; range 2-19). Intention-to-treat analysis revealed lower PHQ-9 scores among participants in the XiaoE group compared with participants in the e-book group and Xiaoai group at both T1 (F<inf>2,136</inf>=17.011; P < .001; d=0.51) and T2 (F<inf>2,136</inf>=5.477; P=.005; d=0.31). Better working alliance (WAQ; F<inf>2,145</inf>=3.407; P=.04) and acceptability (AS; F<inf>2,145</inf>=4.322; P=.02) were discovered with XiaoE, while no significant difference among arms was found for usability (UMUX-LITE; F<inf>2,145</inf>=0.968; P=.38). Conclusions: A CBT-based chatbot is a feasible and engaging digital therapeutic approach that allows easy accessibility and self-guided mental health assistance for young adults with depressive symptoms. A systematic evaluation of nonclinical metrics for a mental health chatbot has been established in this study. In the future, focus on both clinical outcomes and nonclinical metrics is necessary to explore the mechanism by which mental health chatbots work on patients. Further evidence is required to confirm the long-term effectiveness of the mental health chatbot via trails replicated with a longer dose, as well as exploration of its stronger efficacy in comparison with other active controls. © 2023 Elsevier B.V., All rights reserved."
244,5,0.3840427585889653,"Background: Conversational agents (CAs) have been developed in outpatient departments to improve physician-patient communication efficiency. As end users, patients’ continuance intention is essential for the sustainable development of CAs. Objective: The aim of this study was to facilitate the successful usage of CAs by identifying key factors influencing patients’ continuance intention and proposing corresponding managerial implications. Methods: This study proposed an extended expectation-confirmation model and empirically tested the model via a cross-sectional field survey. The questionnaire included demographic characteristics, multiple-item scales, and an optional open-ended question on patients’ specific expectations for CAs. Partial least squares structural equation modeling was applied to assess the model and hypotheses. The qualitative data were analyzed via thematic analysis. Results: A total of 172 completed questionaries were received, with a 100% (172/172) response rate. The proposed model explained 75.5% of the variance in continuance intention. Both satisfaction (β=.68; P<.001) and perceived usefulness (β=.221; P=.004) were significant predictors of continuance intention. Patients' extent of confirmation significantly and positively affected both perceived usefulness (β=.817; P<.001) and satisfaction (β=.61; P<.001). Contrary to expectations, perceived ease of use had no significant impact on perceived usefulness (β=.048; P=.37), satisfaction (β=−.004; P=.63), and continuance intention (β=.026; P=.91). The following three themes were extracted from the 74 answers to the open-ended question: personalized interaction, effective utilization, and clear illustrations. Conclusions: This study identified key factors influencing patients’ continuance intention toward CAs. Satisfaction and perceived usefulness were significant predictors of continuance intention (P<.001 and P<.004, respectively) and were significantly affected by patients’ extent of confirmation (P<.001 and P<.001, respectively). Developing a better understanding of patients’ continuance intention can help administrators figure out how to facilitate the effective implementation of CAs. Efforts should be made toward improving the aspects that patients reasonably expect CAs to have, which include personalized interactions, effective utilization, and clear illustrations. © 2022 Elsevier B.V., All rights reserved."
245,1,0.3754540494284801,"Objective: Evaluating the usefulness of a chat bot as an assistant during CPR care by laypersons. Methods: Twenty-one university graduates and university students naive in basic life support participated in this quasi-experimental simulation pilot trial. A version beta chatbot was designed to guide potential bystanders who need help in caring for cardiac arrest victims. Through a Question-Answering (Q&A) flowchart, the chatbot uses Voice Recognition Techniques to transform the user's audio into text. After the transformation, it generates the answer to provide the necessary help through machine and deep learning algorithms. A simulation test with a Laerdal Little Anne manikin was performed. Participants initiated the chatbot, which guided them through the recognition of a cardiac arrest event. After recognizing the cardiac arrest, the chatbot indicated the start of chest compressions for 2 min. Evaluation of the cardiac arrest recognition sequence was done via a checklist and the quality of CPR was collected with the Laerdal Instructor App. Results: 91% of participants were able to perform the entire sequence correctly. All participants checked the safety of the scene and made sure to call 112. 62% place their hands on the correct compression point. A media time of 158 s (IQR: 146–189) was needed for the whole process. 33% of participants achieved high-quality CPR with a median of 60% in QCPR (IQR: 9–86). Compression depth had a median of 42 mm (IQR: 33–53) and compression rate had a median of 100 compressions/min (IQR: 97–100). Conclusion: The use of a voice assistant could be useful for people with no previous training to perform de out-of-hospital cardiac arrest recognition sequence. Chatbot was able to guide all participants to call 112 and to perform continuous chest compressions. The first version of the chatbot for potential bystanders naive in basic life support needs to be further developed to reduce response times and be more effective in giving feedback on chest compressions. © 2023 Elsevier B.V., All rights reserved."
246,-1,0.21203583264599637,"Background: Access to accurate information in health care is a key point for caregivers to avoid medication errors, especially with the reorganization of staff and drug circuits during health crises such as the COVID-19 pandemic. It is, therefore, the role of the hospital pharmacy to answer caregivers’ questions. Some may require the expertise of a pharmacist, some should be answered by pharmacy technicians, but others are simple and redundant, and automated responses may be provided. Objective: We aimed at developing and implementing a chatbot to answer questions from hospital caregivers about drugs and pharmacy organization 24 hours a day and to evaluate this tool. Methods: The ADDIE (Analysis, Design, Development, Implementation, and Evaluation) model was used by a multiprofessional team composed of 3 hospital pharmacists, 2 members of the Innovation and Transformation Department, and the IT service provider. Based on an analysis of the caregivers’ needs about drugs and pharmacy organization, we designed and developed a chatbot. The tool was then evaluated before its implementation into the hospital intranet. Its relevance and conversations with testers were monitored via the IT provider’s back office. Results: Needs analysis with 5 hospital pharmacists and 33 caregivers from 5 health services allowed us to identify 7 themes about drugs and pharmacy organization (such as opening hours and specific prescriptions). After a year of chatbot design and development, the test version obtained good evaluation scores: its speed was rated 8.2 out of 10, usability 8.1 out of 10, and appearance 7.5 out of 10. Testers were generally satisfied (70%) and were hoping for the content to be enhanced. Conclusions: The chatbot seems to be a relevant tool for hospital caregivers, helping them obtain reliable and verified information they need on drugs and pharmacy organization. In the context of significant mobility of nursing staff during the health crisis due to the COVID-19 pandemic, the chatbot could be a suitable tool for transmitting relevant information related to drug circuits or specific procedures. To our knowledge, this is the first time that such a tool has been designed for caregivers. Its development further continued by means of tests conducted with other users such as pharmacy technicians and via the integration of additional data before the implementation on the 2 hospital sites. © 2022 Elsevier B.V., All rights reserved."
247,2,1.0,"Background: Coronavirus continues to spread worldwide, causing various health and economic disruptions. One of the most important approaches to controlling the spread of this disease is to use an artificial intelligence (AI)-based technological intervention, such as a chatbot system. Chatbots can aid in the fight against the spread of COVID-19. Objective: This paper introduces COVID-Bot, an intelligent interactive system that can help screen students and confirm their COVID-19 vaccination status. Methods: The design and development of COVID-Bot followed the principles of the design science research (DSR) process, which is a research method for creating a new scientific artifact. COVID-Bot was developed and implemented using the SnatchBot chatbot application programming interface (API) and its predefined tools, which are driven by various natural language processing algorithms. Results: An evaluation was carried out through a survey that involved 106 university students in determining the functionality, compatibility, reliability, and usability of COVID-Bot. The findings indicated that 92 (86.8%) of the participants agreed that the chatbot functions well, 85 (80.2%) agreed that it fits well with their mobile devices and their lifestyle, 86 (81.1%) agreed that it has the potential to produce accurate and consistent responses, and 85 (80.2%) agreed that it is easy to use. The average obtained α was.87, indicating satisfactory reliability. Conclusions: This study demonstrates that incorporating chatbot technology into the educational system can combat the spread of COVID-19 among university students. The intelligent system does this by interacting with students to determine their vaccination status. © 2022 Elsevier B.V., All rights reserved."
248,0,0.36838003332510705,"Background: Mental disorders in adolescence and young adulthood are major public health concerns. Digital tools such as text-based conversational agents (ie, chatbots) are a promising technology for facilitating mental health assessment. However, the human-like interaction style of chatbots may induce potential biases, such as socially desirable responding (SDR), and may require further effort to complete assessments. Objective: This study aimed to investigate the convergent and discriminant validity of chatbots for mental health assessments, the effect of assessment mode on SDR, and the effort required by participants for assessments using chatbots compared with established modes. Methods: In a counterbalanced within-subject design, we assessed 2 different constructs-psychological distress (Kessler Psychological Distress Scale and Brief Symptom Inventory-18) and problematic alcohol use (Alcohol Use Disorders Identification Test-3)-in 3 modes (chatbot, paper-and-pencil, and web-based), and examined convergent and discriminant validity. In addition, we investigated the effect of mode on SDR, controlling for perceived sensitivity of items and individuals' tendency to respond in a socially desirable way, and we also assessed the perceived social presence of modes. Including a between-subject condition, we further investigated whether SDR is increased in chatbot assessments when applied in a self-report setting versus when human interaction may be expected. Finally, the effort (ie, complexity, difficulty, burden, and time) required to complete the assessments was investigated. Results: A total of 146 young adults (mean age 24, SD 6.42 years; n=67, 45.9% female) were recruited from a research panel for laboratory experiments. The results revealed high positive correlations (all P<.001) of measures of the same construct across different modes, indicating the convergent validity of chatbot assessments. Furthermore, there were no correlations between the distinct constructs, indicating discriminant validity. Moreover, there were no differences in SDR between modes and whether human interaction was expected, although the perceived social presence of the chatbot mode was higher than that of the established modes (P<.001). Finally, greater effort (all P<.05) and more time were needed to complete chatbot assessments than for completing the established modes (P<.001). Conclusions: Our findings suggest that chatbots may yield valid results. Furthermore, an understanding of chatbot design trade-offs in terms of potential strengths (ie, increased social presence) and limitations (ie, increased effort) when assessing mental health were established. © 2022 Elsevier B.V., All rights reserved."
249,0,0.3482656557146549,"Background: It is recommended that caregivers receive oral health education and in-person training to improve toothbrushing for young children. To strengthen oral health education before COVID-19, the 21-Day FunDee chatbot with in-person toothbrushing training for caregivers was used. During the pandemic, practical experience was difficult to implement. Therefore, the 30-Day FunDee chatbot was created to extend the coverage of chatbots from 21 days to 30 days by incorporating more videos on toothbrushing demonstrations and dialogue. This was a secondary data comparison of 2 chatbots in similar rural areas of Pattani province: Maikan district (Study I) and Maelan district (Study II). Objective: This study aimed to evaluate the effectiveness and usability of 2 chatbots, 21-Day FunDee (Study I) and 30-Day FunDee (Study II), based on the protection motivation theory (PMT). This study explored the feasibility of using the 30-Day FunDee chatbot to increase toothbrushing behaviors for caregivers in oral hygiene care for children aged 6 months to 36 months without in-person training during the COVID-19 pandemic. Methods: A pre-post design was used in both studies. The effectiveness was evaluated among caregivers in terms of oral hygiene practices, knowledge, and oral health care perceptions based on PMT. In Study I, participants received in-person training and a 21-day chatbot course during October 2018 to February 2019. In Study II, participants received only daily chatbot programming for 30 days during December 2021 to February 2022. Data were gathered at baseline of each study and at 30 days and 60 days after the start of Study I and Study II, respectively. After completing their interventions, the chatbot's usability was assessed using open-ended questions. Study I evaluated the plaque score, whereas Study II included an in-depth interview. The 2 studies were compared to determine the feasibility of using the 30-Day FunDee chatbot as an alternative to in-person training. Results: There were 71 pairs of participants: 37 in Study I and 34 in Study II. Both chatbots significantly improved overall knowledge (Study I: P<.001; Study II: P=.001), overall oral health care perceptions based on PMT (Study I: P<.001; Study II: P<.001), and toothbrushing for children by caregivers (Study I: P=.02; Study II: P=.04). Only Study I had statistically significant differences in toothbrushing at least twice a day (P=.002) and perceived vulnerability (P=.003). The highest overall chatbot satisfaction was 9.2 (SD 0.9) in Study I and 8.6 (SD 1.2) in Study II. In Study I, plaque levels differed significantly (P<.001). Conclusions: This was the first study using a chatbot in oral health education. We established the effectiveness and usability of 2 chatbot programs for promoting oral hygiene care of young children by caregivers. The 30-Day FunDee chatbot showed the possibility of improving toothbrushing skills without requiring in-person training. © 2022 Elsevier B.V., All rights reserved."
250,4,1.0,"Background: Mobile technologies are being increasingly developed to support the practice of medicine, nursing, and public health, including HIV testing and prevention. Chatbots using artificial intelligence (AI) are novel mobile health strategies that can promote HIV testing and prevention among men who have sex with men (MSM) in Malaysia, a hard-to-reach population at elevated risk of HIV, yet little is known about the features that are important to this key population. Objective: The aim of this study was to identify the barriers to and facilitators of Malaysian MSM’s acceptance of an AI chatbot designed to assist in HIV testing and prevention in relation to its perceived benefits, limitations, and preferred features among potential users. Methods: We conducted 5 structured web-based focus group interviews with 31 MSM in Malaysia between July 2021 and September 2021. The interviews were first recorded, transcribed, coded, and thematically analyzed using NVivo (version 9; QSR International). Subsequently, the unified theory of acceptance and use of technology was used to guide data analysis to map emerging themes related to the barriers to and facilitators of chatbot acceptance onto its 4 domains: performance expectancy, effort expectancy, facilitating conditions, and social influence. Results: Multiple barriers and facilitators influencing MSM’s acceptance of an AI chatbot were identified for each domain. Performance expectancy (ie, the perceived usefulness of the AI chatbot) was influenced by MSM’s concerns about the AI chatbot’s ability to deliver accurate information, its effectiveness in information dissemination and problem-solving, and its ability to provide emotional support and raise health awareness. Convenience, cost, and technical errors influenced the AI chatbot’s effort expectancy (ie, the perceived ease of use). Efficient linkage to health care professionals and HIV self-testing was reported as a facilitating condition of MSM’s receptiveness to using an AI chatbot to access HIV testing. Participants stated that social influence (ie, sociopolitical climate) factors influencing the acceptance of mobile technology that addressed HIV in Malaysia included privacy concerns, pervasive stigma against homosexuality, and the criminalization of same-sex sexual behaviors. Key design strategies that could enhance MSM’s acceptance of an HIV prevention AI chatbot included an anonymous user setting; embedding the chatbot in MSM-friendly web-based platforms; and providing user-guiding questions and options related to HIV testing, prevention, and treatment. Conclusions: This study provides important insights into key features and potential implementation strategies central to designing an AI chatbot as a culturally sensitive digital health tool to prevent stigmatized health conditions in vulnerable and systematically marginalized populations. Such features not only are crucial to designing effective user-centered and culturally situated mobile health interventions for MSM in Malaysia but also illuminate the importance of incorporating social stigma considerations into health technology implementation strategies. © 2022 Elsevier B.V., All rights reserved."
251,2,1.0,"Background: COVID-19 vaccines are highly effective in preventing severe disease and death but are underused. Interventions to address COVID-19 vaccine hesitancy are paramount to reducing the burden of COVID-19. Objective: We aimed to evaluate the preliminary efficacy, usability, and acceptability of a chatbot for promoting COVID-19 vaccination and examine the factors associated with COVID-19 vaccine hesitancy. Methods: In November 2021, we conducted a pre-post pilot study to evaluate ""Vac Chat, Fact Check,"" a web-based chatbot for promoting COVID-19 vaccination. We conducted a web-based survey (N=290) on COVID-19 vaccination at a university in Hong Kong. A subset of 46 participants who were either unvaccinated (n=22) or were vaccinated but hesitant to receive boosters (n=24) were selected and given access to the chatbot for a 7-day trial period. The chatbot provided information about COVID-19 vaccination (eg, efficacy and common side effects), debunked common myths about the vaccine, and included a decision aid for selecting vaccine platforms (inactivated and mRNA vaccines). The main efficacy outcome was changes in the COVID-19 Vaccine Hesitancy Scale (VHS) score (range 9-45) from preintervention (web-based survey) to postintervention (immediately posttrial). Other efficacy outcomes included changes in intention to vaccinate or receive boosters and willingness to encourage others to vaccinate on a scale from 1 (not at all) to 5 (very). Usability was assessed by the System Usability Scale (range 0-100). Linear regression was used to examine the factors associated with COVID-19 VHS scores in all survey respondents. Results: The mean (SD) age of all survey respondents was 21.4 (6.3) years, and 61% (177/290) of respondents were female. Higher eHealth literacy (B=-0.26; P<.001) and perceived danger of COVID-19 (B=-0.17; P=.009) were associated with lower COVID-19 vaccine hesitancy, adjusting for age, sex, chronic disease status, previous flu vaccination, and perceived susceptibility to COVID-19. The main efficacy outcome of COVID-19 VHS score significantly decreased from 28.6 (preintervention) to 24.5 (postintervention), with a mean difference of -4.2 (P<.001) and an effect size (Cohen d) of 0.94. The intention to vaccinate increased from 3.0 to 3.9 (P<.001) in unvaccinated participants, whereas the intention to receive boosters increased from 1.9 to 2.8 (P<.001) in booster-hesitant participants. Willingness to encourage others to vaccinate increased from 2.7 to 3.0 (P=.04). At postintervention, the median (IQR) System Usability Scale score was 72.5 (65-77.5), whereas the median (IQR) recommendation score was 7 (6-8) on a scale from 0 to 10. In a post hoc 4-month follow-up, 82% (18/22) of initially unvaccinated participants reported having received the COVID-19 vaccine, whereas 29% (7/24) of booster-hesitant participants received boosters. Conclusions: This pilot study provided initial evidence to support the efficacy, usability, and acceptability of a chatbot for promoting COVID-19 vaccination in young adults who were unvaccinated or booster-hesitant. © 2022 Elsevier B.V., All rights reserved."
252,-1,0.20084261811977167,"Background: Conversational agents (CAs), also known as chatbots, are computer programs that simulate human conversations by using predetermined rule-based responses or artificial intelligence algorithms. They are increasingly used in health care, particularly via smartphones. There is, at present, no conceptual framework guiding the development of smartphone-based, rule-based CAs in health care. To fill this gap, we propose structured and tailored guidance for their design, development, evaluation, and implementation. Objective: The aim of this study was to develop a conceptual framework for the design, evaluation, and implementation of smartphone-delivered, rule-based, goal-oriented, and text-based CAs for health care. Methods: We followed the approach by Jabareen, which was based on the grounded theory method, to develop this conceptual framework. We performed 2 literature reviews focusing on health care CAs and conceptual frameworks for the development of mobile health interventions. We identified, named, categorized, integrated, and synthesized the information retrieved from the literature reviews to develop the conceptual framework. We then applied this framework by developing a CA and testing it in a feasibility study. Results: The Designing, Developing, Evaluating, and Implementing a Smartphone-Delivered, Rule-Based Conversational Agent (DISCOVER) conceptual framework includes 8 iterative steps grouped into 3 stages, as follows: design, comprising defining the goal, creating an identity, assembling the team, and selecting the delivery interface; development, including developing the content and building the conversation flow; and the evaluation and implementation of the CA. They were complemented by 2 cross-cutting considerations-user-centered design and privacy and security-that were relevant at all stages. This conceptual framework was successfully applied in the development of a CA to support lifestyle changes and prevent type 2 diabetes. Conclusions: Drawing on published evidence, the DISCOVER conceptual framework provides a step-by-step guide for developing rule-based, smartphone-delivered CAs. Further evaluation of this framework in diverse health care areas and settings and for a variety of users is needed to demonstrate its validity. Future research should aim to explore the use of CAs to deliver health care interventions, including behavior change and potential privacy and safety concerns. © 2022 Elsevier B.V., All rights reserved."
253,2,1.0,"Guidelines for COVID-19 issued by the Centers for Disease Control and Prevention prompted state and local governments to mandate safety measures for screening high-risk patient populations and for institutions to look for ways to limit human contact when possible. The aim of this study was to determine the feasibility of an automated communication system (chatbot) for COVID-19 screening before patients’ radiology appointments and to describe patient experiences with the chatbot. We developed a chatbot for COVID-19 screening before outpatient radiology examination appointments and tested it in a pilot study from July 6 to August 31, 2020. The chatbot assessed the presence of any symptoms, exposure, and recent testing. User experience was assessed via a questionnaire based on a 5-point Likert scale. Multivariable logistic regression was performed to predict response rate. The chatbot COVID-19 screening SMS message was sent to 4687 patients. Of these patients, 2722 (58.1%) responded. Of the respondents, 46 (1.7%) reported COVID-19 symptoms; 34 (1.2%) had COVID-19 tests scheduled or pending. Of the 1965 nonresponders, authentication failed for 174 (8.8%), 1496 (76.1%) did not engage with the SMS message, and 251 (12.8%) timed out of the chatbot. The mean rating for the chatbot experience was 4.6. In a multivariable logistic regression model predicting response rate, English written-language preference independently predicted response (odds ratio, 2.71 [95% CI, 1.77–2.77]; P =.007). Age (P = 0.57) and sex (P = 0.51) did not predict response rate. SMS-based COVID-19 screening before scheduled radiology appointments was feasible. English written-language preference (not age or sex) was associated with higher response rate. © 2022 Elsevier B.V., All rights reserved."
254,0,1.0,"Objective: A significant gap exists between those who need and those who receive care for eating disorders (EDs). Novel solutions are needed to encourage service use and address treatment barriers. This study developed and evaluated the usability of a chatbot designed for pairing with online ED screening. The tool aimed to promote mental health service utilization by improving motivation for treatment and self-efficacy among individuals with EDs. Methods: A chatbot prototype, Alex, was designed using decision trees and theoretically-informed components: psychoeducation, motivational interviewing, personalized recommendations, and repeated administration. Usability testing was conducted over four iterative cycles, with user feedback informing refinements to the next iteration. Post-testing, participants (N= 21) completed the System Usability Scale (SUS), the Usefulness, Satisfaction, and Ease of Use Questionnaire (USE), and a semi-structured interview. Results: Interview feedback detailed chatbot aspects participants enjoyed and aspects necessitating improvement. Feedback converged on four themes: user experience, chatbot qualities, chatbot content, and ease of use. Following refinements, users described Alex as humanlike, supportive, and encouraging. Content was perceived as novel and personally relevant. USE scores across domains were generally above average (~5 out of 7), and SUS scores indicated “good” to “excellent” usability across cycles, with the final iteration receiving the highest average score. Discussion: Overall, participants generally reflected positively on interactions with Alex, including the initial version. Refinements between cycles further improved user experiences. This study provides preliminary evidence of the feasibility and acceptance of a chatbot designed to promote motivation for and use of services among individuals with EDs. Public Significance: Low rates of service utilization and treatment have been observed among individuals following online eating disorder screening. Tools are needed, including scalable, digital options, that can be easily paired with screening, to improve motivation for addressing eating disorders and promote service utilization. © 2022 Elsevier B.V., All rights reserved."
255,2,0.8417010015761333,"Background: Since the beginning of the COVID-19 pandemic, people have been exposed to misinformation, leading to many myths about SARS-CoV-2 and the vaccines against it. As this situation does not seem to end soon, many authorities and health organizations, including the World Health Organization (WHO), are utilizing conversational agents (CAs) in their fight against it. Although the impact and usage of these novel digital strategies are noticeable, the design of the CAs remains key to their success. Objective: This study describes the use of design-based research (DBR) for contextual CA design to address vaccine hesitancy. In addition, this protocol will examine the impact of DBR on CA design to understand how this iterative process can enhance accuracy and performance. Methods: A DBR methodology will be used for this study. Each phase of analysis, design, and evaluation of each design cycle inform the next one via its outcomes. An anticipated generic strategy will be formed after completing the first iteration. Using multiple research studies, frameworks and theoretical approaches are tested and evaluated through the different design cycles. User perception of the CA will be analyzed or collected by implementing a usability assessment during every evaluation phase using the System Usability Scale. The PARADISE (PARAdigm for Dialogue System Evaluation) method will be adopted to calculate the performance of this text-based CA. Results: Two phases of the first design cycle (design and evaluation) were completed at the time of this writing (April 2022). The research team is currently reviewing the natural-language understanding model as part of the conversation-driven development (CDD) process in preparation for the first pilot intervention, which will conclude the CA's first design cycle. In addition, conversational data will be analyzed quantitatively and qualitatively as part of the reflection and revision process to inform the subsequent design cycles. This project plans for three rounds of design cycles, resulting in various studies spreading outcomes and conclusions. The results of the first study describing the entire first design cycle are expected to be submitted for publication before the end of 2022. Conclusions: CAs constitute an innovative way of delivering health communication information. However, they are primarily used to contribute to behavioral change or educate people about health issues. Therefore, health chatbots' impact should be carefully designed to meet outcomes. DBR can help shape a holistic understanding of the process of CA conception. This protocol describes the design of VWise, a contextual CA that aims to address vaccine hesitancy using the DBR methodology. The results of this study will help identify the strengths and flaws of DBR's application to such innovative projects. © 2022 Elsevier B.V., All rights reserved."
256,2,0.5818883495080841,"Background: Social media has changed the way we live and communicate, as well as offering unprecedented opportunities to improve many aspects of our lives, including health promotion and disease prevention. However, there is also a darker side to social media that is not always as evident as its possible benefits. In fact, social media has also opened the door to new social and health risks that are linked to health misinformation. Objective: This study aimed to study the role of social media bots during the COVID-19 outbreak. Methods: The Twitter streaming API was used to collect tweets regarding COVID-19 during the early stages of the outbreak. The Botometer tool was then used to obtain the likelihood of whether each account is a bot or not. Bot classification and topic-modeling techniques were used to interpret the Twitter conversation. Finally, the sentiment associated with the tweets was compared depending on the source of the tweet. Results: Regarding the conversation topics, there were notable differences between the different accounts. The content of nonbot accounts was associated with the evolution of the pandemic, support, and advice. On the other hand, in the case of self-declared bots, the content consisted mainly of news, such as the existence of diagnostic tests, the evolution of the pandemic, and scientific findings. Finally, in the case of bots, the content was mostly political. Above all, there was a general overriding tone of criticism and disagreement. In relation to the sentiment analysis, the main differences were associated with the tone of the conversation. In the case of self-declared bots, this tended to be neutral, whereas the conversation of normal users scored positively. In contrast, bots tended to score negatively. Conclusions: By classifying the accounts according to their likelihood of being bots and performing topic modeling, we were able to segment the Twitter conversation regarding COVID-19. Bot accounts tended to criticize the measures imposed to curb the pandemic, express disagreement with politicians, or question the veracity of the information shared on social media. © 2022 Elsevier B.V., All rights reserved."
257,4,0.4647146889955361,"Background: The French organized population-based cervical cancer screening (CCS) program transitioned from a cytology-based to a human papillomavirus (HPV)-based screening strategy in August 2020. HPV testing is offered every 5 years, starting at the age of 30 years. In the new program, women are invited to undergo an HPV test at a gynecologist's, primary care physician's, or midwife's office, a private clinic or health center, family planning center, or hospital. HPV self-sampling (HPVss) was also made available as an additional approach. However, French studies reported that less than 20% of noncompliant women performed vaginal self-sampling when a kit was sent to their home. Women with lower income and educational levels participate less in CCS. Lack of information about the disease and the benefits of CCS were reported as one of the major barriers among noncompliant women. This barrier could be addressed by overcoming disparities in HPV- and cervical cancer-related knowledge and perceptions about CCS. Objective: This study aimed to assess the effectiveness of a chatbot-based decision aid to improve women's participation in the HPVss detection-based CCS care pathway. Methods: AppDate-You is a 2-arm cluster randomized controlled trial (cRCT) nested within the French organized CCS program. Eligible women are those aged 30-65 years who have not been screened for CC for more than 4 years and live in the disadvantaged clusters in the Occitanie Region, France. In total, 32 clusters will be allocated to the intervention and control arms, 16 in each arm (approximately 4000 women). Eligible women living in randomly selected disadvantaged clusters will be identified using the Regional Cancer Screening Coordinating Centre of Occitanie (CRCDC-OC) database. Women in the experimental group will receive screening reminder letters and HPVss kits, combined with access to a chatbot-based decision aid tailored to women with lower education attainment. Women in the control group will receive the reminder letters and HPVss kits (standard of care). The CRCDC-OC database will be used to check trial progress and assess the intervention's impact. The trial has 2 primary outcomes: (1) the proportion of screening participation within 12 months among women recalled for CCS and (2) the proportion of HPVss-positive women who are ""well-managed"" as stipulated in the French guidelines. Results: To date, the AppDate-You study group is preparing and developing the chatbot-based decision aid (intervention). The cRCT will be conducted once the decision aid has been completed and validated. Recruitment of women is expected to begin in January 2023. Conclusions: This study is the first to evaluate the impact of a chatbot-based decision aid to promote the CCS program and increase its performance. The study results will inform policy makers and health professionals as well as the research community. © 2022 Elsevier B.V., All rights reserved."
258,4,1.0,"Digital health interventions for sexual health promotion have evolved considerably alongside innovations in technology. Despite these efforts, studies have shown that they do not consistently result in the desired sexual health outcomes. This could be attributed to low levels of user engagement, which can hinder digital health intervention effectiveness, as users do not engage with the system enough to be exposed to the intervention components. It has been suggested that conversational agents (automated two-way communication systems e.g. Alexa) have the potential to overcome the limitations of prior systems and promote user engagement through the increased interactivity offered by bidirectional, natural language-based interactions. The present review, therefore, provides an overview of the effectiveness and user acceptability of conversational agents for sexual health promotion. A systematic search of seven databases provided 4534 records, and after screening, 31 articles were included in this review. A narrative synthesis of results was conducted for effectiveness and acceptability outcomes, with the former supplemented by a meta-analysis conducted on a subset of studies. Findings provide preliminary support for the effectiveness of conversational agents for promoting sexual health, particularly treatment adherence. These conversational agents were found to be easy to use and useful, and importantly, resulted in high levels of satisfaction, use and intentions to reuse, whereas user evaluations regarding the quality of information left room for improvement. The results can inform subsequent efforts to design and evaluate these interventions, and offer insight into additional user experience constructs identified outside of current technology acceptance models, which can be incorporated into future theoretical developments. © 2023 Elsevier B.V., All rights reserved."
259,0,0.2792824507244992,"Background: Chatbots have been increasingly considered for applications in the health care field. However, it remains unclear how a chatbot can assist users with complex health needs, such as parents of children with neurodevelopmental disorders (NDDs) who need ongoing support. Often, this population must deal with complex and overwhelming health information, which can make parents less likely to use a software that may be very helpful. An approach to enhance user engagement is incorporating game elements in nongame contexts, known as gamification. Gamification needs to be tailored to users; however, there has been no previous assessment of gamification use in chatbots for NDDs. Objective: We sought to examine how gamification elements are perceived and whether their implementation in chatbots will be well received among parents of children with NDDs. We have discussed some elements in detail as the initial step of the project. Methods: We performed a narrative literature review of gamification elements, specifically those used in health and education. Among the elements identified in the literature, our health and social science experts in NDDs prioritized five elements for in-depth discussion: goal setting, customization, rewards, social networking, and unlockable content. We used a qualitative approach, which included focus groups and interviews with parents of children with NDDs (N=21), to assess the acceptability of the potential implementation of these elements in an NDD-focused chatbot. Parents were asked about their opinions on the 5 elements and to rate them. Video and audio recordings were transcribed and summarized for emerging themes, using deductive and inductive thematic approaches. Results: From the responses obtained from 21 participants, we identified three main themes: parents of children with NDDs were familiar with and had positive experiences with gamification; a specific element (goal setting) was important to all parents, whereas others (customization, rewards, and unlockable content) received mixed opinions; and the social networking element received positive feedback, but concerns about information accuracy were raised. Conclusions: We showed for the first time that parents of children with NDDs support gamification use in a chatbot for NDDs. Our study illustrates the need for a user-centered design in the medical domain and provides a foundation for researchers interested in developing chatbots for populations that are medically vulnerable. Future studies exploring wide range of gamification elements with large number of potential users are needed to understand the impact of gamification elements in enhancing knowledge mobilization. © 2022 Elsevier B.V., All rights reserved."
260,2,0.23623498899538226,"Background: Approximately 1 in 3 Canadians will experience an addiction or mental health challenge at some point in their lifetime. Unfortunately, there are multiple barriers to accessing mental health care, including system fragmentation, episodic care, long wait times, and insufficient support for health system navigation. In addition, stigma may further reduce an individual's likelihood of seeking support. Digital technologies present new and exciting opportunities to bridge significant gaps in mental health care service provision, reduce barriers pertaining to stigma, and improve health outcomes for patients and mental health system integration and efficiency. Chatbots (ie, software systems that use artificial intelligence to carry out conversations with people) may be explored to support those in need of information or access to services and present the opportunity to address gaps in traditional, fragmented, or episodic mental health system structures on demand with personalized attention. The recent COVID-19 pandemic has exacerbated even further the need for mental health support among Canadians and called attention to the inefficiencies of our system. As health care workers and their families are at an even greater risk of mental illness and psychological distress during the COVID-19 pandemic, this technology will be first piloted with the goal of supporting this vulnerable group. Objective: This pilot study seeks to evaluate the effectiveness of the Mental Health Intelligent Information Resource Assistant in supporting health care workers and their families in the Canadian provinces of Alberta and Nova Scotia with the provision of appropriate information on mental health issues, services, and programs based on personalized needs. Methods: The effectiveness of the technology will be assessed via voluntary follow-up surveys and an analysis of client interactions and engagement with the chatbot. Client satisfaction with the chatbot will also be assessed. Results: This project was initiated on April 1, 2021. Ethics approval was granted on August 12, 2021, by the University of Alberta Health Research Board (PRO00109148) and on April 21, 2022, by the Nova Scotia Health Authority Research Ethics Board (1027474). Data collection is anticipated to take place from May 2, 2022, to May 2, 2023. Publication of preliminary results will be sought in spring or summer 2022, with a more comprehensive evaluation completed by spring 2023 following the collection of a larger data set. Conclusions: Our findings can be incorporated into public policy and planning around mental health system navigation by Canadian mental health care providers-from large public health authorities to small community-based, not-for-profit organizations. This may serve to support the development of an additional touch point, or point of entry, for individuals to access the appropriate services or care when they need them, wherever they are. © 2022 Elsevier B.V., All rights reserved."
261,-1,0.11014336076570276,"Knowing how to diagnose effectively and efficiently is a fundamental skill that a good dental professional should acquire. If students perform a greater number of clinical cases, they will improve their performance with patients. In this sense, virtual patients with artificial intelligence offer a controlled, stimulating, and safe environment for students. To assess student satisfaction after interaction with an artificially intelligent chatbot that recreates a virtual patient, a descriptive cross-sectional study was carried out in which a virtual patient was created with artificial intelligence in the form of a chatbot and presented to fourth and fifth year dental students. After several weeks interacting with the AI, they were given a survey to find out their assessment. A total of 193 students participated. A large majority of the students were satisfied with the interaction (mean 4.36), the fifth year students rated the interaction better and showed higher satisfaction values. The students who reached a correct diagnosis rated this technology more positively. Our research suggests that the incorporation of this technology in dental curricula would be positively valued by students and would also ensure their training and adaptation to new technological developments. © 2022 Elsevier B.V., All rights reserved."
262,-1,0.12345022109343333,"Objective: The purpose of our study is to develop a spoken dialogue system (SDS) for pain questionnaire in patients with spinal disease. We evaluate user satisfaction and validated the performance accuracy of the SDS in medical staff and patients. Methods: The SDS was developed to investigate pain and related psychological issues in patients with spinal diseases based on the pain questionnaire protocol. We recognized patients’ various answers, summarized important information, and documented them. User satisfaction and performance accuracy were evaluated in 30 potential users of SDS, including doctors, nurses, and patients and statistically analyzed. Results: The overall satisfaction score of 30 patients was 5.5 ± 1.4 out of 7 points. Satisfaction scores were 5.3 ± 0.8 for doctors, 6.0 ± 0.6 for nurses, and 5.3 ± 0.5 for patients. In terms of performance accuracy, the number of repetitions of the same question was 13, 16, and 33 (13.5%, 16.8%, and 34.7%) for doctors, nurses, and patients, respectively. The number of errors in the summarized comment by the SDS was 5, 0, and 11 (5.2%, 0.0%, and 11.6 %), respectively. The number of summarization omissions was 7, 5, and 7 (7.3%, 5.3%, and 7.4%), respectively. Conclusion: This is the first study in which voice-based conversational artificial intelligence (AI) was developed for a spinal pain questionnaire and validated by medical staff and patients. The conversational AI showed favorable results in terms of user satisfaction and performance accuracy. Conversational AI can be useful for the diagnosis and remote monitoring of various patients as well as for pain questionnaires in the future. © 2022 Elsevier B.V., All rights reserved."
263,-1,0.19464039773720523,"Background: Tobacco addiction is the leading cause of preventable morbidity and mortality worldwide, but only 1 in 20 cessation attempts is supervised by a health professional. The potential advantages of mobile health (mHealth) can circumvent this problem and facilitate tobacco cessation interventions for public health systems. Given its easy scalability to large populations and great potential, chatbots are a potentially useful complement to usual treatment. Objective: This study aims to assess the effectiveness of an evidence-based intervention to quit smoking via a chatbot in smartphones compared with usual clinical practice in primary care. Methods: This is a pragmatic, multicenter, controlled, and randomized clinical trial involving 34 primary health care centers within the Madrid Health Service (Spain). Smokers over the age of 18 years who attended on-site consultation and accepted help to quit tobacco were recruited by their doctor or nurse and randomly allocated to receive usual care (control group [CG]) or an evidence-based chatbot intervention (intervention group [IG]). The interventions in both arms were based on the 5A's (ie, Ask, Advise, Assess, Assist, and Arrange) in the US Clinical Practice Guideline, which combines behavioral and pharmacological treatments and is structured in several follow-up appointments. The primary outcome was continuous abstinence from smoking that was biochemically validated after 6 months by the collaborators. The outcome analysis was blinded to allocation of patients, although participants were unblinded to group assignment. An intention-to-treat analysis, using the baseline-observation-carried-forward approach for missing data, and logistic regression models with robust estimators were employed for assessing the primary outcomes. Results: The trial was conducted between October 1, 2018, and March 31, 2019. The sample included 513 patients (242 in the IG and 271 in the CG), with an average age of 49.8 (SD 10.82) years and gender ratio of 59.3% (304/513) women and 40.7% (209/513) men. Of them, 232 patients (45.2%) completed the follow-up, 104/242 (42.9%) in the IG and 128/271 (47.2%) in the CG. In the intention-to-treat analysis, the biochemically validated abstinence rate at 6 months was higher in the IG (63/242, 26%) compared with that in the CG (51/271, 18.8%; odds ratio 1.52, 95% CI 1.00-2.31; P = .05). After adjusting for basal CO-oximetry and bupropion intake, no substantial changes were observed (odds ratio 1.52, 95% CI 0.99-2.33; P = .05; pseudo-R2=0.045). In the IG, 61.2% (148/242) of users accessed the chatbot, average chatbot-patient interaction time was 121 (95% CI 121.1-140.0) minutes, and average number of contacts was 45.56 (SD 36.32). Conclusions: A treatment including a chatbot for helping with tobacco cessation was more effective than usual clinical practice in primary care. However, this outcome was at the limit of statistical significance, and therefore these promising results must be interpreted with caution. © 2022 Elsevier B.V., All rights reserved."
264,0,0.36515951931716617,"Digital interventions for increasing physical activity behavior have shown great potential, especially those with social media. Chatbots, also known as conversational agents, have emerged in healthcare in relation to digital interventions and have proven effective in promoting physical activity among adults. The study’s objective is to explore users’ experiences with a social media chatbot. The concept and the prototype development of the social media chatbot MYA were realized in three steps: requirement analysis, concept development, and implementation. MYA’s design includes behavior change techniques effective in increasing physical activity through digital interventions. Participants in a usability study answered a survey with the Chatbot Usability Questionnaire (CUQ), which is comparable to the Systems Usability Scale. The mean CUQ score was below 68, the benchmark for average usability. The highest mean CUQ score was 64.5 for participants who thought MYA could help increase their physical activity behavior. The lowest mean CUQ score was 40.6 for participants aged between 50 and 69 years. Generally, MYA was considered to be welcoming, very easy to use, realistic, engaging, and informative. However, some technical issues were identified. A good and diversified user experience promotes prolonged chatbot use. Addressing identified issues will enhance users’ interaction with MYA. © 2022 Elsevier B.V., All rights reserved."
265,2,1.0,"Background: Most clinical studies report the symptoms experienced by those infected with coronavirus disease 2019 (COVID-19) via patients already hospitalized. Here we analyzed the symptoms experienced outside of a hospital setting. Methods: The Vienna Social Fund (FSW; Vienna, Austria), the Public Health Services of the City of Vienna (MA15) and the private company Symptoma collaborated to implement Vienna’s official online COVID-19 symptom checker. Users answered 12 yes/no questions about symptoms to assess their risk for COVID-19. They could also specify their age and sex, and whether they had contact with someone who tested positive for COVID-19. Depending on the assessed risk of COVID-19 positivity, a SARS-CoV‑2 nucleic acid amplification test (NAAT) was performed. In this publication, we analyzed which factors (symptoms, sex or age) are associated with COVID-19 positivity. We also trained a classifier to correctly predict COVID-19 positivity from the collected data. Results: Between 2 November 2020 and 18 November 2021, 9133 people experiencing COVID-19-like symptoms were assessed as high risk by the chatbot and were subsequently tested by a NAAT. Symptoms significantly associated with a positive COVID-19 test were malaise, fatigue, headache, cough, fever, dysgeusia and hyposmia. Our classifier could successfully predict COVID-19 positivity with an area under the curve (AUC) of 0.74. Conclusion: This study provides reliable COVID-19 symptom statistics based on the general population verified by NAATs. © 2022 Elsevier B.V., All rights reserved."
266,0,1.0,"The present study aims to examine whether users perceive a therapeutic alliance with an AI conversational agent (Wysa) and observe changes in the t‘herapeutic alliance over a brief time period. A sample of users who screened positively on the PHQ-4 for anxiety or depression symptoms (N = 1,205) of the digital mental health application (app) Wysa were administered the WAI-SR within 5 days of installing the app and gave a second assessment on the same measure after 3 days (N = 226). The anonymised transcripts of user's conversations with Wysa were also examined through content analysis for unprompted elements of bonding between the user and Wysa (N = 950). Within 5 days of initial app use, the mean WAI-SR score was 3.64 (SD 0.81) and the mean bond subscale score was 3.98 (SD 0.94). Three days later, the mean WAI-SR score increased to 3.75 (SD 0.80) and the mean bond subscale score increased to 4.05 (SD 0.91). There was no significant difference in the alliance scores between Assessment 1 and Assessment 2.These mean bond subscale scores were found to be comparable to the scores obtained in recent literature on traditional, outpatient-individual CBT, internet CBT and group CBT. Content analysis of the transcripts of user conversations with the CA (Wysa) also revealed elements of bonding such as gratitude, self-disclosed impact, and personification. The user's therapeutic alliance scores improved over time and were comparable to ratings from previous studies on alliance in human-delivered face-to-face psychotherapy with clinical populations. This study provides critical support for the utilization of digital mental health services, based on the evidence of the establishment of an alliance. © 2023 Elsevier B.V., All rights reserved."
267,-1,0.12539765735226063,"Background: The rising prevalence of gestational diabetes mellitus (GDM) calls for the use of innovative methods to inform and empower these pregnant women. An information chatbot, Dina, was developed for women with GDM and is Norway's first health chatbot, integrated into the national digital health platform. Objective: The aim of this study is to investigate what kind of information users seek in a health chatbot providing support on GDM. Furthermore, we sought to explore when and how the chatbot is used by time of day and the number of questions in each dialogue and to categorize the questions the chatbot was unable to answer (fallback). The overall goal is to explore quantitative user data in the chatbot's log, thereby contributing to further development of the chatbot. Methods: An observational study was designed. We used quantitative anonymous data (dialogues) from the chatbot's log and platform during an 8-week period in 2018 and a 12-week period in 2019 and 2020. Dialogues between the user and the chatbot were the unit of analysis. Questions from the users were categorized by theme. The time of day the dialogue occurred and the number of questions in each dialogue were registered, and questions resulting in a fallback message were identified. Results are presented using descriptive statistics. Results: We identified 610 dialogues with a total of 2838 questions during the 20 weeks of data collection. Questions regarding blood glucose, GDM, diet, and physical activity represented 58.81% (1669/2838) of all questions. In total, 58.0% (354/610) of dialogues occurred during daytime (8 AM to 3:59 PM), Monday through Friday. Most dialogues were short, containing 1-3 questions (340/610, 55.7%), and there was a decrease in dialogues containing 4-6 questions in the second period (P = .013). The chatbot was able to answer 88.51% (2512/2838) of all posed questions. The mean number of dialogues per week was 36 in the first period and 26.83 in the second period. Conclusions: Frequently asked questions seem to mirror the cornerstones of GDM treatment and may indicate that the chatbot is used to quickly access information already provided for them by the health care service but providing a low-threshold way to access that information. Our results underline the need to actively promote and integrate the chatbot into antenatal care as well as the importance of continuous content improvement in order to provide relevant information. © 2022 Elsevier B.V., All rights reserved."
268,5,0.40264328903364155,"Background: The working alliance refers to an important relationship quality between health professionals and clients that robustly links to treatment success. Recent research shows that clients can develop an affective bond with chatbots. However, few research studies have investigated whether this perceived relationship is affected by the social roles of differing closeness a chatbot can impersonate and by allowing users to choose the social role of a chatbot. Objective: This study aimed at understanding how the social role of a chatbot can be expressed using a set of interpersonal closeness cues and examining how these social roles affect clients' experiences and the development of an affective bond with the chatbot, depending on clients' characteristics (ie, age and gender) and whether they can freely choose a chatbot's social role. Methods: Informed by the social role theory and the social response theory, we developed a design codebook for chatbots with different social roles along an interpersonal closeness continuum. Based on this codebook, we manipulated a fictitious health care chatbot to impersonate one of four distinct social roles common in health care settings-institution, expert, peer, and dialogical self-and examined effects on perceived affective bond and usage intentions in a web-based lab study. The study included a total of 251 participants, whose mean age was 41.15 (SD 13.87) years; 57.0% (143/251) of the participants were female. Participants were either randomly assigned to one of the chatbot conditions (no choice: n=202, 80.5%) or could freely choose to interact with one of these chatbot personas (free choice: n=49, 19.5%). Separate multivariate analyses of variance were performed to analyze differences (1) between the chatbot personas within the no-choice group and (2) between the no-choice and the free-choice groups. Results: While the main effect of the chatbot persona on affective bond and usage intentions was insignificant (P = .87), we found differences based on participants' demographic profiles: main effects for gender (P = .04, η<inf>p</inf>2=0.115) and age (P < .001, η<inf>p</inf>2=0.192) and a significant interaction effect of persona and age (P = .01, η<inf>p</inf>2=0.102). Participants younger than 40 years reported higher scores for affective bond and usage intentions for the interpersonally more distant expert and institution chatbots; participants 40 years or older reported higher outcomes for the closer peer and dialogical-self chatbots. The option to freely choose a persona significantly benefited perceptions of the peer chatbot further (eg, free-choice group affective bond: mean 5.28, SD 0.89; no-choice group affective bond: mean 4.54, SD 1.10; P = .003, η<inf>p</inf>2=0.117). Conclusions: Manipulating a chatbot's social role is a possible avenue for health care chatbot designers to tailor clients' chatbot experiences using user-specific demographic factors and to improve clients' perceptions and behavioral intentions toward the chatbot. Our results also emphasize the benefits of letting clients freely choose between chatbots. © 2022 Elsevier B.V., All rights reserved."
269,-1,0.1986721572065935,"Background: One of the most complicated medical needs of older adults is managing their complex medication regimens. However, the use of technology to aid older adults in this endeavor is impeded by the fact that their technological capabilities are lower than those of much of the rest of the population. What is needed to help manage medications is a technology that seamlessly integrates within their comfort levels, such as artificial intelligence agents. Objective: This study aimed to assess the benefits, barriers, and information needs that can be provided by an artificial intelligence-powered medication information voice chatbot for older adults. Methods: A total of 8 semistructured interviews were conducted with geriatrics experts. All interviews were audio-recorded and transcribed. Each interview was coded by 2 investigators (2 among ML, PR, METR, and KR) using a semiopen coding method for qualitative analysis, and reconciliation was performed by a third investigator. All codes were organized into the benefit/nonbenefit, barrier/nonbarrier, and need categories. Iterative recoding and member checking were performed until convergence was reached for all interviews. Results: The greatest benefits of a medication information voice-based chatbot would be helping to overcome the vision and dexterity hurdles experienced by most older adults, as it uses voice-based technology. It also helps to increase older adults' medication knowledge and adherence and supports their overall health. The main barriers were technology familiarity and cost, especially in lower socioeconomic older adults, as well as security and privacy concerns. It was noted however that technology familiarity was not an insurmountable barrier for older adults aged 65 to 75 years, who mostly owned smartphones, whereas older adults aged >75 years may have never been major users of technology in the first place. The most important needs were to be usable, to help patients with reminders, and to provide information on medication side effects and use instructions. Conclusions: Our needs analysis results derived from expert interviews clarify that a voice-based chatbot could be beneficial in improving adherence and overall health if it is built to serve the many medication information needs of older adults, such as reminders and instructions. However, the chatbot must be usable and affordable for its widespread use. © 2022 Elsevier B.V., All rights reserved."
270,1,1.0,"Background: Speech and language cues are considered significant data sources that can reveal insights into one's behavior and well-being. The goal of this study is to evaluate how different machine learning (ML) classifiers trained both on the spoken word and acoustic features during live conversations between family caregivers and a therapist, correlate to anxiety and quality of life (QoL) as assessed by validated instruments. Methods: The dataset comprised of 124 audio-recorded and professionally transcribed discussions between family caregivers of hospice patients and a therapist, of challenges they faced in their caregiving role, and standardized assessments of self-reported QoL and anxiety. We custom-built and trained an Automated Speech Recognition (ASR) system on older adult voices and created a logistic regression-based classifier that incorporated audio-based features. The classification process automated the QoL scoring and display of the score in real time, replacing hand-coding for self-reported assessments with a machine learning identified classifier. Findings: Of the 124 audio files and their transcripts, 87 of these transcripts (70%) were selected to serve as the training set, holding the remaining 30% of the data for evaluation. For anxiety, the results of adding the dimension of sound and an automated speech-to-text transcription outperformed the prior classifier trained only on human-rendered transcriptions. Specifically, precision improved from 86% to 92%, accuracy from 81% to 89%, and recall from 78% to 88%. Interpretation: Classifiers can be developed through ML techniques which can indicate improvements in QoL measures with a reasonable degree of accuracy. Examining the content, sound of the voice and context of the conversation provides insights into additional factors affecting anxiety and QoL that could be addressed in tailored therapy and the design of conversational agents serving as therapy chatbots. © 2022 Elsevier B.V., All rights reserved."
271,0,1.0,"Background: Patients with chronic pain often experience coexisting, long-term and debilitating mental health comorbidities such as depression and anxiety. Artificial intelligence–supported cognitive behavioral therapy (AI-CBT) interventions could offer cost-effective, accessible, and potentially effective resources to address this problem. However, there is not enough research conducted about the efficacy of AI-CBT interventions for chronic pain. Objective: This prospective cohort study aims to examine the efficacy and use of an AI-CBT intervention for chronic pain (Wysa for Chronic Pain app, Wysa Inc) using a conversational agent (with no human intervention). To the best of our knowledge, this is the first such study for chronic pain using a fully-automated, free-text–based conversational agent. Methods: Participants with self-reported chronic pain (n=500) will be recruited online on a rolling basis from April 2022 through posts on US-based internet communities within this prospective cohort. Informed consent is received from participants within the app, and the Wysa for Chronic Pain intervention is delivered remotely for 8 weeks. Outcome measures including a numeric pain rating scale and Patient-Reported Outcomes Measurement Information System–Pain Interference, Generalized Anxiety Disorder–7, and Patient Health Questionnaire–9 questionnaires administered to test the effectiveness of the intervention on reducing levels of pain interference, depression, and anxiety. The therapeutic alliance created with the conversational agent will be assessed through the Working Alliance Inventory–Short Revised instrument. Retention and use statistics will be observed for adherence and engagement. Results: The study will open for recruitment in April 2022, and data collection is expected to be completed by August 2022. The results for the primary outcomes are expected to be published by late 2022. Conclusions: Mental health conversational agents driven by artificial intelligence could be effective in helping patients with chronic pain learn to self-manage their pain and common comorbidities like depression and anxiety. The Wysa for Chronic Pain app is one such digital intervention that can potentially serve as a solution to the problems of affordability and scalability associated with interventions that include a human therapist. This prospective study examines the efficacy of the app as a treatment solution for chronic pain. It aims to inform future practices and digital mental health interventions for individuals with chronic pain. © 2022 Elsevier B.V., All rights reserved."
272,-1,0.24479919127733557,"For years, several countries have been concerned about how to dispose of unused pharmaceuticals that can endanger human health and the environment. Moreover, some people are in desperate need of medical attention and medications, but they lack the financial resources to obtain them. In Saudi Arabia, there are no take-back medicine programs, and there is no published research on how medications properly are disposed. The aim of this research is to use the power of artificial intelligence to assist in the proper management and disposal of expired and unused medications and to develop a prototype device for collecting medication by automatically classifying medications for proper disposal and donation. In this research, artificial intelligence technologies such as web-based expert systems, image recognition and classification algorithms, chatbots, and the internet of things are used to assist in a take-back medications program. In conclusion, the prototype design of a web-based expert system and the device reduced improper disposal risks by providing significant advice on the safe disposal of unwanted pharmaceuticals. By using an organized method of collecting expired medications, the benefits were made possible. © 2022 Elsevier B.V., All rights reserved."
273,0,1.0,"Background: Depression impacts the lives of a large number of university students. Mobile-based therapy chatbots are increasingly being used to help young adults who suffer from depression. However, previous trials have short follow-up periods. Evidence of effectiveness in pragmatic conditions are still in lack. Objective: This study aimed to compare chatbot therapy to bibliotherapy, which is a widely accepted and proven-useful self-help psychological intervention. The main objective of this study is to add to the evidence of effectiveness for chatbot therapy as a convenient, affordable, interactive self-help intervention for depression. Methods: An unblinded randomized controlled trial with 83 university students was conducted. The participants were randomly assigned to either a chatbot test group (n = 41) to receive a newly developed chatbot-delivered intervention, or a bibliotherapy control group (n = 42) to receive a minimal level of bibliotherapy. A set of questionnaires was implemented as measurements of clinical variables at baseline and every 4 weeks for a period of 16 weeks, which included the Patient Health Questionnaire-9 (PHQ-9), the Generalized Anxiety Disorder scale (GAD-7), the Positive and Negative Affect Scale (PANAS). The Client Satisfaction Questionnaire-8 (CSQ-8) and the Working Alliance Inventory-Short Revised (WAI-SR) were used to measure satisfaction and therapeutic alliance after the intervention. Participants' self-reported adherence and feedback on the therapy chatbot were also collected. Results: Participants were all university students (undergraduate students (n = 31), postgraduate students (n = 52)). They were between 19 and 28 years old (mean = 23.08, standard deviation (SD) = 1.76) and 55.42% (46/83) female. 24.07% (20/83) participants were lost to follow-up. No significant group difference was found at baseline. In the intention-to-treat analysis, individuals in the chatbot test group showed a significant reduction in the PHQ-9 scores (F = 22.89; P < 0.01) and the GAD-7 scores (F = 5.37; P = 0.02). Follow-up analysis of completers suggested that the reduction of anxiety was significant only in the first 4 weeks. The WAI-SR scores in the chatbot group were higher compared to the bibliotherapy group (t = 7.29; P < 0.01). User feedback showed that process factors were more influential than the content factors. Conclusions: The chatbot-delivered self-help depression intervention was proven to be superior to the minimal level of bibliotherapy in terms of reduction on depression, anxiety, and therapeutic alliance achieved with participants. © 2022 Elsevier B.V., All rights reserved."
274,3,0.3470236445979443,"Many experts have emphasised that chatbots are not sufficiently mature to be able to technically diagnose patient conditions or replace the judgements of health professionals. The COVID-19 pandemic, however, has significantly increased the utilisation of health-oriented chatbots, for instance, as a conversational interface to answer questions, recommend care options, check symptoms and complete tasks such as booking appointments. In this paper, we take a proactive approach and consider how the emergence of task-oriented chatbots as partially automated consulting systems can influence clinical practices and expert–client relationships. We suggest the need for new approaches in professional ethics as the large-scale deployment of artificial intelligence may revolutionise professional decision-making and client–expert interaction in healthcare organisations. We argue that the implementation of chatbots amplifies the project of rationality and automation in clinical practice and alters traditional decision-making practices based on epistemic probability and prudence. This article contributes to the discussion on the ethical challenges posed by chatbots from the perspective of healthcare professional ethics. © 2022 Elsevier B.V., All rights reserved."
275,1,1.0,"Generative pretrained transformer models have been popular recently due to their enhanced capabilities and performance. In contrast to many existing artificial intelligence models, generative pretrained transformer models can perform with very limited training data. Generative pretrained transformer 3 (GPT-3) is one of the latest releases in this pipeline, demonstrating human-like logical and intellectual responses to prompts. Some examples include writing essays, answering complex questions, matching pronouns to their nouns, and conducting sentiment analyses. However, questions remain with regard to its implementation in health care, specifically in terms of operationalization and its use in clinical practice and research. In this viewpoint paper, we briefly introduce GPT-3 and its capabilities and outline considerations for its implementation and operationalization in clinical practice through a use case. The implementation considerations include (1) processing needs and information systems infrastructure, (2) operating costs, (3) model biases, and (4) evaluation metrics. In addition, we outline the following three major operational factors that drive the adoption of GPT-3 in the US health care system: (1) ensuring Health Insurance Portability and Accountability Act compliance, (2) building trust with health care providers, and (3) establishing broader access to the GPT-3 tools. This viewpoint can inform health care practitioners, developers, clinicians, and decision makers toward understanding the use of the powerful artificial intelligence tools integrated into hospital systems and health care. © 2022 Elsevier B.V., All rights reserved."
276,-1,0.14298193421769964,"Background: Chatbots have been widely used in many spheres of life from customer services to mental health companions. Despite the breakthroughs in achieving human-like conversations, Arabic language chatbots driven by AI and NLP are relatively scarce due to the complex nature of the Arabic language. Objective: We aim to review published literature on Arabic chatbots to gain insight into the technologies used highlighting the gap in this emerging field. Methods: To identify relevant studies, we searched eight bibliographic databases and conducted backward and forward reference checking. Two reviewers independently performed study selection and data extraction. The extracted data was synthesized using a narrative approach. Results: We included 18 of 1755 retrieved publications. Thirteen unique chatbots were identified from the 18 studies. ArabChat was the most common chatbot in the included studies (n = 5). The type of Arabic language in most chatbots (n = 13) was Modern Standard Arabic. The input and output modalities used in 17 chatbots were only text. Most chatbots (n = 14) were able to have long conversations. The majority of the chatbots (n = 14) were developed to serve a specific purpose (Closed domain). A retrieval-based model was used for developing most chatbots (n = 17). Conclusion: Despite a large number of chatbots worldwide, there is relatively a small number of Arabic language chatbots. Furthermore, the available Arabic language chatbots are less advanced than other language chatbots. Researchers should develop more Arabic language chatbots that are based on more advanced input and output modalities, generative-based models, and natural language processing (NLP). © 2023 Elsevier B.V., All rights reserved."
277,-1,0.15068980152159067,"Background: There are many scales for screening the impact of a disease. These scales are generally used to diagnose or assess the type and severity of a disease and are carried out by doctors. The chatbot helps patients suffering from primary headache disorders through personalized text messages. It could be used to collect patient-reported outcomes. Objective: The aims of this study were (1) to study whether the collection and analysis of remote scores, without prior medical intervention, are possible by a chatbot, (2) to perform suggested diagnosis and define the type of headaches, and (3) to assess the patient satisfaction and engagement with the chatbot. Method: Voluntary users of the chatbot were recruited online. They had to be over 18 and have a personal history of headaches. A questionnaire was presented (1) by text messages to the participants to evaluate migraines (2) based on the criteria of the International Headache Society. Then, the Likert scale (3) was used to assess overall satisfaction with the use of the chatbot. Results: We included 610 participants with primary headache disorders. A total of 89.94% (572/610) participants had fully completed the questionnaire (eight items), 4.72% (30/610) had partially completed it, and 5.41% (33) had refused to complete it. Statistical analysis was performed on 86.01% (547/610) of participants. Auto diagnostic showed that 14.26% (78/547) participants had a tension headache, and 85.74% (469/547) had a probable migraine. In this population, 15.78% (74/469) suffered from migraine without probable aura, and 84.22% (395/469) had migraine without aura. The patient’s age had a significant incidence regarding the auto diagnosis (P =.008<.05). The evaluation of overall satisfaction shows that a total of 93.9% (599/610) of users were satisfied or very satisfied regarding the timeliness of responses the chatbot provides. Conclusion: The study confirmed that it was possible to obtain such a collection remotely, and quickly (average time of 3.24 min) with a high success rate (89.67% (547/610) participants who had fully completed the IHS questionnaire). Users were strongly engaged through chatbot: out of the total number of participants, we observed a very low number of uncompleted questionnaires (6.23% (38/610)). Conversational agents can be used to remotely collect data on the nature of the symptoms of patients suffering from primary headache disorders. These results are promising regarding patient engagement and trust in the chatbot. © 2022 Elsevier B.V., All rights reserved."
278,0,1.0,"Background: Chatbots have the potential to provide cost-effective mental health prevention programs at scale and increase interactivity, ease of use, and accessibility of intervention programs. Objective: The development of chatbot prevention for eating disorders (EDs) is still in its infancy. Our aim is to present examples of and solutions to challenges in designing and refining a rule-based prevention chatbot program for EDs, targeted at adult women at risk for developing an ED. Methods: Participants were 2409 individuals who at least began to use an EDs prevention chatbot in response to social media advertising. Over 6 months, the research team reviewed up to 52,129 comments from these users to identify inappropriate responses that negatively impacted users’ experience and technical glitches. Problems identified by reviewers were then presented to the entire research team, who then generated possible solutions and implemented new responses. Results: The most common problem with the chatbot was a general limitation in understanding and responding appropriately to unanticipated user responses. We developed several workarounds to limit these problems while retaining some interactivity. Conclusions: Rule-based chatbots have the potential to reach large populations at low cost but are limited in understanding and responding appropriately to unanticipated user responses. They can be most effective in providing information and simple conversations. Workarounds can reduce conversation errors. © 2022 Elsevier B.V., All rights reserved."
279,0,1.0,"India imposed the largest lockdown in the world in response to fight the spread of the Novel Coronavirus disease (COVID-19) from 19 March till 31 May 2020. The onset of the pandemic left the general public feeling psycho-socially distressed, helpless, and anxious. The researcher developed a Messenger supported Chatbot, based on the broaden and build model, to cater to the healthy general public to promote positivity and mental well-being. 31 participants between 22 and 45 years old consensually took a pre-test, Chatbot intervention, and post-test. The Chatbot provided guided activities out of which positive affirmations, meditation, and exercises were mostly used. The qualitative data from the study shows that the majority of the participants strongly feel positivity is within themselves and that the tool provided a self-help approach to be me well, mentally during the lockdown. The intervention helped significantly reducing symptoms of psychosocial distress in six of the individual’s post-chatbot interventions. Participants’ impressions of the tool suggest more preponderant opportunities for future research in technology-driven mental health support. © 2022 Elsevier B.V., All rights reserved."
280,2,0.3625984535517373,"Chatbots are software applications to simulate a conversation with a person. The effectiveness of chatbots in facilitating the recruitment of study participants in research, specifically among racial and ethnic minorities, is unknown. The objective of this study is to compare a chatbot versus telephone-based recruitment in enrolling research participants from a predominantly minority patient population at an urban institution. We randomly allocated adults to receive either chatbot or telephone-based outreach regarding a study about vaccine hesitancy. The primary outcome was the proportion of participants who provided consent to participate in the study. In 935 participants, the proportion who answered contact attempts was significantly lower in the chatbot versus telephone group (absolute difference -21.8%; 95% confidence interval [CI] -27.0%, -16.5%; P < 0.001). The consent rate was also significantly lower in the chatbot group (absolute difference -3.4%; 95% CI -5.7%, -1.1%; P = 0.004). However, among participants who answered a contact attempt, the difference in consent rates was not significant. In conclusion, the consent rate was lower with chatbot compared to telephone-based outreach. The difference in consent rates was due to a lower proportion of participants in the chatbot group who answered a contact attempt. © 2022 Elsevier B.V., All rights reserved."
281,4,1.0,"Background: Leveraging artificial intelligence (AI)-driven apps for health education and promotion can help in the accomplishment of several United Nations sustainable development goals. SnehAI, developed by the Population Foundation of India, is the first Hinglish (Hindi + English) AI chatbot, deliberately designed for social and behavioral changes in India. It provides a private, nonjudgmental, and safe space to spur conversations about taboo topics (such as safe sex and family planning) and offers accurate, relatable, and trustworthy information and resources. Objective: This study aims to use the Gibson theory of affordances to examine SnehAI and offer scholarly guidance on how AI chatbots can be used to educate adolescents and young adults, promote sexual and reproductive health, and advocate for the health entitlements of women and girls in India. Methods: We adopted an instrumental case study approach that allowed us to explore SnehAI from the perspectives of technology design, program implementation, and user engagement. We also used a mix of qualitative insights and quantitative analytics data to triangulate our findings. Results: SnehAI demonstrated strong evidence across fifteen functional affordances: Accessibility, multimodality, nonlinearity, compellability, queriosity, editability, visibility, interactivity, customizability, trackability, scalability, glocalizability, inclusivity, connectivity, and actionability. SnehAI also effectively engaged its users, especially young men, with 8.2 million messages exchanged across a 5-month period. Almost half of the incoming user messages were texts of deeply personal questions and concerns about sexual and reproductive health, as well as allied topics. Overall, SnehAI successfully presented itself as a trusted friend and mentor; the curated content was both entertaining and educational, and the natural language processing system worked effectively to personalize the chatbot response and optimize user experience. Conclusions: SnehAI represents an innovative, engaging, and educational intervention that enables vulnerable and hard-to-reach population groups to talk and learn about sensitive and important issues. SnehAI is a powerful testimonial of the vital potential that lies in AI technologies for social good. © 2022 Elsevier B.V., All rights reserved."
282,1,1.0,"Virtual assistants are becoming popular in a variety of domains, responsible for automating repetitive tasks or allowing users to seamlessly access useful information. With the advances in Machine Learning and Natural Language Processing, there has been an increasing interest in applying such assistants in new areas and with new capabilities. In particular, their application in e-healthcare is becoming attractive and is driven by the need to access medically-related knowledge, as well as providing first-level assistance in an efficient manner. In such types of virtual assistants, localization is of utmost importance, since the general population (especially the aging population) is not familiar with the needed “healthcare vocabulary” to communicate facts properly; and state-of-practice proves relatively poor in performance when it comes to specialized virtual assistants for less frequently spoken languages. In this context, we present a Greek ML-based virtual assistant specifically designed to address some commonly occurring tasks in the healthcare domain, such as doctor’s appointments or distress (panic situations) management. We build on top of an existing open-source framework, discuss the necessary modifications needed to address the language-specific characteristics and evaluate various combinations of word embeddings and machine learning models to enhance the assistant’s behaviour. Results show that we are able to build an efficient Greek-speaking virtual assistant to support e-healthcare, while the NLP pipeline proposed can be applied in other (less frequently spoken) languages, without loss of generality. © 2021 Elsevier B.V., All rights reserved."
283,0,1.0,"The objective of this study was to assess the feasibility of using a user-centered chatbotfor collecting linked data to study overweight and obesity causes ina target population. In total 980 people participated in the feasibility study organized in three studies: (1) within a group of university students (88 participants), (2) in a small town (422 participants), and (3) within a university community (470 participants). We gathered self-reported data through the Wakamola chatbot regarding participants diet, physical activity, social network, living area, obesity-associated diseases, and sociodemographic data. For each study, we calculated the mean Body Mass Index (BMI) and number of people in each BMI level. Also, we defined and calculated scores (1–100 scale) regarding global health, BMI, alimentation, physical activity and social network. Moreover, we graphically represented obesity risk for living areas and the social network with nodes colored by BMI. Students group results: Mean BMI 21.37 (SD 2.57) (normal weight), 8 people underweight, 5 overweight, 0 obesity, global health status 78.21, alimentation 63.64, physical activity 65.08 and social 26.54, 3 areas with mean BMI level of obesity, 17 with overweight level. Small town´s study results: Mean BMI 25.66 (SD 4.29) (overweight), 2 people underweight, 63 overweight, 26 obesity, global health status 69.42, alimentation 64.60, physical activity 60.61 and social 1.14, 1 area with mean BMI in normal weight; University´s study results: Mean BMI 23.63 (SD 3.7) (normal weight), 22 people underweight, 86 overweight, 28 obesity, global health status 81.03, alimentation 81.84, physical activity 70.01 and social 1.47, 3 areas in obesity level, 19 in overweight level. Wakamola is a health care chatbot useful to collect relevant data from populations in the risk of overweight and obesity. Besides, the chatbot provides individual self-assessment of BMI and general status regarding the style of living. Moreover, Wakamola connects users in a social network to help the study of O&O´s causes from an individual, social and socio-economic perspective. © 2022 Elsevier B.V., All rights reserved."
284,0,0.5058243187579127,"Background: The rising incidence of chronic diseases is a growing concern, especially in Singapore, which is one of the high-income countries with the highest prevalence of diabetes. Interventions that promote healthy lifestyle behavior changes have been proven to be effective in reducing the progression of prediabetes to diabetes, but their in-person delivery may not be feasible on a large scale. Novel technologies such as conversational agents are a potential alternative for delivering behavioral interventions that promote healthy lifestyle behavior changes to the public. Objective: The aim of this study is to assess the feasibility and acceptability of using a conversational agent promoting healthy lifestyle behavior changes in the general population in Singapore. Methods: We performed a web-based, single-arm feasibility study. The participants were recruited through Facebook over 4 weeks. The Facebook Messenger conversational agent was used to deliver the intervention. The conversations focused on diet, exercise, sleep, and stress and aimed to promote healthy lifestyle behavior changes and improve the participants’ knowledge of diabetes. Messages were sent to the participants four times a week (once for each of the 4 topics of focus) for 4 weeks. We assessed the feasibility of recruitment, defined as at least 75% (150/200) of our target sample of 200 participants in 4 weeks, as well as retention, defined as 33% (66/200) of the recruited sample completing the study. We also assessed the participants’ satisfaction with, and usability of, the conversational agent. In addition, we performed baseline and follow-up assessments of quality of life, diabetes knowledge and risk perception, diet, exercise, sleep, and stress. Results: We recruited 37.5% (75/200) of the target sample size in 1 month. Of the 75 eligible participants, 60 (80%) provided digital informed consent and completed baseline assessments. Of these 60 participants, 56 (93%) followed the study through till completion. Retention was high at 93% (56/60), along with engagement, denoted by 50% (30/60) of the participants communicating with the conversational agent at each interaction. Acceptability, usability, and satisfaction were generally high. Preliminary efficacy of the intervention showed no definitive improvements in health-related behavior. Conclusions: The delivery of a conversational agent for healthy lifestyle behavior change through Facebook Messenger was feasible and acceptable. We were unable to recruit our planned sample solely using the free options in Facebook. However, participant retention and conversational agent engagement rates were high. Our findings provide important insights to inform the design of a future randomized controlled trial. © 2021 Elsevier B.V., All rights reserved."
285,0,1.0,"Background: Body image concerns are prevalent among Brazilian adolescents and can lead to poor psychological and physical health. Yet, there is a scarcity of culturally-appropriate, evidence-based interventions that have been evaluated and made widely available. Chatbot technology (i.e., software that mimics written or spoken human speech) offers an innovative method to increase the scalability of mental health interventions for adolescents. The present protocol outlines the co-creation and evaluation of a body image chatbot for Brazilian adolescents via a partnership between academics, industry organisations and the United Nations Children’s Fund (UNICEF). Methods: A two-armed fully remote randomised controlled trial will evaluate the chatbot’s effectiveness at improving body image and well-being. Adolescent girls and boys (N = 2800) aged 13–18 years recruited online will be randomly allocated (1:1) into either: 1) a body image chatbot or 2) an assessment-only control condition. Adolescents will engage with the chatbot over a 72-hour period on Facebook Messenger. Primary outcomes will assess the immediate and short-term impact of the chatbot on state- and trait-based body image, respectively. Secondary outcomes will include state- and trait-based affect, trait self-efficacy and treatment adherence. Discussion: This research is the first to develop an evidence-informed body image chatbot for Brazilian adolescents, with the proposed efficacy trial aiming to provide support for accessible, scalable and cost-effective interventions that address disparities in body image prevalence and readily available resources. Trial registration number: NCT04825184, registered 30th March 2021. © 2021 Elsevier B.V., All rights reserved."
286,-1,0.2569970263471371,"Artificial Intelligence chatbots allow interactive dialogue-driven teaching of medical sciences. Open-source tools allow educators to adapt existing technology to create intelligent learning systems. We utilised an open-source machine learning architecture and fine-tuned it with a customised database to train an AI dialogue system to teach medical students anatomy. © 2021 Elsevier B.V., All rights reserved."
287,0,0.3418223189034585,"Background: The use of chatbots may increase engagement with digital behavior change interventions in youth by providing human-like interaction. Following a Person-Based Approach (PBA), integrating user preferences in digital tool development is crucial for engagement, whereas information on youth preferences for health chatbots is currently limited. Objective: The aim of this study was to gain an in-depth understanding of adolescents' expectations and preferences for health chatbots and describe the systematic development of a health promotion chatbot. Methods: Three studies in three different stages of PBA were conducted: (1) a qualitative focus group study (n = 36), (2) log data analysis during pretesting (n = 6), and (3) a mixed-method pilot testing (n = 73). Results: Confidentiality, connection to youth culture, and preferences when referring to other sources were important aspects for youth in chatbots. Youth also wanted a chatbot to provide small talk and broader support (e.g., technical support with the tool) rather than specifically in relation to health behaviors. Despite the meticulous approach of PBA, user engagement with the developed chatbot was modest. Conclusion: This study highlights that conducting formative research at different stages is an added value and that adolescents have different chatbot preferences than adults. Further improvement to build an engaging chatbot for youth may stem from using living databases. © 2021 Elsevier B.V., All rights reserved."
288,4,1.0,"Background: The emergence of artificial intelligence (AI) provides opportunities for demand management of sexual and reproductive health services. Conversational agents/chatbots are increasingly common, although little is known about how this technology could aid services. This study aimed to identify barriers and facilitators for engagement with sexual health chatbots to advise service developers and related health professionals. Methods: In January-June 2020, we conducted face-to-face, semi-structured and online interviews to explore views on sexual health chatbots. Participants were asked to interact with a chatbot, offering advice on sexually transmitted infections (STIs) and relevant services. Participants were UK-based and recruited via social media. Data were recorded, transcribed verbatim and analysed thematically. Results: Forty participants (aged 18-50 years; 64% women, 77% heterosexual, 58% white) took part. Many thought chatbots could aid sex education, providing useful information about STIs and sign-posting to sexual health services in a convenient, anonymous and non-judgemental way. Some compared chatbots to health professionals or Internet search engines and perceived this technology as inferior, offering constrained content and interactivity, limiting disclosure of personal information, trust and perceived accuracy of chatbot responses. Conclusions: Despite mixed attitudes towards chatbots, this technology was seen as useful for anonymous sex education but less suitable for matters requiring empathy. Chatbots may increase access to clinical services but their effectiveness and safety need to be established. Future research should identify which chatbots designs and functions lead to optimal engagement with this innovation. © 2021 Elsevier B.V., All rights reserved."
289,-1,0.1577331626339127,"Background: Teenage pregnancy remains high with low contraceptive prevalence among adolescents (aged 15-19 years) in Sierra Leone. Stakeholders leverage multiple strategies to address the challenge. Mobile technology is pervasive and presents an opportunity to reach young people with critical sexual reproductive health and family planning messages. Objective: The objectives of this research study are to understand how mobile health (mHealth) is used for family planning, understand phone use habits among young people in Sierra Leone, and recommend strategies for mobile-enabled dissemination of family planning information at scale. Methods: This formative research study was conducted using a systematic literature review and focus group discussions (FGDs). The literature survey assessed similar but existing interventions through a systematic search of 6 scholarly databases. Cross-sections of young people of both sexes and their support groups were engaged in 9 FGDs in an urban and a rural district in Sierra Leone. The FGD data were qualitatively analyzed using MAXQDA software (VERBI Software GmbH) to determine appropriate technology channels, content, and format for different user segments. Results: Our systematic search results were categorized using Grading of Recommended Assessment and Evaluation (GRADE) into communication channels, audiovisual messaging format, purpose of the intervention, and message direction. The majority of reviewed articles report on SMS-based interventions. At the same time, most intervention purposes are for awareness and as helpful resources. Our survey did not find documented use of custom mHealth apps for family planning information dissemination. From the FGDs, more young people in Sierra Leone own basic mobile phones than those that have feature capablilities or are smartphone. Young people with smartphones use them mostly for WhatsApp and Facebook. Young people widely subscribe to the social media-only internet bundle, with the cost ranging from 1000 leones (US $0.11) to 1500 leones (US $0.16) daily. Pupils in both districts top-up their voice call and SMS credit every day between 1000 leones (US $0.11) and 5000 leones (US $0.52). Conclusions: MHealth has facilitated family planning information dissemination for demand creation around the world. Despite the widespread use of social and new media, SMS is the scalable channel to reach literate and semiliterate young people. We have cataloged mHealth for contraceptive research to show SMS followed by call center as widely used channels. Jingles are popular for audiovisual message formats, mostly delivered as either push or pull only message directions (not both). Interactive voice response and automated calls are best suited to reach nonliterate young people at scale. © 2021 Elsevier B.V., All rights reserved."
290,-1,0.257121339772883,"Background: Tuberculosis (TB) is a highly infectious disease. Negative perceptions and insufficient knowledge have made its eradication difficult. Recently, mobile health care interventions, such as an anti-TB chatbot developed by the research team, have emerged in support of TB eradication programs. However, before the anti-TB chatbot is deployed, it is important to understand the factors that predict its acceptance by the population. Objective: This study aims to explore the acceptance of an anti-TB chatbot that provides information about the disease and its treatment to people vulnerable to TB in South Korea. Thus, we are investigating the factors that predict technology acceptance through qualitative research based on the interviews of patients with TB and homeless facility personnel. We are then verifying the extended Technology Acceptance Model (TAM) and predicting the factors associated with the acceptance of the chatbot. Methods: In study 1, we conducted interviews with potential chatbot users to extract the factors that predict user acceptance and constructed a conceptual framework based on the TAM. In total, 16 interviews with patients with TB and one focus group interview with 10 experts on TB were conducted. In study 2, we conducted surveys of potential chatbot users to validate the extended TAM. Survey participants were recruited among late-stage patients in TB facilities and members of web-based communities sharing TB information. A total of 123 responses were collected. Results: The results indicate that perceived ease of use and social influence were significantly predictive of perceived usefulness (P=.04 and P<.001, respectively). Perceived usefulness was predictive of the attitude toward the chatbot (P<.001), whereas perceived ease of use (P=.88) was not. Behavioral intention was positively predicted by attitude toward the chatbot and facilitating conditions (P<.001 and P=.03, respectively). The research model explained 55.4% of the variance in the use of anti-TB chatbots. The moderating effect of TB history was found in the relationship between attitude toward the chatbot and behavioral intention (P=.01) and between facilitating conditions and behavioral intention (P=.02). Conclusions: This study can be used to inform future design of anti-TB chatbots and highlight the importance of services and the environment that empower people to use the technology. © 2021 Elsevier B.V., All rights reserved."
291,0,0.2820952895055089,"Background: The current COVID-19 coronavirus pandemic is an emergency on a global scale, with huge swathes of the population required to remain indoors for prolonged periods to tackle the virus. In this new context, individuals' health-promoting routines are under greater strain, contributing to poorer mental and physical health. Additionally, individuals are required to keep up to date with latest health guidelines about the virus, which may be confusing in an age of social-media disinformation and shifting guidelines. To tackle these factors, we developed Elena+, a smartphone-based and conversational agent (CA) delivered pandemic lifestyle care intervention. Methods: Elena+ utilizes varied intervention components to deliver a psychoeducation-focused coaching program on the topics of: COVID-19 information, physical activity, mental health (anxiety, loneliness, mental resources), sleep and diet and nutrition. Over 43 subtopics, a CA guides individuals through content and tracks progress over time, such as changes in health outcome assessments per topic, alongside user-set behavioral intentions and user-reported actual behaviors. Ratings of the usage experience, social demographics and the user profile are also captured. Elena+ is available for public download on iOS and Android devices in English, European Spanish and Latin American Spanish with future languages and launch countries planned, and no limits on planned recruitment. Panel data methods will be used to track user progress over time in subsequent analyses. The Elena+ intervention is open-source under the Apache 2 license (MobileCoach software) and the Creative Commons 4.0 license CC BY-NC-SA (intervention logic and content), allowing future collaborations; such as cultural adaptions, integration of new sensor-related features or the development of new topics. Discussion: Digital health applications offer a low-cost and scalable route to meet challenges to public health. As Elena+ was developed by an international and interdisciplinary team in a short time frame to meet the COVID-19 pandemic, empirical data are required to discern how effective such solutions can be in meeting real world, emergent health crises. Additionally, clustering Elena+ users based on characteristics and usage behaviors could help public health practitioners understand how population-level digital health interventions can reach at-risk and sub-populations. © 2021 Elsevier B.V., All rights reserved."
292,0,0.17103251679418796,"Social isolation has affected people globally during the COVID-19 pandemic and had a major impact on older adult's well-being. Chatbot interventions may be a way to provide support to address loneliness and social isolation in older adults. The aims of the current study were to (1) understand the distribution of a chatbot's net promoter scores, (2) conduct a thematic analysis on qualitative elaborations to the net promoter scores, (3) understand the distribution of net promoter scores per theme, and (4) conduct a single word analysis to understand the frequency of words present in the qualitative feedback. A total of 7,099 adults and older adults consented to participate in a chatbot intervention on reducing social isolation and loneliness. The average net promoter score (NPS) was 8.67 out of 10. Qualitative feedback was provided by 766 (10.79%) participants which amounted to 898 total responses. Most themes were rated as positive (517), followed by neutral (311) and a minor portion as negative (70). The following five themes were found across the qualitative responses: positive outcome (277, 30.8%), user did not address question (262, 29.2%), bonding with the chatbot (240, 26.7%), negative technical aspects (70, 7.8%), and ambiguous outcome (49, 5.5%). Themes with a positive valence were found to be associated with a higher NPS. The word “help” and it's variations were found to be the most frequently used words, which is consistent with the thematic analysis. These results show that a chatbot for social isolation and loneliness was perceived positively by most participants. More specifically, users were likely to personify the chatbot (e.g., “Cause I feel like I have a new friend!”) and perceive positive personality features such as being non-judgmental, caring, and open to listen. A minor portion of the users reported dissatisfaction with chatting with a machine. Implications will be discussed. © 2023 Elsevier B.V., All rights reserved."
293,-1,0.3987022449357676,"Background: Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective: This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods: A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results: Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions: Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine. © 2022 Elsevier B.V., All rights reserved."
294,-1,0.17644903621575714,"Background: Conversational agents, which we defined as computer programs that are designed to simulate two-way human conversation by using language and are potentially supplemented with nonlanguage modalities, offer promising avenues for health interventions for different populations across the life course. There is a lack of open-access and user-friendly resources for identifying research trends and gaps and pinpointing expertise across international centers. Objective: Our aim is to provide an overview of all relevant evidence on conversational agents for health and well-being across the life course. Specifically, our objectives are to identify, categorize, and synthesize-through visual formats and a searchable database-primary studies and reviews in this research field. Methods: An evidence map was selected as the type of literature review to be conducted, as it optimally corresponded to our aim. We systematically searched 8 databases (MEDLINE; CINAHL; Web of Science; Scopus; the Cochrane, ACM, IEEE, and Joanna Briggs Institute databases; and Google Scholar). We will perform backward citation searching on all included studies. The first stage of a double-stage screening procedure, which was based on abstracts and titles only, was conducted by using predetermined eligibility criteria for primary studies and reviews. An operational screening procedure was developed for streamlined and consistent screening across the team. Double data extraction will be performed with previously piloted data collection forms. We will appraise systematic reviews by using A Measurement Tool to Assess Systematic Reviews (AMSTAR) 2. Primary studies and reviews will be assessed separately in the analysis. Data will be synthesized through descriptive statistics, bivariate statistics, and subgroup analysis (if appropriate) and through high-level maps such as scatter and bubble charts. The development of the searchable database will be informed by the research questions and data extraction forms. Results: As of April 2021, the literature search in the eight databases was concluded, yielding a total of 16,351 records. The first stage of screening, which was based on abstracts and titles only, resulted in the selection of 1282 records of primary studies and 151 records of reviews. These will be subjected to second-stage screening. A glossary with operational definitions for supporting the study selection and data extraction stages was drafted. The anticipated completion date is October 2021 Conclusions: Our wider definition of a conversational agent and the broad scope of our evidence map will explicate trends and gaps in this field of research. Additionally, our evidence map and searchable database of studies will help researchers to avoid fragmented research efforts and wasteful redundancies. Finally, as part of the Harnessing the Power of Conversational e-Coaches for Health and Well-being Through Swiss-Portuguese Collaboration project, our work will also inform the development of an international taxonomy on conversational agents for health and well-being, thereby contributing to terminology standardization and categorization. 10.2196/26680. © 2021 Elsevier B.V., All rights reserved."
295,0,0.3783352584441806,"Background: Approximately 60%-80% of the primary care visits have a psychological stress component, but only 3% of patients receive stress management advice during these visits. Given recent advances in natural language processing, there is renewed interest in mental health chatbots. Conversational agents that can understand a user's problems and deliver advice that mitigates the effects of daily stress could be an effective public health tool. However, such systems are complex to build and costly to develop. Objective: To address these challenges, our aim is to develop and evaluate a fully automated mobile suite of shallow chatbots-we call them Popbots-that may serve as a new species of chatbots and further complement human assistance in an ecosystem of stress management support. Methods: After conducting an exploratory Wizard of Oz study (N=14) to evaluate the feasibility of a suite of multiple chatbots, we conducted a web-based study (N=47) to evaluate the implementation of our prototype. Each participant was randomly assigned to a different chatbot designed on the basis of a proven cognitive or behavioral intervention method. To measure the effectiveness of the chatbots, the participants' stress levels were determined using self-reported psychometric evaluations (eg, web-based daily surveys and Patient Health Questionnaire-4). The participants in these studies were recruited through email and enrolled on the web, and some of them participated in follow-up interviews that were conducted in person or on the web (as necessary). Results: Of the 47 participants, 31 (66%) completed the main study. The findings suggest that the users viewed the conversations with our chatbots as helpful or at least neutral and came away with increasingly positive sentiment toward the use of chatbots for proactive stress management. Moreover, those users who used the system more often (ie, they had more than or equal to the median number of conversations) noted a decrease in depression symptoms compared with those who used the system less often based on a Wilcoxon signed-rank test (W=91.50; Z=-2.54; P=.01; r=0.47). The follow-up interviews with a subset of the participants indicated that half of the common daily stressors could be discussed with chatbots, potentially reducing the burden on human coping resources Conclusions: Our work suggests that suites of shallow chatbots may offer benefits for both users and designers. As a result, this study's contributions include the design and evaluation of a novel suite of shallow chatbots for daily stress management, a summary of benefits and challenges associated with random delivery of multiple conversational interventions, and design guidelines and directions for future research into similar systems, including authoring chatbot systems and artificial intelligence-enabled recommendation algorithms. © 2021 Elsevier B.V., All rights reserved."
296,3,1.0,"Background: The use of digital health resources is growing quickly as they are easily accessible and permit self-evaluation. Yet, research on consumer health informatics platforms is insufficient. Chatbots, interactive conversational platforms based on artificial intelligence, can facilitate access to specific information. Hidradenitis suppurativa (HS) is burdensome and has a high threshold for consultation. Objectives: We aimed to identify the most important principles for the assembly of medical chatbots through the analysis of usage data. Methods: The HS Chatbot<A51_FootRef>1</A51_FootRef> is a question-and-answer platform in the style of a chatbot. Usage data were collected over the course of a year. 254 responses were statistically analysed. Results: 239 users were alleged patients. 82.9% were looking for a tentative diagnosis. The users were on average 32.49 (±11.33) years old and predominantly female (70.2%). The average number of clicks per visit on the website was 14.69 (±8.83). Conclusions: A medical chatbot has to be customised to the specific subject whilst general principles have to be considered. High-quality information has to be available in just a few clicks. People concerned about HS are looking for a diagnosis online and often have not seen a doctor previously. Guidance towards appropriate care should be provided. © 2021 Elsevier B.V., All rights reserved."
297,3,0.4043205321431638,"Forms of artificial intelligence (AI), such as chatbots that provide automated online counselling, promise to revolutionise alcohol and other drug treatment. Although the replacement of human counsellors remains a speculative prospect, chatbots for ‘narrow AI’ tasks (e.g., assessment and referral) are increasingly being used to augment clinical practice. Little research has addressed the possibilities for care that chatbots may generate in the future, particularly in the context of alcohol and other drug counselling. To explore these issues, we draw on the concept of technological ‘affordances’ and identify the range of possibilities for care that emerging chatbot interventions may afford and foreclose depending on the contexts in which they are implemented. Our analysis is based on qualitative data from interviews with clients (n=20) and focus group discussions with counsellors (n=8) conducted as part of a larger study of an Australian online alcohol and other drug counselling service. Both clients and counsellors expressed a concern that chatbot interventions lacked a ‘human’ element, which they valued in empathic care encounters. Most clients reported that they would share less information with a chatbot than a human counsellor, and they viewed this as constraining care. However, clients and counsellors suggested that the use of narrow AI might afford possibilities for performing discrete tasks, such as screening, triage or referral. In the context of what we refer to as ‘more-than-human’ care, our findings reveal complex views about the types of affordances that chatbots may produce and foreclose in online care encounters. We conclude by discussing implications for the potential ‘addiction futures’ and care trajectories that AI technologies offer, focussing on how they might inform alcohol and other drug policy, and the design of digital healthcare. © 2021 Elsevier B.V., All rights reserved."
298,1,0.3609823241228002,"Background: Due to an aging population, the demand for many services is exceeding the capacity of the clinical workforce. As a result, staff are facing a crisis of burnout from being pressured to deliver high-volume workloads, driving increasing costs for providers. Artificial intelligence (AI), in the form of conversational agents, presents a possible opportunity to enable efficiency in the delivery of care. Objective: This study aims to evaluate the effectiveness, usability, and acceptability of Dora agent: Ufonia's autonomous voice conversational agent, an AI-enabled autonomous telemedicine call for the detection of postoperative cataract surgery patients who require further assessment. The objectives of this study are to establish Dora's efficacy in comparison with an expert clinician, determine baseline sensitivity and specificity for the detection of true complications, evaluate patient acceptability, collect evidence for cost-effectiveness, and capture data to support further development and evaluation. Methods: Using an implementation science construct, the interdisciplinary study will be a mixed methods phase 1 pilot establishing interobserver reliability of the system, usability, and acceptability. This will be done using the following scales and frameworks: the system usability scale; assessment of Health Information Technology Interventions in Evidence-Based Medicine Evaluation Framework; the telehealth usability questionnaire; and the Non-Adoption, Abandonment, and Challenges to the Scale-up, Spread and Suitability framework. Results: The evaluation is expected to show that conversational technology can be used to conduct an accurate assessment and that it is acceptable to different populations with different backgrounds. In addition, the results will demonstrate how successfully the system can be delivered in organizations with different clinical pathways and how it can be integrated with their existing platforms. Conclusions: The project's key contributions will be evidence of the effectiveness of AI voice conversational agents and their associated usability and acceptability. © 2021 Elsevier B.V., All rights reserved."
299,-1,0.19128067172147645,"Background: Conversational agents or chatbots are computer programs that simulate conversations with users. Conversational agents are increasingly used for delivery of behavior change interventions in health care. Behavior change is complex and comprises the use of one or several components collectively known as behavioral change techniques (BCTs). Objective: The objective of this scoping review is to identify the BCTs that are used in behavior change-focused interventions delivered via conversational agents in health care. Methods: This scoping review will be performed in line with the Joanna Briggs Institute methodology and will be reported according to the PRISMA extension for scoping reviews guidelines. We will perform a comprehensive search of electronic databases and grey literature sources, and will check the reference lists of included studies for additional relevant studies. The screening and data extraction will be performed independently and in parallel by two review authors. Discrepancies will be resolved through consensus or discussion with a third review author. We will use a data extraction form congruent with the key themes and aims of this scoping review. BCTs employed in the included studies will be coded in line with BCT Taxonomy v1. We will analyze the data qualitatively and present it in diagrammatic or tabular form, alongside a narrative summary. Results: To date, we have designed the search strategy and performed the search on April 26, 2021. The first round of screening of retrieved articles is planned to begin soon. Conclusions: Using appropriate BCTs in the design and delivery of health care interventions via conversational agents is essential to improve long-term outcomes. Our findings will serve to inform the development of future interventions in this area. © 2021 Elsevier B.V., All rights reserved."
300,2,1.0,"The novel coronavirus disease (COVID-19) forced rapid adaptations in the way healthcare is delivered and coordinated by health systems. Brazil has a universal public health system (Sistema Unico de Saúde—SUS), being the main source of care for 75% of the population. Therefore, a saturation of the system was foreseen with the continuous increase of cases. The use of Artificial Intelligence (AI) to empower telehealth could help to tackle this by increasing a coordinated patient access to the health system. In the present study we describe a descriptive case report analyzing the use of Laura Digital Emergency Room—an AI-powered telehealth platform—in three different cities. It was computed around 130,000 interactions made by the chatbot and 24,162 patients completed the digital triage. Almost half (44.8%) of the patients were classified as having mild symptoms, 33.6% were classified as moderate and only 14.2% were classified as severe. The implementation of an AI-powered telehealth to increase accessibility while maintaining safety and leveraging value amid the unprecedent impact of the COVID-19 pandemic was feasible in Brazil and may reduce healthcare overload. New efforts to yield sustainability of affordable and scalable solutions are needed to truly leverage value in health care systems, particularly in the context of middle-low-income countries. © 2023 Elsevier B.V., All rights reserved."
301,0,1.0,"Background: Body image and eating disorders represent a significant public health concern; however, many affected individuals never access appropriate treatment. Conversational agents or chatbots reflect a unique opportunity to target those affected online by providing psychoeducation and coping skills, thus filling the gap in service provision. Objective: A world-first body image chatbot called “KIT” was designed. The aim of this study was to assess preliminary acceptability and feasibility via the collection of qualitative feedback from young people and parents/carers regarding the content, structure, and design of the chatbot, in accordance with an agile methodology strategy. The chatbot was developed in collaboration with Australia’s national eating disorder support organization, the Butterfly Foundation. Methods: A conversation decision tree was designed that offered psychoeducational information on body image and eating disorders, as well as evidence-based coping strategies. A version of KIT was built as a research prototype to deliver these conversations. Six focus groups were conducted using online semistructured interviews to seek feedback on the KIT prototype. This included four groups of people seeking help for themselves (n=17; age 13-18 years) and two groups of parents/carers (n=8; age 46-57 years). Participants provided feedback on the cartoon chatbot character design, as well as the content, structure, and design of the chatbot webchat. Results: Thematic analyses identified the following three main themes from the six focus groups: (1) chatbot character and design, (2) content presentation, and (3) flow. Overall, the participants provided positive feedback regarding KIT, with both young people and parents/carers generally providing similar reflections. The participants approved of KIT’s character and engagement. Specific suggestions were made regarding the brevity and tone to increase KIT’s interactivity. Conclusions: Focus groups provided overall positive qualitative feedback regarding the content, structure, and design of the body image chatbot. Incorporating the feedback of lived experience from both individuals and parents/carers allowed the refinement of KIT in the development phase as per an iterative agile methodology. Further research is required to evaluate KIT’s efficacy. © 2021 Elsevier B.V., All rights reserved."
302,5,1.0,"AIM: Patients and families can independently identify health conditions through the chatbot teleassessment nursing application. METHODS: Design descriptive with a cross-sectional approach. The sampling technique used in this study was a purposive sampling technique. Setting at African Social Research Initiative (ASRI) Wound Care Pancing Medan, North Sumatra. One hundred and forty-seven at ASRI wound care clinic and 107 samples with characteristics that all people who have Android and have a telegram application. Data were processed and carried out by descriptive statistical tests. Tested the use of chatbots on outpatients at the ASRI wound care clinic. Participants are first taught how to use the application. This was carried out for 5 months from March to July by testing the use of a chatbot on outpatients at the ASRI wound care clinic. RESULTS: The results of research on teleassessment nursing found that 73 respondents (68%) could do it independently and 34 respondents (32%) could not do it due to their first experience of using chatbots, unstable internet networks, not yet proficient in using applications due to age and low educational background. The study also identified the respondent’s ability to make decisions about using health services. CONCLUSION: The telassessment nursing chatbot application allows patients and families to assess general conditions, danger signs and make decisions to use health services. TRIAL REGISTRATION TRIAL: Nursing Health Research Ethics Commission University of North Sumatera with number 2165/VI/SP/2020. © 2021 Elsevier B.V., All rights reserved."
303,1,1.0,"Background: The COVID-19 pandemic has limited daily activities and even contact between patients and primary care providers. This makes it more difficult to provide adequate primary care services, which include connecting patients to an appropriate medical specialist. A smartphone-compatible artificial intelligence (AI) chatbot that classifies patients'symptoms and recommends the appropriate medical specialty could provide a valuable solution. Objective: In order to establish a contactless method of recommending the appropriate medical specialty, this study aimed to construct a deep learning-based natural language processing (NLP) pipeline and to develop an AI chatbot that can be used on a smartphone. Methods: We collected 118,008 sentences containing information on symptoms with labels (medical specialty), conducted data cleansing, and finally constructed a pipeline of 51,134 sentences for this study. Several deep learning models, including 4 different long short-term memory (LSTM) models with or without attention and with or without a pretrained FastText embedding layer, as well as bidirectional encoder representations from transformers for NLP, were trained and validated using a randomly selected test data set. The performance of the models was evaluated on the basis of the precision, recall, F1-score, and area under the receiver operating characteristic curve (AUC). An AI chatbot was also designed to make it easy for patients to use this specialty recommendation system. We used an open-source framework called ""Alpha"" to develop our AI chatbot. This takes the form of a web-based app with a frontend chat interface capable of conversing in text and a backend cloud-based server application to handle data collection, process the data with a deep learning model, and offer the medical specialty recommendation in a responsive web that is compatible with both desktops and smartphones. Results: The bidirectional encoder representations from transformers model yielded the best performance, with an AUC of 0.964 and F1-score of 0.768, followed by LSTM model with embedding vectors, with an AUC of 0.965 and F1-score of 0.739. Considering the limitations of computing resources and the wide availability of smartphones, the LSTM model with embedding vectors trained on our data set was adopted for our AI chatbot service. We also deployed an Alpha version of the AI chatbot to be executed on both desktops and smartphones. Conclusions: With the increasing need for telemedicine during the current COVID-19 pandemic, an AI chatbot with a deep learning-based NLP model that can recommend a medical specialty to patients through their smartphones would be exceedingly useful. This chatbot allows patients to identify the proper medical specialist in a rapid and contactless manner, based on their symptoms, thus potentially supporting both patients and primary care providers. © 2021 Elsevier B.V., All rights reserved."
304,5,1.0,"Objective: Chatbots have potential to deliver interactive self-management interventions but have rarely been studied in the context of hypertension or medication adherence. The objective of this study was to better understand patient information needs and perceptions of chatbots to support hypertension medication self-management. Materials and Methods: Mixed methods were used to assess self-management needs and preferences for using chatbots. We purposively sampled adults with hypertension who were prescribed at least one medication. Participants completed questionnaires on sociodemographics, health literacy, self-efficacy, and technology use. Semi-structured interviews were conducted, audio-recorded, and transcribed verbatim. Quantitative data were analyzed using descriptive statistics, and qualitative data were analyzed using applied thematic analysis. Results: Thematic saturation was met after interviewing 15 participants. Analysis revealed curiosity toward chatbots, and most perceived them as humanlike. The majority were interested in using a chatbot to help manage medications, refills, communicate with care teams, and for accountability toward self-care tasks. Despite general enthusiasm, there were concerns with chatbots providing too much information, making demands for lifestyle changes, invading privacy, and usability issues with deployment on smartphones. Those with overall positive perceptions toward chatbots were younger and taking fewer medications. Discussion: Chatbot-related informational needs were consistent with existing self-management research, and many felt chatbots would be valuable if customizable and compatible with patient portals, pharmacies, or health apps. Conclusion: Although most were not familiar with chatbots, patients were interested in interacting with them, but this varied. This research informs future design and functionalities of conversational interfaces to support hypertension self-management. © 2022 Elsevier B.V., All rights reserved."
305,0,1.0,"Background: Obesity and overweight are a serious health problem worldwide with multiple and connected causes. Simultaneously, chatbots are becoming increasingly popular as a way to interact with users in mobile health apps. Objective: This study reports the user-centered design and feasibility study of a chatbot to collect linked data to support the study of individual and social overweight and obesity causes in populations. Methods: We first studied the users’ needs and gathered users’ graphical preferences through an open survey on 52 wireframes designed by 150 design students; it also included questions about sociodemographics, diet and activity habits, the need for overweight and obesity apps, and desired functionality. We also interviewed an expert panel. We then designed and developed a chatbot. Finally, we conducted a pilot study to test feasibility. Results: We collected 452 answers to the survey and interviewed 4 specialists. Based on this research, we developed a Telegram chatbot named Wakamola structured in six sections: personal, diet, physical activity, social network, user's status score, and project information. We defined a user's status score as a normalized sum (0-100) of scores about diet (frequency of eating 50 foods), physical activity, BMI, and social network. We performed a pilot to evaluate the chatbot implementation among 85 healthy volunteers. Of 74 participants who completed all sections, we found 8 underweight people (11%), 5 overweight people (7%), and no obesity cases. The mean BMI was 21.4 kg/m2 (normal weight). The most consumed foods were olive oil, milk and derivatives, cereals, vegetables, and fruits. People walked 10 minutes on 5.8 days per week, slept 7.02 hours per day, and were sitting 30.57 hours per week. Moreover, we were able to create a social network with 74 users, 178 relations, and 12 communities. Conclusions: The Telegram chatbot Wakamola is a feasible tool to collect data from a population about sociodemographics, diet patterns, physical activity, BMI, and specific diseases. Besides, the chatbot allows the connection of users in a social network to study overweight and obesity causes from both individual and social perspectives. © 2021 Elsevier B.V., All rights reserved."
306,0,0.545956223573663,"Background: Stress, burnout, and mental health problems such as depression and anxiety are common, and can significantly impact workplaces through absenteeism and reduced productivity. To address this issue, organizations must first understand the extent of the difficulties by mapping the mental health of their workforce. Online surveys are a cost-effective and scalable approach to achieve this but typically have low response rates, in part due to a lack of interactivity. Chatbots offer one potential solution, enhancing engagement through simulated natural human conversation and use of interactive features. Objective: The aim of this study was to explore if a text-based chatbot is a feasible approach to engage and motivate employees to complete a workplace mental health assessment. This paper describes the design process and results of a pilot implementation. Methods: A fully automated chatbot (“Viki”) was developed to evaluate employee risks of suffering from depression, anxiety, stress, insomnia, burnout, and work-related stress. Viki uses a conversation style and gamification features to enhance engagement. A cross-sectional analysis was performed to gain first insights of a pilot implementation within a small to medium–sized enterprise (120 employees). Results: The response rate was 64.2% (77/120). In total, 98 employees started the assessment, 77 of whom (79%) completed it. The majority of participants scored in the mild range for anxiety (20/40, 50%) and depression (16/28, 57%), in the moderate range for stress (10/22, 46%), and at the subthreshold level for insomnia (14/20, 70%) as defined by their questionnaire scores. Conclusions: A chatbot-based workplace mental health assessment seems to be a highly engaging and effective way to collect anonymized mental health data among employees with response rates comparable to those of face-to-face interviews. © 2021 Elsevier B.V., All rights reserved."
307,0,1.0,"Background: Software agents are computer-programs that conduct conversations with a human. The present study evaluates the feasibility of the software agent “SISU” aiming to uplift psychological wellbeing. Methods: Within a one-group pretest-posttest trial, N = 30 German-speaking participants were recruited. Assessments took place before (t1), during (t2) and after (t3) the intervention. The ability of SISU to guide participants through the intervention, acceptability, and negative effects were investigated. Data analyses are based on intention-to-treat principles. Linear mixed models will be used to investigate short-term changes over time in mood, depression, anxiety. Intervention: The intervention consists of two sessions. Each session comprises writing tasks on autobiographical negative life events and an Acceptance- and Commitment Therapy-based exercise respectively. Participants interact with the software agent on two consecutive days for about 30 min each. Results: All participants completed all sessions within two days. User experience was positive, with all subscales of the user experience questionnaire (UEQ) M > 0.8. Participants experienced their writings as highly self-relevant and personal. However, 57% of the participants reported at least one negative effect attributed to the intervention. Results on linear mixed models indicate an increase in anxiety over time (β = 1.33, p = .001). Qualitative User Feedback revealed that the best thing about SISU was its innovativeness (13%) and anonymity (13%). As worst thing about SISU participants indicated that the conversational style of SISU often felt unnatural (73%). Conclusion: SISU successfully guided participants through the two-day intervention. Moreover, SISU has the potential to enter the inner world of participants. However, intervention contents have the potential to evoke negative effects in individuals. Expectable short-term symptom deterioration due to writing about negative autobiographical life events could not be prevented by acceptance and commitment therapy-based exercises. Hence, results suggest a revision of intervention contents as well as of the conversational style of SISU. The good adherence rate indicates the useful and acceptable format of SISU as a mental health chatbot. Overall, little is known about the effectiveness of software agents in the context of psychological wellbeing. Results of the present trial underline that the innovative technology bears the potential of SISU to act as therapeutic agent but should not be used with its current intervention content. Trial-registration: The Trial is registered at the WHO International Clinical Trials Registry Platform via the German Clinical Studies Register (DRKS): DRKS00014933 (date of registration: 20.06.2018). Link: https://www.drks.de/drks_web/navigate.do?navigationId=trial.HTML&TRIAL_ID=DRKS00014933. © 2025 Elsevier B.V., All rights reserved."
308,0,1.0,"Background: Misuse of substances is common, can be serious and costly to society, and often goes untreated due to barriers to accessing care. Woebot is a mental health digital solution informed by cognitive behavioral therapy and built upon an artificial intelligence-driven platform to deliver tailored content to users. In a previous 2-week randomized controlled trial, Woebot alleviated depressive symptoms. Objective: This study aims to adapt Woebot for the treatment of substance use disorders (W-SUDs) and examine its feasibility, acceptability, and preliminary efficacy. Methods: American adults (aged 18-65 years) who screened positive for substance misuse without major health contraindications were recruited from online sources and flyers and enrolled between March 27 and May 6, 2020. In a single-group pre/postdesign, all participants received W-SUDs for 8 weeks. W-SUDs provided mood, craving, and pain tracking and modules (psychoeducational lessons and psychotherapeutic tools) using elements of dialectical behavior therapy and motivational interviewing. Paired samples t tests and McNemar nonparametric tests were used to examine within-subject changes from pre- to posttreatment on measures of substance use, confidence, cravings, mood, and pain. Results: The sample (N=101) had a mean age of 36.8 years (SD 10.0), and 75.2% (76/101) of the participants were female, 78.2% (79/101) were non-Hispanic White, and 72.3% (73/101) were employed. Participants'W-SUDs use averaged 15.7 (SD 14.2) days, 12.1 (SD 8.3) modules, and 600.7 (SD 556.5) sent messages. About 94% (562/598) of all completed psychoeducational lessons were rated positively. From treatment start to end, in-app craving ratings were reduced by half (87/101, 86.1% reporting cravings in the app; odds ratio 0.48, 95% CI 0.32-0.73). Posttreatment assessment completion was 50.5% (51/101), with better retention among those who initially screened higher on substance misuse. From pre- to posttreatment, confidence to resist urges to use substances significantly increased (mean score change +16.9, SD 21.4; P<.001), whereas past month substance use occasions (mean change -9.3, SD 14.1; P<.001) and scores on the Alcohol Use Disorders Identification Test-Concise (mean change -1.3, SD 2.6; P<.001), 10-item Drug Abuse Screening Test (mean change -1.2, SD 2.0; P<.001), Patient Health Questionnaire-8 item (mean change 2.1, SD 5.2; P=.005), Generalized Anxiety Disorder-7 (mean change -2.3, SD 4.7; P=.001), and cravings scale (68.6% vs 47.1% moderate to extreme; P=.01) significantly decreased. Most participants would recommend W-SUDs to a friend (39/51, 76%) and reported receiving the service they desired (41/51, 80%). Fewer felt W-SUDs met most or all of their needs (22/51, 43%). Conclusions: W-SUDs was feasible to deliver, engaging, and acceptable and was associated with significant improvements in substance use, confidence, cravings, depression, and anxiety. Study attrition was high. Future research will evaluate W-SUDs in a randomized controlled trial with a more diverse sample and with the use of greater study retention strategies. © 2021 Elsevier B.V., All rights reserved."
309,-1,0.1642746816205194,"Background: To motivate people to adopt medical chatbots, the establishment of a specialized medical knowledge database that fits their personal interests is of great importance in developing a chatbot for perinatal care, particularly with the help of health professionals. Objective: The objectives of this study are to develop and evaluate a user-friendly question-and-answer (Q&A) knowledge database–based chatbot (Dr. Joy) for perinatal women’s and their partners’ obstetric and mental health care by applying a text-mining technique and implementing contextual usability testing (UT), respectively, thus determining whether this medical chatbot built on mobile instant messenger (KakaoTalk) can provide its male and female users with good user experience. Methods: Two men aged 38 and 40 years and 13 women aged 27 to 43 years in pregnancy preparation or different pregnancy stages were enrolled. All participants completed the 7-day-long UT, during which they were given the daily tasks of asking Dr. Joy at least 3 questions at any time and place and then giving the chatbot either positive or negative feedback with emoji, using at least one feature of the chatbot, and finally, sending a facilitator all screenshots for the history of the day’s use via KakaoTalk before midnight. One day after the UT completion, all participants were asked to fill out a questionnaire on the evaluation of usability, perceived benefits and risks, intention to seek and share health information on the chatbot, and strengths and weaknesses of its use, as well as demographic characteristics. Results: Despite the relatively higher score of ease of learning (EOL), the results of the Spearman correlation indicated that EOL was not significantly associated with usefulness (ρ=0.26; P=.36), ease of use (ρ=0.19; P=.51), satisfaction (ρ=0.21; P=.46), or total usability scores (ρ=0.32; P=.24). Unlike EOL, all 3 subfactors and the total usability had significant positive associations with each other (all ρ>0.80; P<.001). Furthermore, perceived risks exhibited no significant negative associations with perceived benefits (ρ=−0.29; P=.30) or intention to seek (SEE; ρ=−0.28; P=.32) or share (SHA; ρ=−0.24; P=.40) health information on the chatbot via KakaoTalk, whereas perceived benefits exhibited significant positive associations with both SEE and SHA. Perceived benefits were more strongly associated with SEE (ρ=0.94; P<.001) than with SHA (ρ=0.70; P=.004). Conclusions: This study provides the potential for the uptake of this newly developed Q&A knowledge database–based KakaoTalk chatbot for obstetric and mental health care. As Dr. Joy had quality contents with both utilitarian and hedonic value, its male and female users could be encouraged to use medical chatbots in a convenient, easy-to-use, and enjoyable manner. To boost their continued usage intention for Dr. Joy, its Q&A sets need to be periodically updated to satisfy user intent by monitoring both male and female user utterances. © 2021 Elsevier B.V., All rights reserved."
310,5,1.0,"(1) Background: Follow-up management of workers’ general health examination (WGHE) is important, but it is not currently well done. Chatbot, a type of digital healthcare tool, is used in various medical fields but has never been developed for follow-up management of WGHE in Korea. (2) Methods: The database containing results and explanations related to WGHE was constructed. Then, the channel, which connects users with the database was created. A user survey regarding effectiveness was administered to 23 healthcare providers. Additionally, interviews on applicability for occupational health services were conducted with six nurses in the agency of occupational health management. (3) Results: Chatbot was implemented on a small scale on the Amazon cloud service (AWS) EC2 using KaKaoTalk and Web Chat as user channels. Regarding the effectiveness, 21 (91.30%) rated the need for chatbots as very high; however, 11 (47.83%) rated the usability as not high. Of the 23 participants, 14 (60.87%) expressed overall satisfaction. Nurses appreciated the chat-bot program as a method for resolving accessibility and as an aid for explaining examination results and follow-up management. (4) Conclusions: The effectiveness of WGHE and the applicability in the occupational health service of the chatbot program for follow-up management can be confirmed. © 2021 Elsevier B.V., All rights reserved."
311,-1,0.12908425076112054,"Background: Successful management of chronic diseases requires a trustful collaboration between health care professionals, patients, and family members. Scalable conversational agents, designed to assist health care professionals, may play a significant role in supporting this collaboration in a scalable way by reaching out to the everyday lives of patients and their family members. However, to date, it remains unclear whether conversational agents, in such a role, would be accepted and whether they can support this multistakeholder collaboration. Objective: With asthma in children representing a relevant target of chronic disease management, this study had the following objectives: (1) to describe the design of MAX, a conversational agent-delivered asthma intervention that supports health care professionals targeting child-parent teams in their everyday lives; and (2) to assess the (a) reach of MAX, (b) conversational agent-patient working alliance, (c) acceptance of MAX, (d) intervention completion rate, (e) cognitive and behavioral outcomes, and (f) human effort and responsiveness of health care professionals in primary and secondary care settings. Methods: MAX was designed to increase cognitive skills (ie, knowledge about asthma) and behavioral skills (ie, inhalation technique) in 10-15-year-olds with asthma, and enables support by a health professional and a family member. To this end, three design goals guided the development: (1) to build a conversational agent-patient working alliance; (2) to offer hybrid (human- and conversational agent-supported) ubiquitous coaching; and (3) to provide an intervention with high experiential value. An interdisciplinary team of computer scientists, asthma experts, and young patients with their parents developed the intervention collaboratively. The conversational agent communicates with health care professionals via email, with patients via a mobile chat app, and with a family member via SMS text messaging. A single-arm feasibility study in primary and secondary care settings was performed to assess MAX. Results: Results indicated an overall positive evaluation of MAX with respect to its reach (49.5%, 49/99 of recruited and eligible patient-family member teams participated), a strong patient-conversational agent working alliance, and high acceptance by all relevant stakeholders. Moreover, MAX led to improved cognitive and behavioral skills and an intervention completion rate of 75.5%. Family members supported the patients in 269 out of 275 (97.8%) coaching sessions. Most of the conversational turns (99.5%) were conducted between patients and the conversational agent as opposed to between patients and health care professionals, thus indicating the scalability of MAX. In addition, it took health care professionals less than 4 minutes to assess the inhalation technique and 3 days to deliver related feedback to the patients. Several suggestions for improvement were made. Conclusions: This study provides the first evidence that conversational agents, designed as mediating social actors involving health care professionals, patients, and family members, are not only accepted in such a “team player” role but also show potential to improve health-relevant outcomes in chronic disease management. © 2021 Elsevier B.V., All rights reserved."
312,0,0.40378620784507324,"There are many young people who experience mental health and wellbeing challenges. A potential negative mental health trigger for some youth is a struggle to cope with stress at school, feelings of depression and anxiety and availability of adequate help for these stressors. In response to youth needs a mental health and wellbeing Chatbot has been co-developed with youth, technology partners and expert stakeholders. An element of the Chatbot is powered by artificial intelligence and rules based AI using natural language processing. It is created to communicate evidence based resources, wellbeing support, educational mental health information and adaptive coping strategies. This paper will discuss how the Chatbot has been developed, highlighting its participatory, co-design process with youth who are the key stakeholders to benefit from this digital tool. Research from interviews and surveys informed the creation of the Chabots personality and its character design. Examples of the conversation design and content development are provided. The paper finishes with how, if at all, digital tools such as Chatbot applications could support the mental health of young people in secondary schools or health care settings in conjunction with the wellbeing or health care team, concluding with lessons learned and cautions. © 2021 Elsevier B.V., All rights reserved."
313,3,1.0,"Background: Breast cancer is the most common form of cancer in Japan; genetic background and hereditary breast and ovarian cancer (HBOC) are implicated. The key to HBOC diagnosis involves screening to identify high-risk individuals. However, genetic medicine is still developing; thus, many patients who may potentially benefit from genetic medicine have not yet been identified. Objective: This study’s objective is to develop a chatbot system that uses augmented intelligence for HBOC screening to determine whether patients meet the National Comprehensive Cancer Network (NCCN) BRCA1/2 testing criteria. Methods: The system was evaluated by a doctor specializing in genetic medicine and certified genetic counselors. We prepared 3 scenarios and created a conversation with the chatbot to reflect each one. Then we evaluated chatbot feasibility, the required time, the medical accuracy of conversations and family history, and the final result. Results: The times required for the conversation were 7 minutes for scenario 1, 15 minutes for scenario 2, and 16 minutes for scenario 3. Scenarios 1 and 2 met the BRCA1/2 testing criteria, but scenario 3 did not, and this result was consistent with the findings of 3 experts who retrospectively reviewed conversations with the chatbot according to the 3 scenarios. A family history comparison ascertained by the chatbot with the actual scenarios revealed that each result was consistent with each scenario. From a genetic medicine perspective, no errors were noted by the 3 experts. Conclusions: This study demonstrated that chatbot systems could be applied to preliminary genetic medicine screening for HBOC. © 2021 Elsevier B.V., All rights reserved."
314,2,0.39612333942110484,"The coronavirus disease 2019 (COVID-19) epidemic poses a threat to the everyday life of people worldwide and brings challenges to the global health system. During this outbreak, it is critical to find creative ways to extend the reach of informatics into every person in society. Although there are many websites and mobile applications for this purpose, they are insufficient in reaching vulnerable populations like older adults who are not familiar with using new technologies to access information. In this paper, the authors propose an AI-enabled chatbot assistant that delivers real-time, useful, context-aware, and personalized information about COVID-19 to users, especially older adults. To use the assistant, a user simply speaks to it through a mobile phone or a smart speaker. This natural and interactive interface does not require the user to have any technical background. The virtual assistant was evaluated in the lab environment through various types of use cases. Preliminary qualitative test results demonstrate a reasonable precision and recall rate. © 2023 Elsevier B.V., All rights reserved."
315,-1,0.2698359276107708,"Introduction: With the COVID-19 pandemic, Singapore underwent a national lockdown in which most organisations, including schools were closed. Halting face-to-face tutorials resulting in decreased clinical contact for medical students. Prior to the pandemic, we had developed the Virtual Integrated Patient (VIP). Equipped with conversational technology, it provides students online practice in various clinical skills such as history-taking, physical examination and investigations. The aim of this paper is to describe the supplementary use of VIP in the second-year class, in which a pilot study was conducted. Methods: The VIP platform was introduced to the cohort and used to supplement the teaching of history-taking in the “Communication with Patients” (CWP) module for second-year students. Traditionally, CWP tutorials involve face-to-face history-taking from standardised patients (SPs). Students, who consented to participating in the trial, had an additional 3 weeks’ access to VIP to practice their history-taking skills. They completed a survey on their user experience and satisfaction at the end of the 3 weeks. Results: Out of the 106 participants, 87% strongly agreed or agreed that using VIP helped in remembering the content while 69% of them felt that VIP increased their confidence and competence in history-taking. Conclusion: VIP was well-received by students and showed promise as a tool to supplement history-taking tutorials, prior to students’ encounter with SPs and real patients. Hence, this trend showed its potential as an alternative when clinical rotations were delayed or cancelled. Further research can be done to evaluate its effectiveness in this context. © 2022 Elsevier B.V., All rights reserved."
316,0,1.0,"This work aimed to study the effect of confinement on weight and lifestyle using the Wakamola chatbot to collect data from 739 adults divided into two groups (341 case-control, 398 confinement). Nutrition score (0–100 scale) improved for men (medians 81.77–82.29, p < 0.05), with no difference for women (medians 82.29 in both cases). Both genders reduced the consumption of sweetmeats and sugared drinks (p < 0.01); men increased their consumption of vegetables, salad, and legumes (p < 0.01). Both genders reduced their physical activity score (men 100–40.14, p < 0.01, women 80.42–36.12, p < 0.01). Women sat less hours/week, men’s medians 28.81–28.27, women’s medians 35.97–23.33, p = 0.03. Both genders slept longer (hours/day), men 7–7.5, women 7–8 (p < 0.01) (medians). Their overall health score was significantly reduced (men 85.06–74.05, p < 0.01, women 84.47–72.42, p < 0.01), with no significant weight difference in either gender. Wakamola helped to contact participants and confirm changes in their lifestyle during confinement. © 2021 Elsevier B.V., All rights reserved."
317,3,1.0,"Background: Chatbots are artificial intelligence–driven programs that interact with people. The applications of this technology include the collection and delivery of information, generation of and responding to inquiries, collection of end user feedback, and the delivery of personalized health and medical information to patients through cellphone- and web-based platforms. However, no chatbots have been developed for patients with lung cancer and their caregivers. Objective: This study aimed to develop and evaluate the early feasibility of a chatbot designed to improve the knowledge of symptom management among patients with lung cancer in Japan and their caregivers. Methods: We conducted a sequential mixed methods study that included a web-based anonymized questionnaire survey administered to physicians and paramedics from June to July 2019 (phase 1). Two physicians conducted a content analysis of the questionnaire to curate frequently asked questions (FAQs; phase 2). Based on these FAQs, we developed and integrated a chatbot into a social network service (phase 3). The physicians and paramedics involved in phase I then tested this chatbot (α test; phase 4). Thereafter, patients with lung cancer and their caregivers tested this chatbot (β test; phase 5). Results: We obtained 246 questions from 15 health care providers in phase 1. We curated 91 FAQs and their corresponding responses in phase 2. In total, 11 patients and 1 caregiver participated in the β test in phase 5. The participants were asked 60 questions, 8 (13%) of which did not match the appropriate categories. After the β test, 7 (64%) participants responded to the postexperimental questionnaire. The mean satisfaction score was 2.7 (SD 0.5) points out of 5. Conclusions: Medical staff providing care to patients with lung cancer can use the categories specified in this chatbot to educate patients on how they can manage their symptoms. Further studies are required to improve chatbots in terms of interaction with patients. © 2021 Elsevier B.V., All rights reserved."
318,3,1.0,"Background: Artificial intelligence (AI)-driven chatbots are increasingly being used in health care, but most chatbots are designed for a specific population and evaluated in controlled settings. There is little research documenting how health consumers (eg, patients and caregivers) use chatbots for self-diagnosis purposes in real-world scenarios. Objective: The aim of this research was to understand how health chatbots are used in a real-world context, what issues and barriers exist in their usage, and how the user experience of this novel technology can be improved. Methods: We employed a data-driven approach to analyze the system log of a widely deployed self-diagnosis chatbot in China. Our data set consisted of 47,684 consultation sessions initiated by 16,519 users over 6 months. The log data included a variety of information, including users' nonidentifiable demographic information, consultation details, diagnostic reports, and user feedback. We conducted both statistical analysis and content analysis on this heterogeneous data set. Results: The chatbot users spanned all age groups, including middle-aged and older adults. Users consulted the chatbot on a wide range of medical conditions, including those that often entail considerable privacy and social stigma issues. Furthermore, we distilled 2 prominent issues in the use of the chatbot: (1) a considerable number of users dropped out in the middle of their consultation sessions, and (2) some users pretended to have health concerns and used the chatbot for nontherapeutic purposes. Finally, we identified a set of user concerns regarding the use of the chatbot, including insufficient actionable information and perceived inaccurate diagnostic suggestions. Conclusions: Although health chatbots are considered to be convenient tools for enhancing patient-centered care, there are issues and barriers impeding the optimal use of this novel technology. Designers and developers should employ user-centered approaches to address the issues and user concerns to achieve the best uptake and utilization. We conclude the paper by discussing several design implications, including making the chatbots more informative, easy-to-use, and trustworthy, as well as improving the onboarding experience to enhance user engagement. © 2021 Elsevier B.V., All rights reserved."
319,5,1.0,"Background: The clinical application of voice technology provides novel opportunities in the field of telehealth. However, patients’ readiness for this solution has not been investigated among patients with cardiovascular diseases (CVD). Objective: This paper aims to evaluate patients’ anticipated experiences regarding telemedicine, including voice conversational agents combined with provider-driven support delivered by phone. Methods: A cross-sectional study enrolled patients with chronic CVD who were surveyed using a validated investigator-designed questionnaire combining 19 questions (eg, demographic data, medical history, preferences for using telehealth services). Prior to the survey, respondents were educated on the telemedicine services presented in the questionnaire while being assisted by a medical doctor. Responses were then collected and analyzed, and multivariate logistic regression was used to identify predictors of willingness to use voice technology. Results: In total, 249 patients (mean age 65.3, SD 13.8 years; 158 [63.5%] men) completed the questionnaire, which showed good repeatability in the validation procedure. Of the 249 total participants, 209 (83.9%) reported high readiness to receive services allowing for remote contact with a cardiologist (176/249, 70.7%) and telemonitoring of vital signs (168/249, 67.5%). The voice conversational agents combined with provider-driven support delivered by phone were shown to be highly anticipated by patients with CVD. The readiness to use telehealth was statistically higher in people with previous difficulties accessing health care (OR 2.920, 95% CI 1.377-6.192) and was most frequent in city residents and individuals reporting a higher education level. The age and sex of the respondents did not impact the intention to use voice technology (P=.20 and P=.50, respectively). Conclusions: Patients with cardiovascular diseases, including both younger and older individuals, declared high readiness for voice technology. © 2020 Elsevier B.V., All rights reserved."
320,-1,0.2697528795776647,"Background: Respondent engagement of questionnaires in health care is fundamental to ensure adequate response rates for the evaluation of services and quality of care. Conventional survey designs are often perceived as dull and unengaging, resulting in negative respondent behavior. It is necessary to make completing a questionnaire attractive and motivating. Objective: The aim of this study is to compare the user experience of a chatbot questionnaire, which mimics intelligent conversation, with a regular computer questionnaire. Methods: The research took place at the preoperative outpatient clinic. Patients completed both the standard computer questionnaire and the new chatbot questionnaire. Afterward, patients gave their feedback on both questionnaires by the User Experience Questionnaire, which consists of 26 terms to score. Results: The mean age of the 40 included patients (25 [63%] women) was 49 (SD 18-79) years; 46.73% (486/1040) of all terms were scored positive for the chatbot. Patients preferred the computer for 7.98% (83/1040) of the terms and for 47.88% (498/1040) of the terms there were no differences. Completion (mean time) of the computer questionnaire took 9.00 minutes by men (SD 2.72) and 7.72 minutes by women (SD 2.60; P=.148). For the chatbot, completion by men took 8.33 minutes (SD 2.99) and by women 7.36 minutes (SD 2.61; P=.287). Conclusions: Patients preferred the chatbot questionnaire over the computer questionnaire. Time to completion of both questionnaires did not differ, though the chatbot questionnaire on a tablet felt more rapid compared to the computer questionnaire. This is an important finding because it could lead to higher response rates and to qualitatively better responses in future questionnaires. © 2020 Elsevier B.V., All rights reserved."
321,0,1.0,"Artificial intelligence virtual health assistants are a promising emerging technology. This study is a process evaluation of a 12-week pilot physical activity and diet program delivered by virtual assistant “Paola”. This single-arm repeated measures study (n = 28, aged 45–75 years) was evaluated on technical performance (accuracy of conversational exchanges), engagement (number of weekly check-ins completed), adherence (percentage of step goal and recommended food servings), and user feedback. Paola correctly asked scripted questions and responded to participants during the check-ins 97% and 96% of the time, respectively, but correctly responded to spontaneous exchanges only 21% of the time. Participants completed 63% of weekly check-ins and conducted a total of 3648 exchanges. Mean dietary adherence was 91% and was lowest for discretionary foods, grains, red meat, and vegetables. Participants met their step goal 59% of the time. Participants enjoyed the program and found Paola useful during check-ins but not for spontaneous exchanges. More in-depth knowledge, personalized advice and spontaneity were identified as important improvements. Virtual health assistants should ensure an adequate knowledge base and ability to recognize intents and entities, include personality and spontaneity, and provide ongoing technical troubleshooting of the virtual assistant to ensure the assistant remains effective. © 2020 Elsevier B.V., All rights reserved."
322,2,0.6189574279996072,"The COVID-19 pandemic has created unique challenges for the U.S. healthcare system due to the staggering mismatch between healthcare system capacity and patient demand. The healthcare industry has been a relatively slow adopter of digital innovation due to the conventional belief that humans need to be at the center of healthcare delivery tasks. However, in the setting of the COVID-19 pandemic, artificial intelligence (AI) may be used to carry out specific tasks such as pre-hospital triage and enable clinicians to deliver care at scale. Recognizing that the majority of COVID-19 cases are mild and do not require hospitalization, Partners HealthCare (now Mass General Brigham) implemented a digitally-automated pre-hospital triage solution to direct patients to the appropriate care setting before they showed up at the emergency department and clinics, which would otherwise consume resources, expose other patients and staff to potential viral transmission, and further exacerbate supply-and-demand mismatching. Although the use of AI has been well-established in other industries to optimize supply and demand matching, the introduction of AI to perform tasks remotely that were traditionally performed in-person by clinical staff represents a significant milestone in healthcare operations strategy. © 2020 Elsevier B.V., All rights reserved."
323,-1,0.1377497414750486,"Research question: What are the effects of using a fertility education chatbot, i.e. automatic conversation programme, on knowledge, intentions to improve preconception behaviour and anxiety? Design: A three-armed, randomized controlled trial was conducted using an online social research panel. Participants included 927 women aged 20–34 years who were randomly allocated to one of three groups: a fertility education chatbot (intervention group), a document about fertility and preconception health (control group 1) or a document about an irrelevant topic (control group 2). Participants’ scores on the Cardiff Fertility Knowledge Scale and the State-Trait Anxiety Inventory, their intentions to optimize preconception behaviours, e.g. taking folic acid, and the free-text feedback provided by chatbot users were assessed. Results: A repeated-measures analysis of variance showed significant fertility knowledge gains after the intervention in the intervention group (+9.1 points) and control group 1 (+14.9 points) but no significant change in control group 2 (+1.1 points). Post-test increases in the intentions to optimize behaviours were significantly higher in the intervention group than in control group 2, and were similar to those in control group 1. Post-test state anxiety scores were significantly lower in the intervention group than in control group 1 and control group 2. User feedbacks about the chatbot suggested technical limitations, e.g. low comprehension of users’ words, and pros and cons of using the chatbot, e.g. convenient versus coldness. Conclusions: Providing fertility education using a chatbot improved fertility knowledge and intentions to optimize preconception behaviour without increasing anxiety, but the improvement in knowledge was small. Further technical development and exploration of personal affinity for technology is required. © 2021 Elsevier B.V., All rights reserved."
324,0,1.0,"Background: Mental health difficulties are highly prevalent, yet access to support is limited by barriers of stigma, cost, and availability. These issues are even more prevalent in low- and middle-income countries, and digital technology is one potential way to overcome these barriers. Digital mental health interventions are effective but often struggle with low engagement rates, particularly in the absence of human support. Chatbots could offer a scalable solution, simulating human support at a lower cost. Objective: To complete a preliminary evaluation of engagement and effectiveness of Vitalk, a mental health chatbot, at reducing anxiety, depression and stress. Methods: Real world data was analyzed from 3,629 Vitalk users who had completed the first phase of a Vitalk program (“less anxiety,” “less stress” or “better mood”). Programs were delivered through written conversation with a chatbot. Engagement was calculated from the number of responses sent to the chatbot divided by days in the program. Results: Users sent an average of 8.17 responses per day. For all three programs, target outcome scores reduced between baseline and follow up with large effect sizes for anxiety (Cohen's d = −0.85), depression (Cohen's d = −0.91) and stress (Cohen's d = −0.81). Increased engagement resulted in improved post-intervention values for anxiety and depression. Conclusion: This study highlights a chatbot's potential to reduce mental health symptoms in the general population within Brazil. While findings show promise, further research is required. © 2022 Elsevier B.V., All rights reserved."
325,2,0.2591193788182365,"Background: Pressure on the US health care system has been increasing due to a combination of aging populations, rising health care expenditures, and most recently, the COVID-19 pandemic. Responses to this pressure are hindered in part by reliance on a limited supply of highly trained health care professionals, creating a need for scalable technological solutions. Digital symptom checkers are artificial intelligence-supported software tools that use a conversational “chatbot” format to support rapid diagnosis and consistent triage. The COVID-19 pandemic has brought new attention to these tools due to the need to avoid face-to-face contact and preserve urgent care capacity. However, evidence-based deployment of these chatbots requires an understanding of user demographics and associated triage recommendations generated by a large general population. Objective: In this study, we evaluate the user demographics and levels of triage acuity provided by a symptom checker chatbot deployed in partnership with a large integrated health system in the United States. Methods: This population-based descriptive study included all web-based symptom assessments completed on the website and patient portal of the Sutter Health system (24 hospitals in Northern California) from April 24, 2019, to February 1, 2020. User demographics were compared to relevant US Census population data. Results: A total of 26,646 symptom assessments were completed during the study period. Most assessments (17,816/26,646, 66.9%) were completed by female users. The mean user age was 34.3 years (SD 14.4 years), compared to a median age of 37.3 years of the general population. The most common initial symptom was abdominal pain (2060/26,646, 7.7%). A substantial number of assessments (12,357/26,646, 46.4%) were completed outside of typical physician office hours. Most users were advised to seek medical care on the same day (7299/26,646, 27.4%) or within 2-3 days (6301/26,646, 23.6%). Over a quarter of the assessments indicated a high degree of urgency (7723/26,646, 29.0%). Conclusions: Users of the symptom checker chatbot were broadly representative of our patient population, although they skewed toward younger and female users. The triage recommendations were comparable to those of nurse-staffed telephone triage lines. Although the emergence of COVID-19 has increased the interest in remote medical assessment tools, it is important to take an evidence-based approach to their deployment. © 2020 Elsevier B.V., All rights reserved."
326,0,0.5622427659121337,"Background: Chatbots could be a scalable solution that provides an interactive means of engaging users in behavioral health interventions driven by artificial intelligence. Although some chatbots have shown promising early efficacy results, there is limited information about how people use these chatbots. Understanding the usage patterns of chatbots for depression represents a crucial step toward improving chatbot design and providing information about the strengths and limitations of the chatbots. Objective: This study aims to understand how users engage and are redirected through a chatbot for depression (Tess) to provide design recommendations. Methods: Interactions of 354 users with the Tess depression modules were analyzed to understand chatbot usage across and within modules. Descriptive statistics were used to analyze participant flow through each depression module, including characters per message, completion rate, and time spent per module. Slide plots were also used to analyze the flow across and within modules. Results: Users sent a total of 6220 messages, with a total of 86,298 characters, and, on average, they engaged with Tess depression modules for 46 days. There was large heterogeneity in user engagement across different modules, which appeared to be affected by the length, complexity, content, and style of questions within the modules and the routing between modules. Conclusions: Overall, participants engaged with Tess; however, there was a heterogeneous usage pattern because of varying module designs. Major implications for future chatbot design and evaluation are discussed in the paper. © 2021 Elsevier B.V., All rights reserved."
327,2,1.0,"Objectives: The objective was to understand how people respond to coronavirus disease 2019 (COVID-19) screening chatbots. Materials and Methods: We conducted an online experiment with 371 participants who viewed a COVID-19 screening session between a hotline agent (chatbot or human) and a user with mild or severe symptoms. Results: The primary factor driving user response to screening hotlines (human or chatbot) is perceptions of the agent's ability. When ability is the same, users view chatbots no differently or more positively than human agents. The primary factor driving perceptions of ability is the user's trust in the hotline provider, with a slight negative bias against chatbots' ability. Asian individuals perceived higher ability and benevolence than did White individuals. Conclusions: Ensuring that COVID-19 screening chatbots provide high-quality service is critical but not sufficient for widespread adoption. The key is to emphasize the chatbot's ability and assure users that it delivers the same quality as human agents. © 2021 Elsevier B.V., All rights reserved."
328,-1,0.2023530400409598,"Background: Seeking medical information can be an issue for physicians. In the specific context of medical practice, chatbots are hypothesized to present additional value for providing information quickly, particularly as far as drug risk minimization measures are concerned. Objective: This qualitative study aimed to elicit physicians’ perceptions of a pilot version of a chatbot used in the context of drug information and risk minimization measures. Methods: General practitioners and specialists were recruited across France to participate in individual semistructured interviews. Interviews were recorded, transcribed, and analyzed using a horizontal thematic analysis approach. Results: Eight general practitioners and 2 specialists participated. The tone and ergonomics of the pilot version were appreciated by physicians. However, all participants emphasized the importance of getting exhaustive, trustworthy answers when interacting with a chatbot. Conclusions: The chatbot was perceived as a useful and innovative tool that could easily be integrated into routine medical practice and could help health professionals when seeking information on drug and risk minimization measures. © 2021 Elsevier B.V., All rights reserved."
329,-1,0.126973931226192,"Background: Chronic obstructive pulmonary disease (COPD) is one of the most common disorders in the world. COPD is characterized by airflow obstruction, which is not fully reversible. Patients usually experience breathing-related symptoms with periods of acute worsening and a substantial decrease in the health-related quality-of-life. Active and comprehensive disease management can slow down the progressive course of the disease and improve patients’ disabilities. Technological progress and digitalization of medicine have the potential to make elaborate interventions easily accessible and applicable to a broad spectrum of patients with COPD without increasing the costs of the intervention. Objective: This study aims to develop a comprehensive telemonitoring and hybrid virtual coaching solution and to investigate its effects on the health-related quality of life of patients with COPD. Methods: A monocentric, assessor-blind, two-arm (intervention/control) randomized controlled trial will be performed. Participants randomized to the control group will receive usual care and a CAir Desk (custom-built home disease-monitoring device to telemonitor disease-relevant parameters) for 12 weeks, without feedback or scores of the telemonitoring efforts and virtual coaching. Participants randomized to the intervention group will receive a CAir Desk and a hybrid digital coaching intervention for 12 weeks. As a primary outcome, we will measure the delta in the health-related quality of life, which we will assess with the St. George Respiratory Questionnaire, from baseline to week 12 (the end of the intervention). Results: The development of the CAir Desk and virtual coach has been completed. Recruitment to the trial started in September 2020. We expect to start data collection by December 2020 and expect it to last for approximately 18 months, as we follow a multiwave approach. We expect to complete data collection by mid-2022 and plan the dissemination of the results subsequently. Conclusions: To our knowledge, this is the first study investigating a combination of telemonitoring and hybrid virtual coaching in patients with COPD. We will investigate the effectiveness, efficacy, and usability of the proposed intervention and provide evidence to further develop app-based and chatbot-based disease monitoring and interventions in COPD. © 2020 Elsevier B.V., All rights reserved."
330,2,1.0,"Background: A large number of web-based COVID-19 symptom checkers and chatbots have been developed; however, anecdotal evidence suggests that their conclusions are highly variable. To our knowledge, no study has evaluated the accuracy of COVID-19 symptom checkers in a statistically rigorous manner. Objective: The aim of this study is to evaluate and compare the diagnostic accuracies of web-based COVID-19 symptom checkers. Methods: We identified 10 web-based COVID-19 symptom checkers, all of which were included in the study. We evaluated the COVID-19 symptom checkers by assessing 50 COVID-19 case reports alongside 410 non-COVID-19 control cases. A bootstrapping method was used to counter the unbalanced sample sizes and obtain confidence intervals (CIs). Results are reported as sensitivity, specificity, F1 score, and Matthews correlation coefficient (MCC). Results: The classification task between COVID-19-positive and COVID-19-negative for ""high risk"" cases among the 460 test cases yielded (sorted by F1 score): Symptoma (F1=0.92, MCC=0.85), Infermedica (F1=0.80, MCC=0.61), US Centers for Disease Control and Prevention (CDC) (F1=0.71, MCC=0.30), Babylon (F1=0.70, MCC=0.29), Cleveland Clinic (F1=0.40, MCC=0.07), Providence (F1=0.40, MCC=0.05), Apple (F1=0.29, MCC=-0.10), Docyet (F1=0.27, MCC=0.29), Ada (F1=0.24, MCC=0.27) and Your.MD (F1=0.24, MCC=0.27). For ""high risk"" and ""medium risk"" combined the performance was: Symptoma (F1=0.91, MCC=0.83) Infermedica (F1=0.80, MCC=0.61), Cleveland Clinic (F1=0.76, MCC=0.47), Providence (F1=0.75, MCC=0.45), Your.MD (F1=0.72, MCC=0.33), CDC (F1=0.71, MCC=0.30), Babylon (F1=0.70, MCC=0.29), Apple (F1=0.70, MCC=0.25), Ada (F1=0.42, MCC=0.03), and Docyet (F1=0.27, MCC=0.29). Conclusions: We found that the number of correctly assessed COVID-19 and control cases varies considerably between symptom checkers, with different symptom checkers showing different strengths with respect to sensitivity and specificity. A good balance between sensitivity and specificity was only achieved by two symptom checkers. © 2020 Elsevier B.V., All rights reserved."
331,3,1.0,"New concepts of medical consultations are currently disrupting the practice of medicine. The use of standardized questionnaires, or patient-reported outcome (PRO and ePRO) has already significantly changed the relationship between the physician and the patient. Telemedicine, or even automatic conversational agents, such as chatbots, are also providing more convenient access to care and medical information for many patients. These tools have a major impact in oncology, precisely because of the rising chronicity of the diseases the radiation oncologists treat. In this article, we provide a detailed analysis of these new concepts. © 2020 Elsevier B.V., All rights reserved."
332,2,1.0,"The screening of healthcare workers for COVID-19 (coronavirus disease 2019) symptoms and exposures prior to every clinical shift is important for preventing nosocomial spread of infection but creates a major logistical challenge. To make the screening process simple and efficient, University of California, San Francisco Health designed and implemented a digital chatbot-based workflow. Within 1 week of forming a team, we conducted a product development sprint and deployed the digital screening process. In the first 2 months of use, over 270 000 digital screens have been conducted. This process has reduced wait times for employees entering our hospitals during shift changes, allowed for physical distancing at hospital entrances, prevented higher-risk individuals from coming to work, and provided our healthcare leaders with robust, real-time data for make staffing decisions. © 2021 Elsevier B.V., All rights reserved."
333,0,0.49775942695315806,"Background: Acceptance and commitment therapy (ACT) is a pragmatic approach to help individuals decrease avoidable pain. Objective: This study aims to evaluate the effects of ACT delivered via an automated mobile messaging robot on postoperative opioid use and patient-reported outcomes (PROs) in patients with orthopedic trauma who underwent operative intervention for their injuries. Methods: Adult patients presenting to a level 1 trauma center who underwent operative fixation of a traumatic upper or lower extremity fracture and who used mobile phone text messaging were eligible for the study. Patients were randomized in a 1:1 ratio to either the intervention group, who received twice-daily mobile phone messages communicating an ACT-based intervention for the first 2 weeks after surgery, or the control group, who received no messages. Baseline PROs were completed. Two weeks after the operative intervention, follow-up was performed in the form of an opioid medication pill count and postoperative administration of PROs. The mean number of opioid tablets used by patients was calculated and compared between groups. The mean PRO scores were also compared between the groups. Results: A total of 82 subjects were enrolled in the study. Of the 82 participants, 76 (38 ACT and 38 controls) completed the study. No differences between groups in demographic factors were identified. The intervention group used an average of 26.1 (SD 21.4) opioid tablets, whereas the control group used 41.1 (SD 22.0) tablets, resulting in 36.5% ([41.1-26.1]/41.1) less tablets used by subjects receiving the mobile phone-based ACT intervention (P=.004). The intervention group subjects reported a lower postoperative Patient-Reported Outcome Measure Information System Pain Intensity score (mean 45.9, SD 7.2) than control group subjects (mean 49.7, SD 8.8; P=.04). Conclusions: In this study, the delivery of an ACT-based intervention via an automated mobile messaging robot in the acute postoperative period decreased opioid use in selected patients with orthopedic trauma. Participants receiving the ACT-based intervention also reported lower pain intensity after 2 weeks, although this may not represent a clinically important difference. © 2020 Elsevier B.V., All rights reserved."
334,0,1.0,"Background: Poor diet and physical inactivity are leading modifiable causes of death and disease. Advances in artificial intelligence technology present tantalizing opportunities for creating virtual health coaches capable of providing personalized support at scale. Objective: This proof of concept study aimed to test the feasibility (recruitment and retention) and preliminary efficacy of physical activity and Mediterranean-style dietary intervention (MedLiPal) delivered via artificially intelligent virtual health coach. Methods: This 12-week single-arm pre-post study took place in Adelaide, Australia, from March to August 2019. Participants were inactive community-dwelling adults aged 45 to 75 years, recruited through news stories, social media posts, and flyers. The program included access to an artificially intelligent chatbot, Paola, who guided participants through a computer-based individualized introductory session, weekly check-ins, and goal setting, and was available 24/7 to answer questions. Participants used a Garmin Vivofit4 tracker to monitor daily steps, a website with educational materials and recipes, and a printed diet and activity log sheet. Primary outcomes included feasibility (based on recruitment and retention) and preliminary efficacy for changing physical activity and diet. Secondary outcomes were body composition (based on height, weight, and waist circumference) and blood pressure. Results: Over 4 weeks, 99 potential participants registered expressions of interest, with 81 of those screened meeting eligibility criteria. Participants completed a mean of 109.8 (95% CI 1.9-217.7) more minutes of physical activity at week 12 compared with baseline. Mediterranean diet scores increased from a mean of 3.8 out of 14 at baseline, to 9.6 at 12 weeks (mean improvement 5.7 points, 95% CI 4.2-7.3). After 12 weeks, participants lost an average 1.3 kg (95% CI –0.1 to –2.5 kg) and 2.1 cm from their waist circumference (95% CI –3.5 to –0.7 cm). There were no significant changes in blood pressure. Feasibility was excellent in terms of recruitment, retention (90% at 12 weeks), and safety (no adverse events). Conclusions: An artificially intelligent virtual assistant-led lifestyle-modification intervention was feasible and achieved measurable improvements in physical activity, diet, and body composition at 12 weeks. Future research examining artificially intelligent interventions at scale, and for other health purposes, is warranted. © 2020 Elsevier B.V., All rights reserved."
335,2,0.5106993049688907,"Background: The response to COVID-19 catalyzed the adoption and integration of digital health tools into the health care delivery model for musculoskeletal patients. The change, suspension, or relaxation of Medicare and federal guidelines enabled the rapid implementation of these technologies. The expansion of payment models for virtual care facilitated its rapid adoption. The authors aim to provide several examples of digital health solutions utilized to manage orthopedic patients during the pandemic and discuss what features of these technologies are likely to continue to provide value to patients and clinicians following its resolution. Conclusion: The widespread adoption of new technologies enabling providers to care for patients remotely has the potential to permanently change the expectations of all stakeholders about the way care is provided in orthopedics. The new era of Digital Orthopaedics will see a gradual and nondisruptive integration of technologies that support the patient's journey through the successful management of their musculoskeletal disease. © 2020 Elsevier B.V., All rights reserved."
336,0,1.0,"Background: Over the past several years, the emergence of mobile mental health apps has increased as a potential solution for populations who may face logistical and social barriers to traditional service delivery, including individuals connected to the military. Objective: The goal of the #Here4U App – Military Version is to provide evidence-informed mental health support to members of Canada’s military community, leveraging artificial intelligence in the form of IBM Canada’s Watson Assistant to carry on unique text-based conversations with users, identify presenting mental health concerns, and refer users to self-help resources or recommend professional health care where appropriate. Methods: As the availability and use of mental health apps has increased, so too has the list of recommendations and guidelines for efficacious development. We describe the development and testing conducted between 2018 and 2020 and assess the quality of the #Here4U App against 16 criteria for rigorous mental health app development, as identified by Bakker and colleagues in 2016. Results: The #Here4U App – Military Version met the majority of Bakker and colleagues’ criteria, with those unmet considered not applicable to this particular product or out of scope for research conducted to date. Notably, a formal evaluation of the efficacy of the app is a major priority moving forward. Conclusions: The #Here4U App – Military Version is a promising new mental health e-solution for members of the Canadian Armed Forces community, filling many of the gaps left by traditional service delivery. © 2021 Elsevier B.V., All rights reserved."
337,0,1.0,"Background: Ongoing pain is one of the most common diseases and has major physical, psychological, social, and economic impacts. A mobile health intervention utilizing a fully automated text-based health care chatbot (TBHC) may offer an innovative way not only to deliver coping strategies and psychoeducation for pain management but also to build a working alliance between a participant and the TBHC. Objective: The objectives of this study are twofold: (1) to describe the design and implementation to promote the chatbot painSELfMAnagement (SELMA), a 2-month smartphone-based cognitive behavior therapy (CBT) TBHC intervention for pain self-management in patients with ongoing or cyclic pain, and (2) to present findings from a pilot randomized controlled trial, in which effectiveness, influence of intention to change behavior, pain duration, working alliance, acceptance, and adherence were evaluated. Methods: Participants were recruited online and in collaboration with pain experts, and were randomized to interact with SELMA for 8 weeks either every day or every other day concerning CBT-based pain management (n=59), or weekly concerning content not related to pain management (n=43). Pain-related impairment (primary outcome), general well-being, pain intensity, and the bond scale of working alliance were measured at baseline and postintervention. Intention to change behavior and pain duration were measured at baseline only, and acceptance postintervention was assessed via self-reporting instruments. Adherence was assessed via usage data. Results: From May 2018 to August 2018, 311 adults downloaded the SELMA app, 102 of whom consented to participate and met the inclusion criteria. The average age of the women (88/102, 86.4%) and men (14/102, 13.6%) participating was 43.7 (SD 12.7) years. Baseline group comparison did not differ with respect to any demographic or clinical variable. The intervention group reported no significant change in pain-related impairment (P=.68) compared to the control group postintervention. The intention to change behavior was positively related to pain-related impairment (P=.01) and pain intensity (P=.01). Working alliance with the TBHC SELMA was comparable to that obtained in guided internet therapies with human coaches. Participants enjoyed using the app, perceiving it as useful and easy to use. Participants of the intervention group replied with an average answer ratio of 0.71 (SD 0.20) to 200 (SD 58.45) conversations initiated by SELMA. Participants’ comments revealed an appreciation of the empathic and responsible interaction with the TBHC SELMA. A main criticism was that there was no option to enter free text for the patients’ own comments. Conclusions: SELMA is feasible, as revealed mainly by positive feedback and valuable suggestions for future revisions. For example, the participants’ intention to change behavior or a more homogenous sample (eg, with a specific type of chronic pain) should be considered in further tailoring of SELMA. © 2020 Elsevier B.V., All rights reserved."
338,-1,0.2058636786458355,"Background: Conversational agents (also known as chatbots) have evolved in recent decades to become multimodal, multifunctional platforms with potential to automate a diverse range of health-related activities supporting the general public, patients, and physicians. Multiple studies have reported the development of these agents, and recent systematic reviews have described the scope of use of conversational agents in health care. However, there is scarce research on the effectiveness of these systems; thus, their viability and applicability are unclear. Objective: The objective of this systematic review is to assess the effectiveness of conversational agents in health care and to identify limitations, adverse events, and areas for future investigation of these agents. Methods: The Preferred Reporting Items for Systematic Reviews and Meta-Analyses Protocols will be used to structure this protocol. The focus of the systematic review is guided by a population, intervention, comparator, and outcome framework. A systematic search of the PubMed (Medline), EMBASE, CINAHL, and Web of Science databases will be conducted. Two authors will independently screen the titles and abstracts of the identified references and select studies according to the eligibility criteria. Any discrepancies will then be discussed and resolved. Two reviewers will independently extract and validate data from the included studies into a standardized form and conduct quality appraisal. Results: As of January 2020, we have begun a preliminary literature search and piloting of the study selection process. Conclusions: This systematic review aims to clarify the effectiveness, limitations, and future applications of conversational agents in health care. Our findings may be useful to inform the future development of conversational agents and promote the personalization of patient care. © 2020 Elsevier B.V., All rights reserved."
339,0,0.2641223868424476,"Background: Previous research suggests that artificial agents may be a promising source of social support for humans. However, the bulk of this research has been conducted in the context of social support interventions that specifically address stressful situations or health improvements. Little research has examined social support received from artificial agents in everyday contexts. Objective: Considering that social support manifests in not only crises but also everyday situations and that everyday social support forms the basis of support received during more stressful events, we aimed to investigate the types of everyday social support that can be received from artificial agents. Methods: In Study 1, we examined publicly available user reviews (N=1854) of Replika, a popular companion chatbot. In Study 2, a sample (n=66) of Replika users provided detailed open-ended responses regarding their experiences of using Replika. We conducted thematic analysis on both datasets to gain insight into the kind of everyday social support that users receive through interactions with Replika. Results: Replika provides some level of companionship that can help curtail loneliness, provide a ""safe space"" in which users can discuss any topic without the fear of judgment or retaliation, increase positive affect through uplifting and nurturing messages, and provide helpful information/advice when normal sources of informational support are not available. Conclusions: Artificial agents may be a promising source of everyday social support, particularly companionship, emotional, informational, and appraisal support, but not as tangible support. Future studies are needed to determine who might benefit from these types of everyday social support the most and why. These results could potentially be used to help address global health issues or other crises early on in everyday situations before they potentially manifest into larger issues. © 2020 Elsevier B.V., All rights reserved."
340,3,1.0,"Chatbots are able to provide support to patients suffering from very different conditions. Patients with chronic diseases or comorbidities could benefit the most from chatbots which can keep track of their condition, provide specific information, encourage adherence to medication, etc. To perform these functions, chatbots need a suitable underlying software architecture. In this paper, we introduce a chatbot architecture for chronic patient support grounded on three pillars: scalability by means of microservices, standard data sharing models through HL7 FHIR and standard conversation modeling using AIML. We also propose an innovative automation mechanism to convert FHIR resources into AIML files, thus facilitating the interaction and data gathering of medical and personal information that ends up in patient health records. To align the way people interact with each other using messaging platforms with the chatbot architecture, we propose these very same channels for the chatbot-patient interaction, paying special attention to security and privacy issues. Finally, we present a monitored-data study performed in different chronic diseases, and we present a prototype implementation tailored for one specific chronic disease, psoriasis, showing how this new architecture allows the change, the addition or the improvement of different parts of the chatbot in a dynamic and flexible way, providing a substantial improvement in the development of chatbots used as virtual assistants for chronic patients. © 2020 Elsevier B.V., All rights reserved."
341,3,1.0,"Background: The data regarding the use of conversational agents in oncology are scarce. Objective: The aim of this study was to verify whether an artificial conversational agent was able to provide answers to patients with breast cancer with a level of satisfaction similar to the answers given by a group of physicians. Methods: This study is a blind, noninferiority randomized controlled trial that compared the information given by the chatbot, Vik, with that given by a multidisciplinary group of physicians to patients with breast cancer. Patients were women with breast cancer in treatment or in remission. The European Organisation for Research and Treatment of Cancer Quality of Life Group information questionnaire (EORTC QLQ-INFO25) was adapted and used to compare the quality of the information provided to patients by the physician or the chatbot. The primary outcome was to show that the answers given by the Vik chatbot to common questions asked by patients with breast cancer about their therapy management are at least as satisfying as answers given by a multidisciplinary medical committee by comparing the success rate in each group (defined by a score above 3). The secondary objective was to compare the average scores obtained by the chatbot and physicians for each INFO25 item. Results: A total of 142 patients were included and randomized into two groups of 71. They were all female with a mean age of 42 years (SD 19). The success rates (as defined by a score >3) was 69% (49/71) in the chatbot group versus 64% (46/71) in the physicians group. The binomial test showed the noninferiority (P<.001) of the chatbot’s answers. Conclusions: This is the first study that assessed an artificial conversational agent used to inform patients with cancer. The EORTC INFO25 scores from the chatbot were found to be noninferior to the scores of the physicians. Artificial conversational agents may save patients with minor health concerns from a visit to the doctor. This could allow clinicians to spend more time to treat patients who need a consultation the most. © 2020 Elsevier B.V., All rights reserved."
342,3,0.377144098168018,"Conversational artificial intelligence (AI) is changing the way mental health care is delivered. By gathering diagnostic information, facilitating treatment, and reviewing clinician behavior, conversational AI is poised to impact traditional approaches to delivering psychotherapy. While this transition is not disconnected from existing professional services, specific formulations of clinician-AI collaboration and migration paths between forms remain vague. In this viewpoint, we introduce four approaches to AI-human integration in mental health service delivery. To inform future research and policy, these four approaches are addressed through four dimensions of impact: access to care, quality, clinician-patient relationship, and patient self-disclosure and sharing. Although many research questions are yet to be investigated, we view safety, trust, and oversight as crucial first steps. If conversational AI isn’t safe it should not be used, and if it isn’t trusted, it won’t be. In order to assess safety, trust, interfaces, procedures, and system level workflows, oversight and collaboration is needed between AI systems, patients, clinicians, and administrators. © 2019 Elsevier B.V., All rights reserved."
343,5,1.0,"Background: Artificial intelligence (AI) is increasingly being used in healthcare. Here, AI-based chatbot systems can act as automated conversational agents, capable of promoting health, providing education, and potentially prompting behaviour change. Exploring the motivation to use health chatbots is required to predict uptake; however, few studies to date have explored their acceptability. This research aimed to explore participants’ willingness to engage with AI-led health chatbots. Methods: The study incorporated semi-structured interviews (N-29) which informed the development of an online survey (N-216) advertised via social media. Interviews were recorded, transcribed verbatim and analysed thematically. A survey of 24 items explored demographic and attitudinal variables, including acceptability and perceived utility. The quantitative data were analysed using binary regressions with a single categorical predictor. Results: Three broad themes: ‘Understanding of chatbots’, ‘AI hesitancy’ and ‘Motivations for health chatbots’ were identified, outlining concerns about accuracy, cyber-security, and the inability of AI-led services to empathise. The survey showed moderate acceptability (67%), correlated negatively with perceived poorer IT skills OR = 0.32 [CI95%:0.13–0.78] and dislike for talking to computers OR = 0.77 [CI95%:0.60–0.99] as well as positively correlated with perceived utility OR = 5.10 [CI95%:3.08–8.43], positive attitude OR = 2.71 [CI95%:1.77–4.16] and perceived trustworthiness OR = 1.92 [CI95%:1.13–3.25]. Conclusion: Most internet users would be receptive to using health chatbots, although hesitancy regarding this technology is likely to compromise engagement. Intervention designers focusing on AI-led health chatbots need to employ user-centred and theory-based approaches addressing patients’ concerns and optimising user experience in order to achieve the best uptake and utilisation. Patients’ perspectives, motivation and capabilities need to be taken into account when developing and assessing the effectiveness of health chatbots. © 2019 Elsevier B.V., All rights reserved."
344,-1,0.22528885653691122,"Background: The integration of new scientific discoveries into clinical practice costs considerable time and resources. With the increased use of social media for scientific communication, new opportunities arise to “bridge the gap” in translational medicine. The present study aimed to investigate how medical professionals access scientific information and understand their view on the role of social media in translational medicine. Methods: A questionnaire regarding (i) the use of social media for scientific updates, (ii) the opportunities and challenges of social media for translational medicine, (iii) social media function Chatbot, and (iv) participant demographics was developed. The survey link was posted online from February, 2018, until April, 2018. Results: A total of 555 professionals responded to the survey. Respondents identified themselves predominantly as researcher/scientists (27%) or medical/biomedical students (15%). The majority of participants was employed at a university or research institute (59%), and most practiced either in Europe (48%) or in Asia (37%). Seventy-eight percent of respondents reported receiving most of scientific news and updates via non-social media options, such as journal websites and newspapers. Fifty-one percent of respondents believed that social media could contribute to closing the gap between scientific discovery and translation to medical application. The most crucial opportunity created by social media was found to be “connecting the right scientist to the right clinician.” Participants rated “the translation of scientific finding to clinical practice is too fast before the safety is properly demonstrated” as the most crucial challenge. Half of the respondents were aware of their institutions policy on the professional use of social media. Only 2% of respondents had previously used Chatbot. Conclusions: Overall, medical professionals were positive about the idea that social media could contribute to the progress of translational medicine. However, it is clear that they are still being cautious about using social media for professional purposes. To fully harness the potential of social media on translational medicine, the medical community needs to be provided with educational programs, guidelines, and support infrastructure within social media. © 2020 Elsevier B.V., All rights reserved."
345,-1,0.19480125205334675,"Background: Patients experience common symptoms and/or complications after undergoing ureteroscopy, which is a common procedure used to treat kidney stones. Current methods for patient education regarding these complications include counseling and discharge materials. This study aimed to assess chatbot usage and their ability to deliver information to patient post-ureteroscopy. Methods: Patients who underwent ureteroscopy at the University of Michigan were given instructions to activate the chatbot. Within one to four weeks of their surgery, semi-structured interviews were conducted regarding post-surgical recovery and chatbot usage. Results: Twenty patients were interviewed, seven of whom activated the chatbot. Frequent reasons for not activating the chatbot included misplacing instructions for chatbot use (n=6), relying on follow-up with clinic or discharge materials (n=4), inability to activate chatbot (n=2), and inability to text (n=1). Perceived benefits included alleviation of concerns surrounding common symptoms and quick access to information for nonemergent issues. Conclusions: These results suggest that chatbots are a convenient method to address common concerns post-ureteroscopy. However, better integration in the flow of care delivery and improved usability are needed to increase patient engagement. © 2023 Elsevier B.V., All rights reserved."
346,3,1.0,"Background: A chatbot is a software that interacts with users by simulating a human conversation through text or voice via smartphones or computers. It could be a solution to follow up with patients during their disease while saving time for health care providers. Objective: The aim of this study was to evaluate one year of conversations between patients with breast cancer and a chatbot. Methods: Wefight Inc designed a chatbot (Vik) to empower patients with breast cancer and their relatives. Vik responds to the fears and concerns of patients with breast cancer using personalized insights through text messages. We conducted a prospective study by analyzing the users' and patients' data, their usage duration, their interest in the various educational contents proposed, and their level of interactivity. Patients were women with breast cancer or under remission. Results: A total of 4737 patients were included. Results showed that an average of 132,970 messages exchanged per month was observed between patients and the chatbot, Vik. Thus, we calculated the average medication adherence rate over 4 weeks by using a prescription reminder function, and we showed that the more the patients used the chatbot, the more adherent they were. Patients regularly left positive comments and recommended Vik to their friends. The overall satisfaction was 93.95% (900/958). When asked what Vik meant to them and what Vik brought them, 88.00% (943/958) said that Vik provided them with support and helped them track their treatment effectively. Conclusions: We demonstrated that it is possible to obtain support through a chatbot since Vik improved the medication adherence rate of patients with breast cancer. © 2021 Elsevier B.V., All rights reserved."
347,0,0.6239790855243174,"Background: Positive psychology interventions show promise for reducing psychosocial distress associated with health adversity and have the potential to be widely disseminated to young adults through technology. Objective: This pilot randomized controlled trial examined the feasibility of delivering positive psychology skills via the Vivibot chatbot and its effects on key psychosocial well-being outcomes in young adults treated for cancer. Methods: Young adults (age 18-29 years) were recruited within 5 years of completing active cancer treatment by using the Vivibot chatbot on Facebook messenger. Participants were randomized to either immediate access to Vivibot content (experimental group) or access to only daily emotion ratings and access to full chatbot content after 4 weeks (control). Created using a human-centered design process with young adults treated for cancer, Vivibot content includes 4 weeks of positive psychology skills, daily emotion ratings, video, and other material produced by survivors, and periodic feedback check-ins. All participants were assessed for psychosocial well-being via online surveys at baseline and weeks 2, 4, and 8. Analyses examined chatbot engagement and open-ended feedback on likability and perceived helpfulness and compared experimental and control groups with regard to anxiety and depression symptoms and positive and negative emotion changes between baseline and 4 weeks. To verify the main effects, follow-up analyses compared changes in the main outcomes between 4 and 8 weeks in the control group once participants had access to all chatbot content. Results: Data from 45 young adults (36 women; mean age: 25 [SD 2.9]; experimental group: n=25; control group: n=20) were analyzed. Participants in the experimental group spent an average of 74 minutes across an average of 12 active sessions chatting with Vivibot and rated their experience as helpful (mean 2.0/3, SD 0.72) and would recommend it to a friend (mean 6.9/10; SD 2.6). Open-ended feedback noted its nonjudgmental nature as a particular benefit of the chatbot. After 4 weeks, participants in the experimental group reported an average reduction in anxiety of 2.58 standardized t-score units, while the control group reported an increase in anxiety of 0.7 units. A mixed-effects models revealed a trend-level (P=.09) interaction between group and time, with an effect size of 0.41. Those in the experimental group also experienced greater reductions in anxiety when they engaged in more sessions (z=-1.9, P=.06). There were no significant (or trend level) effects by group on changes in depression, positive emotion, or negative emotion. Conclusions: The chatbot format provides a useful and acceptable way of delivering positive psychology skills to young adults who have undergone cancer treatment and supports anxiety reduction. Further analysis with a larger sample size is required to confirm this pattern. © 2020 Elsevier B.V., All rights reserved."
348,0,0.20353913801496468,"Purpose The aim of this study was to investigate if and how an artificially intelligent chat agent (chatbot) that answers questions about sex, drugs, and alcohol is used and evaluated by adolescents, especially in comparison with information lines and search engines. Methods A sample of 929 adolescents (64% girls, mean age = 15), varying in urbanization level and educational level, participated in this study. Use of the chatbot was objectively tracked through server registrations (e.g., frequency and duration of conversations with the chatbot, the number and topics of queries), and a web-based questionnaire was used to evaluate the chatbot (e.g., the perception of anonymity, conciseness, ease of use, fun, quality and quantity of information, and speed) and to compare it with information lines and search engines. Results The chatbot reached high school attendees in general and not only adolescents with previous experience related to sex, drugs, or alcohol; this is promising from an informed decision-making point of view. Frequency (M = 11) and duration of conversations (3:57 minutes) was high and the chatbot was evaluated positively, especially in comparison with information lines and search engines. Conclusion The use of chatbots within the field of health promotion has a large potential to reach a varied group of adolescents and to provide them with answers to their questions related to sex, drugs, and alcohol. © 2011 Society for Adolescent Health and Medicine. © 2011 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document."
